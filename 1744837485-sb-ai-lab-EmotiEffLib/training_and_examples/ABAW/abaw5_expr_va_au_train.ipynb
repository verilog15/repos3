{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,roc_auc_score,average_precision_score\n",
    "import mord\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(id):\n",
    "    name = \"\"\n",
    "    if id>=0 and id<10:\n",
    "        name = \"0000\" + str(id)\n",
    "    elif id>=10 and id<100:\n",
    "        name = \"000\" + str(id)\n",
    "    elif id>=100 and id<1000:\n",
    "        name = \"00\" + str(id)\n",
    "    elif id>=1000 and id<10000:\n",
    "        name = \"0\" + str(id)\n",
    "    else:\n",
    "        name = str(id)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_filenames=lambda x: int(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.7.1+cu110\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    PATH='enet_b2_8.pt'\n",
    "    #PATH='enet_b2_7.pt'\n",
    "    IMG_SIZE=260 #224 #\n",
    "else:\n",
    "    #PATH='enet_b0_8_best_afew.pt'\n",
    "    PATH='enet_b0_8_best_vgaf.pt'\n",
    "    \n",
    "    #PATH='enet_b0_8_va_mtl.pt'\n",
    "    IMG_SIZE=224\n",
    "    \n",
    "#IMG_SIZE=112\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "np_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(None),\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf.pt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)\n",
    "feature_extractor_model = torch.load('../../models/affectnet_emotions/'+PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1280) [[ 0.00679121  0.09001139  0.0694934  ...  0.10351563 -0.00995514\n",
      "  -0.17376047]\n",
      " [-0.004085   -0.07134113 -0.12164655 ... -0.05029012  0.03059323\n",
      "   0.08198261]\n",
      " [-0.0034241  -0.06510569 -0.00448079 ...  0.04248156 -0.10535879\n",
      "  -0.00544419]\n",
      " ...\n",
      " [ 0.07878461 -0.03540913 -0.06665969 ... -0.10314589  0.1332206\n",
      "  -0.06119434]\n",
      " [-0.02409821 -0.00270485  0.00887998 ... -0.00501176  0.01345664\n",
      "  -0.02131553]\n",
      " [-0.04529824 -0.04590099 -0.00950194 ...  0.00753843  0.02128105\n",
      "  -0.05743075]]\n",
      "(10,) [-0.03629377 -0.00268708 -0.05411524  0.01482256  0.13788255  0.09921926\n",
      " -0.05259513 -0.0124341   0.0816549   0.04621203]\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    classifier_weights=feature_extractor_model.classifier[0].weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier[0].bias.cpu().data.numpy()\n",
    "else:\n",
    "    classifier_weights=feature_extractor_model.classifier.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier.bias.cpu().data.numpy()\n",
    "print(classifier_weights.shape,classifier_weights)\n",
    "print(classifier_bias.shape,classifier_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor_model.classifier=torch.nn.Identity()\n",
    "feature_extractor_model=feature_extractor_model.to(device)\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probab(features):\n",
    "    x=np.dot(features,np.transpose(classifier_weights))+classifier_bias\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(112, 112), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER/cropped_aligned/cropped_aligned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fec6744e1848ca80ff742775bf11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER/cropped_aligned/cropped_aligned_new_50_vids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69ddd6232c14cc3bde6e5526b9b7f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "img_names=[]\n",
    "X_global_features=[]\n",
    "imgs=[]\n",
    "for d in ['cropped_aligned','cropped_aligned_new_50_vids']:\n",
    "    data_dir=os.path.join(DATA_DIR,'cropped_aligned',d)\n",
    "    print(data_dir)\n",
    "    for filename in tqdm(os.listdir(data_dir)):\n",
    "        frames_dir=os.path.join(data_dir,filename)   \n",
    "        if not os.path.isdir(frames_dir):\n",
    "            continue\n",
    "        for img_name in os.listdir(frames_dir):\n",
    "            if img_name.lower().endswith('.jpg'):\n",
    "                img = Image.open(os.path.join(frames_dir,img_name))\n",
    "                img_tensor = test_transforms(img)\n",
    "                if img.size:\n",
    "                    img_names.append(filename+'/'+img_name)\n",
    "                    imgs.append(img_tensor)\n",
    "                    if len(imgs)>=64: #96: #48: #32:        \n",
    "                        features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                        features=features.data.cpu().numpy()\n",
    "                        #print(features.shape)\n",
    "\n",
    "                        if len(X_global_features)==0:\n",
    "                            X_global_features=features\n",
    "                        else:\n",
    "                            X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                        imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]\n",
    "\n",
    "    #X_scores=X_global_features #get_probab(X_global_features)\n",
    "    #print(X_global_features.shape,X_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95fdbc250b4451b90b1753cb9166a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in tqdm(os.listdir(data_dir)[8:]):\n",
    "    frames_dir=os.path.join(data_dir,filename)   \n",
    "    if not os.path.isdir(frames_dir):\n",
    "        continue\n",
    "    for img_name in os.listdir(frames_dir):\n",
    "        if img_name.lower().endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(frames_dir,img_name))\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                img_names.append(filename+'/'+img_name)\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=96: #64: #48: #32:        \n",
    "                    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    features=features.data.cpu().numpy()\n",
    "                    #print(features.shape)\n",
    "\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=features\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER/cropped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a2505bef1d49a98930f28163c390b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "img_names=[]\n",
    "X_global_features=[]\n",
    "imgs=[]\n",
    "data_dir=os.path.join(DATA_DIR,'cropped')\n",
    "print(data_dir)\n",
    "for filename in tqdm(os.listdir(data_dir)):\n",
    "    frames_dir=os.path.join(data_dir,filename)   \n",
    "    if not os.path.isdir(frames_dir):\n",
    "        continue\n",
    "    for img_name in os.listdir(frames_dir):\n",
    "        if img_name.lower().endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(frames_dir,img_name))\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                img_names.append(filename+'/'+img_name)\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=64: #96: #48: #32:        \n",
    "                    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    features=features.data.cpu().numpy()\n",
    "                    #print(features.shape)\n",
    "\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=features\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scores=get_probab(X_global_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2942996, 10), (2942996, 1280))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scores.shape,X_global_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942996\n"
     ]
    }
   ],
   "source": [
    "filename2featuresAll={img_name:(global_features,scores) for img_name,global_features,scores in zip(img_names,X_global_features,X_scores)}\n",
    "#filename2featuresAll={img_name:(global_features,) for img_name,global_features, in zip(img_names,X_global_features)}\n",
    "print(len(filename2featuresAll))\n",
    "#cropped 2942996, aligned 2941546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf_cropped.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "num_classes=8\n",
    "model_name='enet_b0_8_best_vgaf' #first three challenges\n",
    "\n",
    "#model_name='enet_b0_8_va_mtl'\n",
    "\n",
    "#MODEL2FEATURES=model_name+'_aligned_112.pickle'\n",
    "MODEL2FEATURES=model_name+'_cropped.pickle' \n",
    "\n",
    "print(MODEL2FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(MODEL2FEATURES, 'wb') as handle:\n",
    "        pickle.dump(filename2featuresAll, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942996\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL2FEATURES, 'rb') as handle:\n",
    "    filename2featuresAll=pickle.load(handle)\n",
    "print(len(filename2featuresAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential, load_model,model_from_json\n",
    "from tensorflow.keras.applications import mobilenet,mobilenet_v2,densenet,inception_resnet_v2,inception_v3,vgg16,resnet_v2,resnet\n",
    "import efficientnet.tfkeras as enet\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,GlobalAveragePooling2D,Activation, Conv2D, Reshape,DepthwiseConv2D,Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transfer(label,class_num):\n",
    "    return np.eye(class_num)[label]\n",
    "\n",
    "def metric_for_Exp(gt,pred,class_num=8):\n",
    "    # compute_acc\n",
    "    acc = accuracy_score(gt,pred)\n",
    "    # compute_F1\n",
    "    gt = one_hot_transfer(gt,class_num)\n",
    "    pred = one_hot_transfer(pred,class_num)\n",
    "    F1 = []\n",
    "    for i in range(class_num):\n",
    "        gt_ = gt[:,i]\n",
    "        pred_ = pred[:,i]\n",
    "        F1.append(f1_score(gt_.flatten(), pred_))\n",
    "    F1_mean = np.mean(F1)\n",
    "    return F1_mean,acc,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCC_score(x, y):\n",
    "    vx = x - np.mean(x)\n",
    "    vy = y - np.mean(y)\n",
    "    rho = np.sum(vx * vy) / (np.sqrt(np.sum(vx**2)) * np.sqrt(np.sum(vy**2)))\n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    x_s = np.std(x)\n",
    "    y_s = np.std(y)\n",
    "    ccc = 2*rho*x_s*y_s/(x_s**2 + y_s**2 + (x_m - y_m)**2)\n",
    "    return ccc\n",
    "\n",
    "def metric_for_VA(gt_V,gt_A,pred_V,pred_A):\n",
    "    ccc_V,ccc_A = CCC_score(gt_V,pred_V),CCC_score(gt_A,pred_A)\n",
    "    return ccc_V,ccc_A, 0.5*(ccc_V+ccc_A)\n",
    "\n",
    "def CCC_numpy(y_true, y_pred):\n",
    "    '''Reference numpy implementation of Lin's Concordance correlation coefficient'''\n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    s_xy = np.cov([y_true, y_pred])[0,1]\n",
    "    # means\n",
    "    x_m = np.mean(y_true)\n",
    "    y_m = np.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = np.var(y_true)\n",
    "    s_y_sq = np.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2)\n",
    "    \n",
    "    return ccc\n",
    "\n",
    "def CCC(y_true, y_pred):\n",
    "    '''Lin's Concordance correlation coefficient: https://en.wikipedia.org/wiki/Concordance_correlation_coefficient\n",
    "    \n",
    "    The concordance correlation coefficient is the correlation between two variables that fall on the 45 degree line through the origin.\n",
    "    \n",
    "    It is a product of\n",
    "    - precision (Pearson correlation coefficient) and\n",
    "    - accuracy (closeness to 45 degree line)\n",
    "\n",
    "    Interpretation:\n",
    "    - `rho_c =  1` : perfect agreement\n",
    "    - `rho_c =  0` : no agreement\n",
    "    - `rho_c = -1` : perfect disagreement \n",
    "    \n",
    "    Args: \n",
    "    - y_true: ground truth\n",
    "    - y_pred: predicted values\n",
    "    \n",
    "    Returns:\n",
    "    - concordance correlation coefficient (float)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    #N = K.int_shape(y_pred)[-1]\n",
    "    #s_xy = 1.0 / (N - 1.0 + K.epsilon()) * K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    #s_xy = K.mean(K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred))))\n",
    "    s_xy = K.mean((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    # means\n",
    "    x_m = K.mean(y_true)\n",
    "    y_m = K.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = K.var(y_true)\n",
    "    s_y_sq = K.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2+K.epsilon())\n",
    "    #print(s_xy,s_x_sq,s_y_sq,x_m,y_m)\n",
    "    return ccc\n",
    "\n",
    "def CCC_VA(y_true, y_pred):\n",
    "    return 1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def f1_score_max_for_AU_one_class(gt, pred, thresh,type=0):\n",
    "    gt = gt[:,type]\n",
    "    pred = pred[:,type]\n",
    "    P = []\n",
    "    R = []\n",
    "    ACC = []\n",
    "    F1 = []\n",
    "    for i in thresh:\n",
    "        new_pred = ((pred >= i) * 1).flatten()\n",
    "        P.append(precision_score(gt.flatten(), new_pred))\n",
    "        R.append(recall_score(gt.flatten(), new_pred))\n",
    "        ACC.append(accuracy_score(gt.flatten(), new_pred))\n",
    "        F1.append(f1_score(gt.flatten(), new_pred))\n",
    "\n",
    "    F1_MAX = max(F1)\n",
    "    if F1_MAX < 0 or math.isnan(F1_MAX):\n",
    "        F1_MAX = 0\n",
    "        F1_THRESH = 0\n",
    "        accuracy = 0\n",
    "    else:\n",
    "        idx_thresh = np.argmax(F1)\n",
    "        F1_THRESH = thresh[idx_thresh]\n",
    "        accuracy = ACC[idx_thresh]\n",
    "    return F1,F1_MAX,F1_THRESH,accuracy\n",
    "\n",
    "def f1_score_max(gt, pred, thresh,c=12):\n",
    "    F1_s = []\n",
    "    F1_t = []\n",
    "    ACC = []\n",
    "    from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "    for i in range(c):\n",
    "        F1, F1_MAX, F1_THRESH,acc = f1_score_max_for_AU_one_class(gt,pred,thresh,i)\n",
    "        F1_s.append(F1_MAX)\n",
    "        F1_t.append(F1_THRESH)\n",
    "        ACC.append(acc)\n",
    "    F1_s=np.array(F1_s)\n",
    "    F1_t=np.array(F1_t)\n",
    "    ACC=np.array(ACC)\n",
    "    return F1_s.mean(),F1_t.mean(),F1_s,F1_t,ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffectNet: {'Angry': 0, 'Contempt': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Sad': 6, 'Surprise': 7}\n",
      "[5 0 2 3 4 6 7 1]\n"
     ]
    }
   ],
   "source": [
    "idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprise'}\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n",
    "print('AffectNet:',class_to_idx)\n",
    "\n",
    "#idx_to_class_2={0: 'Neutral', 1:'Angry', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprised', 7:'Other'} #ABAW\n",
    "#idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprised'} #AffectNet\n",
    "AFFECTNET2MTL=np.array([5,0,2,3,4,6,7,1])\n",
    "print(AFFECTNET2MTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585317, 1280) (585317,) 12044 1\n",
      "(280532, 1280) (280532,) 3698 3\n"
     ]
    }
   ],
   "source": [
    "def get_image2Expr(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'EXPR_Classification_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    minConstantFrames,numConstant=100000,0\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                prev_val=None\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        expression=int(line)\n",
    "                        if expression>=0:\n",
    "                            if prev_val is None:\n",
    "                                prev_val=expression\n",
    "                                numConstant=1\n",
    "                            elif prev_val==expression:\n",
    "                                numConstant+=1\n",
    "                            else:\n",
    "                                if numConstant<minConstantFrames:\n",
    "                                    minConstantFrames=numConstant\n",
    "                                prev_val=expression\n",
    "                                numConstant=1\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if imagename in filename2featuresAll:\n",
    "                                X.append(filename2featuresAll[imagename][0])\n",
    "                                #X.append(filename2featuresAll[imagename][1])\n",
    "                                y.append(expression)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed,minConstantFrames)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2Expr('Train_Set')\n",
    "X_val,y_val=get_image2Expr('Validation_Set')\n",
    "TRAIN_VAL=False\n",
    "#cropped: (585317, 1280) (585317,) 12044 1\n",
    "#(280532, 1280) (280532,) 3698 3\n",
    "\n",
    "#aligned: (586959, 1280) (586959,) 10402 1\n",
    "#(279749, 1280) (279749,) 4481 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146381, 1280) (1146381,)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_train=np.concatenate((y_train,y_val))\n",
    "    print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expr():\n",
    "    y_val_preds=mlpModel.predict(X_val)\n",
    "    y_pred=np.argmax(y_val_preds,axis=1)\n",
    "    print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "    print(metric_for_Exp(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[341714  28825  21363  25896 164485 129065  56279 378754] {0: 1.1083947394604845, 1: 13.139774501300954, 2: 17.72943874923934, 3: 14.625965400061785, 4: 2.3026658965863147, 5: 2.9345988455429435, 6: 6.729934789175358, 7: 1.0} 8 [0 1 2 3 4 5 6 7]\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 82258,   6126,   5296,   8408,  34511,  25157,  12332, 106444]))\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)\n",
    "print(np.unique(y_val, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256 #128\n",
    "mlpModel=Sequential()\n",
    "if False:\n",
    "    mlpModel.add(Dense(num_classes, input_shape=X_train.shape[1:],activation='softmax',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_train.shape[1:],activation='relu')) #256\n",
    "    mlpModel.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 165,000\n",
      "Trainable params: 165,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4479/4479 [==============================] - 19s 4ms/step - loss: 1.4780 - accuracy: 0.7774 - val_loss: 0.2638 - val_accuracy: 0.9082\n",
      "0.9082100987434387\n"
     ]
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(lr=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlpModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_accuracy',True)\n",
    "mlpModel.fit(X_train,y_train, batch_size=batch_size, epochs=1 if TRAIN_VAL else 10, verbose=1, \n",
    "             callbacks=[save_best_model], validation_data=(X_val,y_val),class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.44149687023227296 F1: 0.33779997894441405\n",
      "(0.33779997894441405, 0.44149687023227296, [0.4416201062812616, 0.15014895729890765, 0.4473529411764706, 0.03736895502198174, 0.44162295893122216, 0.4805736532655331, 0.1928639673178928, 0.5108482922620425])\n",
      "Best weights:\n",
      "Acc: 0.4512782855431822 F1: 0.32977590239234855\n",
      "(0.32977590239234855, 0.4512782855431822, [0.5265049308722749, 0.136551724137931, 0.23451630063074705, 0.034811438043928715, 0.5094281502343286, 0.5118863619636418, 0.22221146632462913, 0.4622968469313074])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print_expr()\n",
    "    print('Best weights:')\n",
    "    mlpModel.set_weights(best_model_weights)\n",
    "print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    mlpModel.save_weights('expr_enet0_vgaf.h5')#Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "else:\n",
    "    #mlpModel.load_weights('../expr_enet0_vgaf.h5') #Acc: 0.500285172458044 F1: 0.3807067519117502\n",
    "    mlpModel.load_weights('expr_enet0_vgaf.h5') #Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "    print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n"
     ]
    }
   ],
   "source": [
    "mlpModel.load_weights('expr_enet0_vgaf.h5')\n",
    "y_val_preds=mlpModel.predict(X_val)\n",
    "y_pred=np.argmax(y_val_preds,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "print(metric_for_Exp(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280532,) (280532,) 0.49544436998274705\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAIUCAYAAAAaBSb8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAACdpUlEQVR4nOzddXQUVxvH8e9NQgLxQALBg7tT3Cm0uBeHtlC0SHF3K1Ao0pe2uEORYsXdNbi7FJdAQnQ39/1jl20oDkk26T6fczgkM7Ozz93NzPz23juJ0lojhBBCCGEL7KxdgBBCCCFEbJHgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZDtYuIL5TDom0cnSzdhmxKk+2NNYuIdYpaxcgYkVYRKS1S4h1Tgls7/OvMdL2fo1LUJjB2iXEqgd3bvLsyePXnrol+Hwi5eiGU5avrF1GrNqxZ6K1S4h1Dna2F32U7TWZy/eeW7uEWJcuqYu1S4h1gSER1i4h1u2++tDaJcSqno0qvXGd7UV9IYQQQtgsCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshoO1CxBgZ6fYNqcHd+4/pUGXXylZMDNDO9XCMYE9x87epMOw+RiNkbi7JOS3oc1JlcwLewd7Js/bwoLV+wFYMrEdn+X0Y/+xKzTo8utL++/Xtho1yufDGBnJjGW7+H3xDms087U6DZvPpr2n8fZyY+f83i+tm7JgK4MmreDMuhEk8XRFa03f8cvYsvcMiRI6MrF/Y3JnSQ3ArbuP6TJyIbfvBaAUzB/XhjTJk1ijSR/MaIyk/NdjSO7jwcJxbdBaM/zXNazachQ7ezu+qV2C1vXLsPvIRZp0/520KUztqlomD91bVrJy9R/u1r0ntBs0l/uPA1FA81rFadOgDCs2H+XHqWu5cO0em2d2I1/2NADcuP2IIvWHkzFNUgAK5vRjXO8GVmzB+1m4ajcrNhxCa03NLwrRqEYJngYG02f0Au7ce0LyZF6M7NkId1dnrt28z5AJSzl3+W/aNv2CprVLWfazYMUuVmw8hFKKjH6+DOhUFyfHBFZs2ft5GhhM5+ELOXvlNkopJvZrTCKnBHT7cTHPQ8JInTwJvw1uhptrIsIjDHQduYhj525gpxTDu9SlRIFM1m7CezMaI6neejy+3h5MH9WSm3ce0WHIXAKePidnltSM69MIxwQOTPtjO4v/OoC9vR1JPF35sUd9UvkmBuDve0/oNWYxd+4HoJRi5qjvSJU8sZVbZjJ1+hqOHr+Eu7szo4a1sizfuPkQm7ccwc7Ojjx5MtLwq3IA3Lh5n5mz1xESEoZSisEDv8ExgQNLlm1n956TPA8OZdqv3S372bLN37wfRcKEjnzbvBIpU/rEWHviZPBRSmlgnNa6q/n7boCr1nrQR+zLE2iktf7fRzz2GlBQa/3wQx/7Ido0KMuFq/dwc0mIUoopg5pSo90kLt+4T+/WVWhYpTDzVu2jZb1SnL9yl4ZdfiOJpyuHlvZnybpDRBiMTJq7GeeEjnxdq8RL+25UrQgpk3lSqN5QtNZ4e7nGZFM+WIMqhWlRrxTfD5n30vK/7z1h+8FzpPL1sizbsu8MV28+YP+S/hw5fY0eo/9g/fSuAHQYMo/OX1ekdKGsPA8OQ9mpWG3Hp/ht8XYy+yUj8HkoAAvWHODve0/Y/0c/7OzsePA40LJt0bwZWDiujbVKjRYO9nYM7VSLPFlTE/g8lHLNRlOmUBayZUjOnNEt6TJy0SuP8Uvpzc75vaxQ7ce5dP0uKzYcYvZP7XFIYE/HgTMp+VlW/txwkM9yZ+TremWYtWQ7s5fuoMPXlXB3c6Zrq2rs2H/mpf3cf/SUxav3svh/XUjolIDeo+azcedxqn1e0Eote399xi2jXNFszBzVgvAIAyGh4dTp8AuDO9akeP5MzF+1j8nzttC7TVXmrtgLwK4FfXjwOJD6naeweVY37Ozix6DEzGU7yZg2KUHPwwAY9dsaWtQtTbXy+ej70xL+WHuAJjWKkyNTSlb99gOJEjoyb+UeRv22hskDmwHQdcQC2jf9nJIFs/A8OAy7OHQOK1kiNxXKF+TXaassy86cvYb/0YsMH9KSBAkcePrsOWAKgb/+vpLW31UnbZpkBAYF42Bveh/z5c1EhfIF6dZrykv7L1YkB+XL5gfA/+gF5i/aQo+uMffhJq7+VIUBtZVS3tGwL0+g3etWKKWsHvxSJPWkYokczFlpOvATe7gQHmHg8o37AGw/cI7q5fICoAFXFycAXJydePIsGIMxEoCdhy4QaD7oovq2TglGT1uH1hqAh0+CYrhFH6Zovox4uju/snzAhOUMaF8DxT8H//qdJ6lXqRBKKQrmTMezoBDuPXzK+at3MBgjKV0oK2B6bZwTOsZaGz7F3/eesHHPaZrUKGpZNnP5Lrq3qGQ56fskdrNWeTHC19uDPFlNPXVuLgnJnM6XOw+ekiWdL5nSJrNyddHj2s375MySmoQJHXGwtyd/znRs23eaHQfOULW86QRftXx+tu8/DUBiT1dyZE6Ng8Orp2RDZCRh4REYjEZCwyLwSeweq235GM+CQth39BJNqpt+rh0TOODh5szlG/cpli8jAGUKZ2X1tuMAnL96l5IFMwOmn3cPt0QcO3vDOsV/oDv3A9i2/yz1qxQBQGvNPv9LVCqdG4A6X37Gxt2nACiaLxOJzOemfNnTcvdBAAAXr93FaIykZMEsgOkcligOncOyZkmDi2vCl5Zt2eZP1cpFSZDAdBn1cHcB4OSpK6ROlZS0aUzHspurs+VcljFDSjw9X/3wnSiRk+XrsLAIVAxnvrgafAzA78AP/16hlPJRSi1TSh0y/ytuXj7I3DP0YrtTSik/YBSQQSl1TCk1RilVRim1Sym1Cjhj3naFUuqIUuq0UqrVv58zJo3oUoeBE1cQGWkKJo8CgnCwtydvNlM3f/XyeUmZzNTrMfWPHWT28+XsuuHsWdiH3j8ttQSaN0mX0ofaFQqwdXYPlkxoS/rUMdd9GF3W7TyBr48nOTKlfGn5nQdPSZnM0/J9ch9P7jx4yuUbD3B3TcQ3vaZRvtmPDJ60AqM5EMZ1fccvZ9D3NbBT/xyK12495M/N/pRrPpqvOv/PEoIBDp28SqnGI/mq8/84d+WONUqOVjduP+LE+VsUyJH2nduVbvIjVVtPYN/RS7FU3cfLkNaXY6evEfDsOaGh4ew9fJ57DwN4HBCEtzm4JPFy43HA2z+IJE3iQZNaJan27SgqNRuBi0tCiuTPHBtN+CTXbz8iiZcrHYbOo2zTH+k0fAHPQ8LImj4563aeAGDllqP8ff8JADkypWT9rpMYDEau337I8XM3+ftegBVb8P6GTF5Br9ZVsTNfrZ88fY67a0IcHOwB8PXx4N6Dp688bvFfByhdKBsAV2+azmFt+s+kSsufGDFlVZw/h929+5jzF24ycOgsho2ay5Urt03L7z1GKcXosQvpN3A6a9bue6/9bdpymK49/seiP7bStFHFmCw9zgYfgF+Axkopj38tnwCM11p/BtQBpr1jP72Ay1rrvFrrF4OK+YFOWusXZ5BvtdYFgIJAR6XUWyeHKKVaKaUOK6UOa0PIh7TpJV+UyMnDJ4EcP3fzpeUt+s5kxA+12TyrG0HPwzBGmg6AckWycfLCLbJV6kupxiMZ3b0ebi4JX7drC0dHB0LDIyjXfDSzV+xlcv/GH11vbAgODWfC7E30/K7yez/GaDRy4PhlBnaoyYYZ3bh++xGL/joQg1VGjw27T+Gd2NUScl8IjzCQ0NGBrbN70LRGMToOmw9A7iypOLZyCDvn9+a7eqVp2n2qNcqONkHBYTTvNZ0RXWrj7projdsl83bnxKoh7JjXk2Gda/Fd/9k8C/r44y42pEudlGZ1StNhwAw6DppB5vTJXxm2USpqf+brPQsKZueBM6yc1oN1s/sQGhrO2m1HY67waGIwRnLi/C2+qV2SbXN74pLQkYmzNzGxXyNmLN1NuWajCQoOxdEcDhpXK0LypJ58/vUY+o5bTqFc6bC3jztDPW+yZe9pvL1cyWWea/i+/tx4mJPnb9KqQVnA9HodOnmFPm2rs/LXzty884il6w/GRMnRxhgZyfPnIQzq15yGX5Vn0pQ/0VpjNEZy/uJN2rauQf8+zTjif4HTZ66+c38Vyhfkp9HtqF+vHCtX74nR2q0+1PMmWutnSqk5QEcg6lnucyC7+qcvzF0p9aETVw5qraO+Ex2VUrXMX6cGMgGP3lLb75h6pLBzTvr2Lpe3KJwnPV+WzEWFYjlwckqAm0tCfhvSjNYD5lC51c8AlC2clQzmSZ2NqxXh59mbALh66yHXbz8iU9pk+J+5/sbnuH3/iaU7ec224/wyoMnHlhsrrt16yI07jyjX9EcAbj8IoMLXY1g/vSvJfTxe+hR450EAyX08MBiN5MyUEr+UppHRSqVyceTUNaDoq08Qhxw4foX1O0+xee8ZwsIiCHweSuuBs0me1JOqZfMApgnMHYaagk/UcFCheA66j/mDRwFBJHlN13FcF2Ew0rznNOp+UZBqZfO+dVsnxwSWybx5s6UhXSpvLt94YJn8HFfVqPgZNSp+BsAvc9aTNIkHiT1defj4Gd6J3Xn4+Ble73jvDh67RIpkifHyMG1XtlgOTpy9TuWy+WK8/k+RIqknKZJ6UiCnHwDVyuVlwpxN9G5TlaWT2gNw6cZ9Nu0xDfU5ONgz/Ic6lsdXajmODKmTxnrdH+rIqats3nOabfvPEhZuICg4lCGTV/AsKBSDwYiDgz13Hzwlmc8/n993H77AL/M2s2hCe5wcTZfg5D4eZMuYgjTmGxcqlMjF0TPXqW+VVr2fxF7uFCyQBaUUGdKnwE4pAgODSZzYjayZ0+DmZprCkCd3Bq5dv0eO7Onea79FCmdn1tz1MVl6nO7xAfgZaAG4RFlmBxQx9+Dk1Vqn1FoHYRoei9qet3WFPH/xhVKqDKYwVVRrnQc4+o7HRpshv6wiZ9X+5KkxkBZ9ZrLr0AVaD5hjmYDsmMCBTs0rMHP5bgBu3X1Cqc9MY8A+id3ImDYZ1/5++7zrtTtOUNJ8d0Tx/Jm4FGXYJC7KnjEFZ9aO4PCfgzj85yBS+HiyaVZ3kiZx54uSuViy7iBaaw6fuoqbS0KSeXuQL1tangaF8PCJaRLw7iMXyZzO18otebcB7atzas1Qjq0YzNRh31CyYGZ+G9ycyqVzs/vwRQD2+F+yBN97j55ZhjaPnL5GZKQmsYfLG/cfV2mt6Th0PpnT+dK+cbl3bv/wSaCl2//a3w+5cvMBfinj/h17L4ax7t4PYNve03xZOi+lCmVnzRZ/ANZs8ad04exv3Yevjycnz90gNDQcrTWHjl8mXTwYrk6WxJ2UST25eP0eADsPXyBLuuSWifqRkZGMm7HecjNGcGg4z0NMcxS3HziHvb0dWdInt07xH6BHq6rsWzqQ3Yv7M2lAU4rly8TP/ZpQJF9G1u0wDektW3+ICsVzAnD64i36jlvC1BEt8Pb6Z+5e7qxpeBYUwiPzz8w+/4txfr5bgfyZOXvO9KH7zt1HGAxG3NycyZ0zPTdv3ScsLAKjMZJz52+QMsXbp+vevfvY8vWxE5fwTeb1lq0/XZzt8QHQWj9WSv2BKfzMMC/eCHQAxgAopfJqrY8B14Cq5mX5gRfxMhB42+xQD+CJ1jpYKZUVKBLNzfhgHZt+TsUSObGzU8xYtotdhy8AMGb6en4Z2IQ9C/ugFAyevJLHT00Zbu3vncnklwyXRE6cWjOUjsMWsHX/WcbP2sTUoc1p16gcQcFhdBq2wJpNe0XrAbPY63+JxwFB5K3en+4tK9O4+ut7aj4vlp0te09TuN4QEjk5MqGfadjO3t6OQR1qUrfDL2ityZM1NU1qFIvNZkSrzs0q0HrAbKYs2oZLIicm9GkIwKqtR5m5bDcO9nYkdHJk2rCvUTE9CzAGHDh+hcXrDpE9YwpKNR4FQP921QgLN9Dzp6U8ehJEgy6/kjNTSpZNas/eo5cZ+dtfJHCwx85O8VOv+njFg8DXc+Q8ngaa7mjp0bYGbq6JaF63NL1/XMCqTYfwTWq6nR1M4a75D5MsdyQuWrWbxf/rQs4saShfPBdNOk8yh4EU1PqysJVb9n5GdqtHmwGziTAYSZsiCZP6N2Hx2oNMX7oTgKpl89Comul0+/BxIPU6/Q87O0VyHw+mDGpmzdI/Wa/WVekwZA4/TV9L9kyp+Kqy6T0bOWU1z0PCaD9wNgApknkxbUQL7O3t6NO2Oo27TAGtyZk5NQ2qWv1SZPHLrys4e+46QUEhdOwyido1S1K6ZB6mTl9Dr36/42BvT6uW1VBK4eKSiEpfFGbgkJmgIE/ujOTNY5rQvvCPrezbf5rw8Ag6dplEmVJ5qF2zFJu2HOb0mWvY29vh4pKQVi2rxWh71Lsmx1qDUipIa+1q/joZcBUYrbUeZL7T6xcgG6bgtlNr3UYplQhYCaQEDmAa56iktb6mlFoA5AbWAX8B3bTWL0KSE7AC8APOY7oLbJDWevv73M5u55xUO2X5Kppfgbjt3r6J1i4h1jnEoVtLY0s8zFSf7PK95+/e6D8mXdK4HyKjW2BIhLVLiHW7r8bob2WJc3o2qsTlM8dfexaLkz0+L0KP+et7gHOU7x/Cq0OfWusQ4LVTwbXWjf61aHuUdWHAa38LnNba7wPKFkIIIUQcF9fn+AghhBBCRBsJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyG0lpbu4Z4LX+BgnrHnoPWLiNWKWXtCmKfvZ3tNTpSTg02wRavAQ72tveZ32CMtHYJsapUsUL4Hzn82hO37b37QgghhLBZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMcrF2A+EenYfPZtPc03l5u7JzfG4BBk1awcfcpEiRwwC+lNxP7NcLDzZkbdx5RosEIMqRNCkCBHH6M7VkfgBG/ruGPdQcJCAzm2taxVmvP++g4bD6b9pjavGuBqc1Pnj7nu36zuHHnMWmSJ2ba8G/wdHdm8rwtLN1wGACjMZIL1+5ybt0IgkPDaT94Lg8eB6KUomnNYrSuX8aKrXp/t+49od2gudx/HIgCmtcqTpsGZTh54RZdRi0mLCwCB3s7xvT8igI5/Lhw7S7fD5nPifO36Nu2Kh2alLd2Ez7Yxev3+K7vTMv31/5+RK9WlSleIBPdRi0mLDwCe3s7xvT4ivw5/ADYfeQi/cYvI8JgJLGnK6t/7WSl6j/O08BgOg9fyNkrt1FKMbFfY35dtI3L1++b1geF4OGaiO3zelkec+vuY4o3GE73lpX5Pp69z5eu36Nlv1mW76///ZCerSpTokBmuv+4mOchYaT2TcyvQ5rh5pII/9PX6TJqkWljreneshJVyuSxTvGf4Psh89iw+xTeXm7sW9z3pXWT522h/4Q/ubRpFEk8XZk4dzNL1h0CwGA+n13aOAovDxdrlP7eXnfOXrnlKGOmrePCtXtsnNGVvNnSALD9wDmG/m8VEQYjCRzsGdShJiULZiY4NJwWfWZw7e+H2NvZUbFETga0rx5rbVBa61h7suiilKoJ/Alk01qfs2Yt+QsU1Dv2HIyWfe07egkXZye+HzLPEny2HThLyQKZcXCwZ8gvKwEY0L4GN+48okm33y3bRXX41FVS+yam8FdDYyT4KBV9+9p79BIuiUxtfnEQDZ60Ek8PZzo1q8CEOZt4+iyYAd/XeOlxG3ad5NdF2/nzlw7cffiUew+fkSdraoKeh1L+6zHMGd2SLOmSR1ud9nbR2OgootYe+DyUcs1GM3fMd/QZv5y2DctQoVgONu05zcS5m1n9aycePA7k5t3HrN1+Ag935xgNPpGxcGowGiPJVbUfG2Z044cRC2nTsAyfm9s8ad5mVk3pxNPAYCq1HM8fE9qSyjcxDx4H4pPYLeaLi0btB8+lSN4MNK1RjPAIAyGh4Xi4OVvW95+wHHeXRHRvWcmy7Jte01EK8ufwi9HgE9PXAKMxklzV+rNhele+7TODQR1qUDx/Juav3seN24/p3boKwaHhODrY4+Bgz92HTynb9EdOrh6Kg4N9jNTkYB8zgx17/C/h6uxEm4FzXgo+t+4+odPw+Vy4do/tc3uSxNP1pcet23mSKQu3sWpKxxipC0zhKjq87px94epd7OwUXUctZnDHmpbgc+L8TZImdsfXx4Ozl2/zVecpnFw9lODQcPxPX6NEgcyERxio/f1kOjevyOfFskdLjQClihXC/8jh15644+tQV0Ngt/n/GKOUitUesaL5MuLp7vzSsrKFs1kO/gI5/Lh9P+Cd+ymYMx3JvD1iosRoVyxfRrz+1eZ1u05Sv3IhAOpXLsTanSdfedzyTf7UrlAAAF9vD/JkTQ2Aq0tCMvsl4879pzFcefSIWrubS0Iyp/PlzoOnKCDweSgAz4JC8DW/nz6J3cifPW2MXRBi285D5/FL5U3q5IlR6vVtXrbhMFXL5iGVb2KAeBd6ngWFsO/oJZpULwqAYwKHl0KP1pqVm49Su2IBy7K1O46TJkUSsqSPvvBuLTsPn8cvpek9vnzjPsXyZQSgTKGsrNl2DADnhI6Wn+mwcAOKmPmgEdOK53/1fAbQd/wyBnWoiXrDp8ZlGw9TJ8r7H5e97pydOZ0vGdMme2Xb3FlS4+tjOo6zpk9OaFgEYeEROCd0pESBzIDpeMidJTV33uPaFl3iXfBRSrkCJYAWQAPzsjJKqe1KqaVKqXNKqfnK/BOmlKpsXnZEKTVRKbXGvNxFKTVDKXVQKXVUKVXDvPxrpdQqpdRWYIt1Wvl6C9fsp3zRfxLxjduPKNfsR2q0ncD+Y5etWFn0evA40HLRS5bEnQePA19aHxwaztb9Z6la9tWu8Bu3H3Hywt8UyJk2VmqNTjduP+LE+VsUyJGWEV3qMHDiSnJW7c+AiStitRs4Nv25yd9ywR/+Qx0GTVpJ7mr9GThpBf3bmdp8+cYDAp4FU73tBMo1G83itQesWfIHu377EUm8XOkwdB5lm/5Ip+ELeB4SZlm/79hlfBK7kSGNadg6KDiMiXM2v9T7E59FfY+zpvdlnfmDzKotR/k7ysXuyKlrlGg4glKNRzKm51f/mXC/dscJkvt4kitzqteuDw4NZ8u+s1Qvlzd2C4tlq7cdI3fmVDg5Jnhp+dPAYDbuPkXJzzLHWi3xLvgANYD1WusLwCOl1IuYnA/oDGQH0gPFlVIJgd+ASlrrAoBPlP30BbZqrQsBZYExSqkXg6v5gbpa69KvK0Ap1UopdVgpdfjhgwfR3LzXGz9rA/b29tT9oiBgCgT+KwazdU5PhnSqRZuBswl8HhIrtcQmpdQrQ2sbdp2iUK50r4yFBwWH8U3v6QzrXBs3l0SxWOWnCwoOo3mv6YzoUht310TMXLab4T/U5tSaoQzrXJuOw+Zbu8RoFx5hYP2uk1Qvlw+Amct3M6xzbU6sNrW503BTmw1GI8fP3WThuDYsmdiOsdM3cOnGfWuW/kEMxkhOnL/FN7VLsm1uT1wSOjJx9ibL+uUbj7zU2zN66lraNCyLq7OTNcqNVuERBjbsOmW5qE/o25iZy3ZRvvlogoLDcIwSbgrk9GP3wj5smtGNCXM2ERoWYaWqo09waDjjZm6gd5sqb9xm/c6TFM6dPs7P7fkU567cYegvqxjbq/5Lyw0GI636z6blV6XwS+kda/XEx+DTEDDPgmMR/wx3HdRa39JaRwLHAD8gK3BFa33VvM3CKPupCPRSSh0DtgMJgTTmdZu01o/fVIDW+netdUGtdUFvH583bRZtFv11gI17TjNlcDNLV6mTYwISmw+UPFnT4JfSm8s3YieExTSfxG7cfWgaqrr78CneXi8PbazY7P/ShQIgwmDkm97TqftFwdf2BMVlEQYjzXtOo+4XBalWNi8AC/86QDVzO2p+no8jZ25YscKYsXnvGXJnSU3SJO6A6ef8xXtXo3w+/E+b2pwiqSdli2TFJZETSTxdKZYvA6cv/m21uj9UiqSepEjqSYGcfgBUK5eX4+dvAqYT/1/bjlPr8/yW7f1PX2Pw5JXkqzmQ3xZt5+fZG5m2ZIc1Sv9kW/adIXeWVJb3OJNfMpZMbM+W2T2oXbEAfqlevdhlTueLSyInzl25E9vlRrurtx5w/fYjSjYaSe7qA7h9P4DSTX7k3sNnlm2WbzpCnS/ixzDXx7h9/wnNe05j8oCmpEv18vWyy6hFpE/tQ5sGZWO1pngVfJRSiYFywDSl1DWgO/AVoICwKJsaefcdawqoo7XOa/6XRmt91rzuefRW/vG27jvD5HmbmTv6O5wTOlqWP3wSiNE8We3a3w+5cvMBaVMksVaZ0erLkjlZvNY0YXzx2oNUKpnLsu5ZUAh7j17iy1L/LNNa03n4AjL7JaNto3KxXu+n0FrTceh8MqfzpX3jf2r39fFgj/8lAHYeukCG1DEfsGPbv3s6orZ51+ELpDe3uVKp3Bw4fgWDwUhwaDhHTl8ns9+r8wniqmRJ3EmZ1JOL1+8BsPPwBcvE+x2HzpPRLxkpknlZtl/z+w8cXTGYoysG07pBGTo3r0jLeq/tfI7zlm/0p1aU9/jFsHVkZCTjZm6gea3igGk40GAwAnDzzmMuXr9H6uSJY7/gaJYjY0oubhzFiVVDOLFqCCmSerJjXk+SeZuC4NOgEPb4X6Jy6dxWrjRmPA0MplGX3+jfrjqF86R/ad2IX9fwLCiU4T/UjvW64tvt7HWBuVrr1i8WKKV2ACXfsP15IL1Syk9rfQ2I2s+2AeiglOqgtdZKqXxa66MxVfj7aD1gFnv8L/E4IIg81fvTo2VlJszZRHiEgXqd/gf8c9v6vmOXGT11LQ4O9tgpxZgeX1m6SgdPXsnyjYcJCY0gT/X+NK5elB4tK1uzaW/Uqv8/bc5drT89vqtMx2YVaNl3JvNX7Se1rxfThn9j2f6v7ScoU8j06f+FA8ev8Me6Q2TPkIIyTX8EoG/bqlQoliPW2/OhDhy/wuJ1h8ieMQWlGo8CoH+7akzo05De45ZhMBhxckrA+N4NALj38Bnlvh5D4PNQ7JTi10Xb2beoD+6u8Wto73lIGDsOnmOcuV0A43s3pM+4ZRiNpja/WJc5nS/limSjVONR2NkpmlQvSrYMKaxV+kcZ2a0ebQbMJsJgJG2KJEzq3wSAPzcdeaX38r/ixXv8U5ThjeWbjjBj6S4AqpTJQ6OqRQA4cPwyE+dstpzPRnf/6pU7n+KDFn1nsufIRR4FBJGjSj96tapM0xrF3rj9X9uOU7bwy+ezuO5152wvd2d6/7SURwFBNOryGzkyp2TJhHZMW7KLq7ceMnbGesbOWA/AkgntiDAYGD9rI5nSJqNc8zEAtKhb8q2vVXSKV7ezK6W2AT9qrddHWdYRaAtc1lpXNS+bDBzWWs9SSlUDxmDqxTkEuGmtGyulEgE/A8Uw9Xxd1VpXVUp9DRTUWn//PjVF5+3s8UV03s4eX8TU7exxWWzczi6sLz5dA6JLTN3OHpdF1+3s8cXbbmePVz0+WutXBgK11hOBif9aFjW0bNNaZzXf5fULcNi8TQjQmn/RWs8CZkVf1UIIIYSIK2wh9n5nnsB8GvDAdJeXEEIIIWxQvOrx+Rha6/HAeGvXIYQQQgjrs4UeHyGEEEIIQIKPEEIIIWyIBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmOFi7gP8CB3tl7RJilVK21V6Ap8ER1i4h1nk4J7B2CbFOa23tEmKfDR7PkZG29z7b29ne+/wm0uMjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJvhYO0CxOuFhkVQtfXPhIUbMBgjqV4+L71bVaHyd+MJCg4D4OGTQPJnT8u8sa0sj/M/c50vWoxj2rCvqVE+n7XKj3b/W7CVuSv2glJkz5iCXwY0IaFTAmuX9VFCwyKo33EyYREGjEYjlUrnocu3leg6cgEHjl3GzTUhAGN7NSJHppRs3H2ScdPXoewUDvZ2DPi+Fp/lTg/A3/ee0Gv0Im7fD0ApxcwfW5E6eWJrNu+D3Lr7hLaD5vDgcSAKaF6rOG0alrWsnzxvC/0n/MmlTaNI4ulqvUI/0ZuO5xd6jV3K/NX7uLnjJwAWrNnPwIkrSe7jAUDLeqVoVrOYVWr/GG9q79Q/dvDrou1cvfWQixtHWt7TiXM3s3T9YQAMxkguXLvLxQ0j8fJwsWYzPorRGEn5r8eQ3MeDhePacP32Q1r2m8WTp8/JkzU1UwY1wzGB6dK7YrM/P05dh1KQM1NKfh/6tXWL/0C37j2h3aC53I96/DYow8kLt+gyajFhYRE42NsxpudXFMjhB8DuIxfpM24ZEQYjSTxdWfNbp1ivO84FH6WUETgJJAAMwBxgvNY6UilVEGimte4YwzX4AcW01gti8nnexsnRgRX/64irsxMRBiOVvhvP50Wzs3bqD5ZtmvWcRuVSuSzfG42RDJ60krKFs1qj5Bhz+34Avy3ewf7FfUmU0JFvek9n+cYjNKpWxNqlfRQnRwcWjG+Hi/m9rfv9RMoUzgZAn7bVqFwm70vbF8+fmQrFc6KU4uzl27QfNJutc3sD0GXEfL5vUoGSn2XheXAYdnYqtpvzSRwc7BjWuTZ5sqYm8HkoZZv9SJnCWcmaPjm37j5h24GzpPL1snaZn+xNx/NnudJx9MwNAgKDX3lMrQr5GN39KytU++ne1N7CedLzRYmcVGs78aXtOzb9nI5NPwdg/a6TTFmwLV6GHoDfFm8ns18yAp+HAjB48iraNihL7YoF6DpqEfNW7ePbOiW5fOM+P8/exLqpP+Dp7syDx4FWrvzDOdjbMbRTLcvxW67ZaMoUysLASSvp0fJLKhTLwaY9pxk0aSWrf+3E08Bguo3+g6UT2pLKN7HV2hwXh7pCtNZ5tdY5gApAJWAggNb6cEyHHjM/oFEsPM8bKaVwdXYCIMJgxGAwotQ/F7VnQSHsOnyByqVzW5b9/scOqpXLi49X/P1k/CYGg5HQsAgMBiPBoeH4mj8Jx0dKKVzM763hNe/tv7k4O1nWB4eE82LLi9fuYjRGUvKzLJbtEiV0jNHao5uvtwd5sqYGwM0lIZn9fLnzIACAvuOXMahDzbe+NvHFm45nozGSgZNWMKhDDStXGL3e1N7cWVKTJkWStz522YYj1P6iQGyUGe3+vveEjXtO06RGUQC01uw6fIHq5fIC0KBKYdbuOAHA3JV7aVG3JJ7uzgD4JHazSs2f4pXjN50vdx48RYEl+D0LCsHX23S+XrrhMNXK5CGVr6lX2lptjovBx0JrfR9oBXyvTMoopdYAKKVKK6WOmf8dVUq5KaXslFL/U0qdU0ptUkqtVUrVNW9/TSnlbf66oFJq+5v2A4wCSpqX/fDa4mKB0RhJqcajyPJFb8oUykrBnH6WdWt3nKDUZ1lwd00EmHpF/tp+gm/rlLBStTEnRVJPOjQpT65q/claqS/uLokoVySbtcv6JEZjJJVajKFAzf6UKJiFfNnTAjB22lq+/GY0Qyb/SVi4wbL9+p0nKNd0JN/2msrong0BuHLzAe6uiWjdbwaVW4xlxJRVGI2RVmlPdLhx+xEnzt+iQA4/1u44QXIfT3JlTmXtsqLN647nqUt28mXJnJYLQ1Srtx6nRKORNO81nVv3nlih4k/ztvPXmwSHhrNl/1mql80b4/XFhL7jlzPo+xrYKdOl9fHT53i4JcLBwR4wncvuPHgKwKUb97l84z6VvhtHxW9/Ysu+M1arOzr8c/ymZUSXOgycuJKcVfszYOIKBrSvDsClGw8ICAymWpsJlG02mkV/HbBKrXE6+ABora8A9kDSf63qBrTXWucFSgIhQG1MvTXZgaZA0fd4itftpxewy9zzNP7TW/Fx7O3t2Dm/F6fWDMX/zHXOXL5tWbds4xHqVPznU1GfccsY+H117Ozi/Fv6wQKeBbN250mOrRzM2XXDCQ4NZ/Hag9Yu65PY29uxbnp39i0ZxPGzNzh/5Q49W1Vhy9zerPytCwHPgvl1wRbL9l+Wys3Wub35ffi3jJuxFgCj0cihE1fo2646q377gRu3H7F0ffx8XYKCw2jWcxoju9TBwcGecTM30LtNlXc/MB759/G81/8SK7ccpdVXpV/Z9ssSuTi2chC7F/SmbKEstB801woVf5q3nb/eZP2ukxTOnT5eDnNt2H0K78Su5M2W5r22NxojuXzzAaumdGLqsOZ0HrGQp68Z8owPgoLDaN5rOiO61MbdNREzl+1m+A+1ObVmKMM616bjsPmA6Zx17NxNFo1vw9KJ7Rg7YwOXrt+P9Xrj81VyDzBOKdUR8NRaG4ASwBKtdaTW+i6w7SP381ZKqVZKqcNKqcMPHz74lDa8Fw83Z0oUyMSWfWcBeBQQhP/p61QsnsOyzbGzN2jZbxZ5agxk1dZjdB/9B39tPx7jtcWG7QfPkTZFEry93EjgYE+1snk4eOKqtcuKFh5uiSiaLyM7Dp4jaRIPlFI4OTpQr1Jhjp+78cr2hfNk4MbtRzwOCMLXx5NsGVOSJoU3Dg72VCyRk1MXblmhFZ8mwmCkec+p1PuyINXK5eXqrQdcv/2Iko1Gkrv6AG7fD6B0kx+59/CZtUuNFi+O511HLnD15gMK1BlCnhoDCQ6NoEDtwQAk9nTBydE0eb9pjWIcO3fTmiV/kn+fv97mz43+L32gi08OHL/C+p2nyFtzIN/1m8muwxfoM24ZTwNDMBiMgKln/sWE9RRJPfmyZC4SONiTNoU3GdIk5fLNmL+eRDfT8TuNul8UpJq5p27hXweoVjYPADU/z8eRM6ZzWYqknpQrkhWXRE4k8XSlaN4MnLr4d6zXHOeDj1IqPWAEXoqFWutRQEsgEbBHKfWuGb0G/mlvwk/YD1rr37XWBbXWBb29fd67LR/i4ZNAS/oPCQ1n+4FzZE6bDIBVW47xRYmcL93VdGzlYI6b/1Uvl5cxPb6iSpk8MVJbbEvlm5jDJ68SHBqO1podh86TJV0ya5f10R4FBPE0MASA0LBwdh8+T4Y0Sbn/yNQFrrVm4+6TZE7nC8C1Ww/QWgNw6sJNwiOMeHm4kCdrGp4FhfAoIAiAvf6XyOTna4UWfTytNR2Gziezny/tG5cHIEfGlFzcOIoTq4ZwYtUQUiT1ZMe8niTzdrdytR/vdcdz3qxpOLd+hOW4dU6YgCPLBwJw9+FTy2PX7fznZyG+eNv5602eBYWw5+glKpXO9dbt4qoB7atzas1Qjq0YzNRh31CyYGZ+G9KcEgUysWrrMQAW/XWASuYbUiqXzs0e/4uA6Zxw+cZ9/FJ6W6v8j6K1puPQ+WRO50v7xuUsy319PNjjfwmAnYcukCG16TpZqVRuDhy7YpmreeT0dTJb4Vwe5+7qikop5QP8CkzWWuuokxyVUhm01ieBk0qpz4CsmHpvmiulZgM+QBngxZ1Z14ACwDqgzjv2cxOw6kyzew+f0W7wPIyRkURGamp+no8vSuYEYPmmI3RqXsGa5cWqgjn9qF4+H2Wa/Ii9vR25s6Siea3i1i7ro91/9IyuIxYQGRlJpNZUKZOX8sVy0LDzLzwOeI5Gkz1jSoZ3qQfAup0nWL7hEA4O9iR0TMDkgc1QSmFvr+jbtjqNf/gfWkPOLKloUDV+3em2//gVFq89SPaMKSjZaCQA/dtXf6k387/gbcfz6/y+eAfrdp7Ewd4OLw8XfhnQOBar/XRvau9vi7czce4W7j96RslGI/m8WA4m9jPdR7Jm+3HKFjb1BvyXDPy+Bi37zWTEb2vIlTkVTaqbZmCUK5KNbQfOUbT+cOztFYM71CRxPBviO3D8CovXHSJ7xhSUajwKgP7tqjGhT0N6j1uGwWDEySkB43s3ACBLOl/KFc1GicajsFOKpjWKkj1DilivW734JBlXvOZ29rnAOPPt7GWAblrrqkqpSUBZIBI4DXwNRAD/wxR4bgIK+FFrvUkpVRKYDjwDtgMFtdZl3rCfSGADkASY9bZ5PvkLFNR79h+KvhcgHvgv3GXzoZ4GR1i7hFjn4Rw/f0/Sp4hr50MRM2zxbba103bxIp/hf+Twa1sd53p8tNb2b1m3HVNoQWvd4XXbKKW6aa2DlFJJgIOYQhRa611A5tfs87X7Acq9YbkQQggh4qk4F3yiwRqllCfgCAw1T3IWQgghhPjvBR+tdRlr1yCEEEKIuCnO39UlhBBCCBFdJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwHaxcQ32kN4YZIa5cRq5wS2Fu7hFjn4mR7bRa2wWDU1i4h1kVqW2yztSuIXW97i6XHRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2w8HaBYh/dB6+gE17TuPt5cqO+b0BGDNtHfNX7SOJlysAvVtX4fNiOQiPMND9x8UcP3cTOzvF0M61KZ4/EwAjf13DkvWHCAgM5sqWMVZrz4f6fsg8Nuw+hbeXG/sW9wXg294zuHj9HgBPg0LwcE3ErgW9uXH7EYW/GkbGNEkBKJjLj/G9G1qt9k/x2+LtzFu5D601TWoUpU2Dspy6+Dfdf1zM85AwUvsm5tchzXBzSWR5zK27jynecAQ9WlaifePyVqz+w73ufX7y9Dnf9pnBjTuPSZM8MTNHtsDT3ZmJczezZN0hAAzGSC5cu8uljaPw8nCxZhM+WGhYBFVb/0xYuAGDMZLq5fPSu1UVdhw8z8BJK4iM1Lg4O/HLgCakT+3DzGW7mbZ0J/Z2drg4OzG+dwOypk9u7Wa8U6dh89m09zTeXm7sNJ/DRv32F+t2ncTOTuHt5cqkfk3w9fEAYI//Rfr9vByDwUhiDxdWTulEaFgENdpOICzCgNEYSdWyeen5XWVrNuuNXnfOBpi2ZCezlu3Czt6Oz4tlZ0D7GvifuU73HxcDoLWmW4svqVw6DwBPA4PpMnIR56/cQSnF+D4NKZgrnVXa9C5/33tCp6HzePAkEIWiSY2itPyqDKu3HuWn6eu5eP0ea6d2IU+2NADcvPOI0o1Gkt58ri6QIy0/9qgPwMrN/kycsxGjUfN58Rz0a1c9VtqgtNax8kSxSSllBE5GWVRTa30tJp4rX/6CevueA9Gyr31HL+Hi7ESHIfNeCj4uzk60a1TupW1nLNvF8bM3mNCvMQ8eB9K466+sn94VOzs7jpy6RipfL4rWHxYjwccpgX207xNgj/8lXJ2daDNwjuWCGFW/8ctxd01Ej+8qceP2I+r/8Otrt4sJBmNkjOz37OXbtOo/mw0zuuLoYE/9zlMY07M+rQfMZlCHGhTPn4n5q/dx4/ZjereuYnncN72no5SiQI60MRZ8HOxjpkP4de/zgIkr8HJ35oevKzJ+1kYCAoMZ3KHmS49bt/MkUxZuY9WUjjFSF5guSDG13+ch4bg6OxFhMFLpu/GM7FKHdoPmMm9sK7Kk82X60p34n77OLwOb8iwoBHdXU9Bdt/Mk05fuYunEdjFSm8EYfW1+cQ77fsg8S/AJfB5iCe1T/9jB+at3GduzPk8Dg6nSajyLxrcllW9iHjwOxCex2yuvVbXWPzPsh9oUzBl9QSAymt7n152zdx+5yITZG5k3tjVOjg6WdgWHhuPoYI+Dgz33Hj6lXLPRHF81BAcHezoMnUeRPBloXL0o4REGQkLD8XBzjpYaX4iMprf53sOn3Hv0jNxZUhP0PJQvW4xlxsiWKAVKKXqO+YMB7Wu8FHyadf+dbfN6v7Sfx0+fU/Gb0WyY3p0kXq50GjqPupU+o2TBLNFSZ7kShTnqf1i9bt1/dagrRGudN8q/a5+yM6VUrPSMFc2XEU/39/thv3D1LiUKZAbAJ7Eb7q6JOHbuJgAFcvqRzNsjxuqMKcXzZ8TrDe3XWvPnZn/qfFEglquKWReu3SN/jrQ4J3TEwcGeYvkz8tf241y+cZ9i+TICUKZQVtZsO2Z5zNodJ0ibIglZ0/laqepP87r3ed2OEzSsWhiAhlULs3b7iVcet2zjYepUjJ/vv1IKV2cnACIMRgwGI0oplFIEPg8F4FlQqKUn5EXoAQgOCUO99vQd97zuHBa1pzJqW5ZtPEKVMnlI5ZsYMJ3H4NXXKsL8WsVFr2vv7D9306Hp5zg5mi4bL9r14hgHCA03WF6HZ0Eh7D92mUbVigDgmMAh2kNPdErm7UHuLKkBcHVJSMa0ybjzIIBMfr5kTJvsvfdz4/ZD0qfysYxmlPwsC2u3H4+Rmv/tvxp8XqGUKqCU2qGUOqKU2qCUSm5e/p1S6pBS6rhSaplSytm8fJZS6lel1AFgtDVrn7F0F2WbjqLz8AUEPAsGIEfGlGzYfQqDwcj12484cf4Wt+89sWaZMWrv0cskTeJGBnN3KcCN248o1XgUVVr9zN6jl6xY3cfLlj45+49d5vHT5wSHhrN57xn+vhdA1vS+rNtp6rRcteUof98PACAoOIxJczfTrUUlK1Yd/e4/DsTXHNaTJXHn/uPAl9YHh4azZd9ZqpfLa4XqoofRGEmpxqPI8kVvyhTKSsGcfkzo25D6naeQo2p/Fq87RKdmFSzbT1uyk/y1BjNw0kpGda1rxco/3Yhf15C3xgCWbTxiGba6cuM+Ac+CqdluIp9/PZrFaw9atjcaIynb7EeyV+5D6UJZKJDDz0qVf7grNx+w//hlKrUcR812Ezl65rplnf/pa5RqPJKyTUcxusdXODjYc+P2I5J4utJp+AI+bz6aLiMX8jwkzIoteH837zzi1MVb5H/H+3PjzmMqfD2a2u0ncuDYZQD8Uvpw+cZ9bt55hMFgZP3OE5bzXEz7rwafREqpY+Z/fyqlEgCTgLpa6wLADGC4edvlWuvPtNZ5gLNAiyj7SQUU01p3idXqo/i6dnEOLOnPltk9SJbEnUGTVgCmT8UpknrwRYufGPDzcgrm8sPe7r/6dr74tF/Q8n0yb3dOrh7Czvm9GP5Dbb7rN4tnQSFWrPDjZE7nS4emn1Ov4y/U7zyFnJlSYm+vmNC3MTOX7aJ889EEBYfhaP6kOGbaOlo3KGP5RPxfZOoJeXnZ+p0nKZw7fbyb2xOVvb0dO+f34tSaofifuc6Zy7eZsnAbi39uy+k1Q2lUtTD9fv7Tsn3LeqXw/3Mgg76vwU8zNlix8k/Xp01Vjq0cQp2KBZi+dBdgGj4+cf4m839qzeKf2zFu5gYu37gPmF6rbXN6cnzlEI6euc7Zy7etWf4HMRiMBDwLZu3UHxjwfQ1a9Z9lGULNn8OPnfN7s356VybO2UxoWAQGYyQnL9zi61rF2Ty7B84JHZk8d7OVW/Fuz4PDaNl3BkM61sbNJeEbt0uaxINDywexaVYPBnWoRbvBcwh8HoqnuzMju31FmwGzqdVuIqmTJ461a9h/dXJziNY674tvlFI5gZzAJnOXqT1wx7w6p1JqGOAJuAJRzzBLtNbGf+9cKdUKaAWQOnWaGCj/Hz6J3S1fN65RlKbdfgfAwcGeIZ1qW9ZVbTXeMnnsv8ZgMLJm23G2zelhWebkmAAnxwQA5M2WhnSpvLl84z75sqe1VpkfrUn1ojSpXhSAYVNWk8LHk0x+yVgysT0Al2/cZ9Pe0wAcOX2N1VuPMWTyKp4GhWBnp3ByTEDLeqWsVn90SJrYjbsPn+Lr7cHdh0/x8XJ7af3yTUf+M8OcHm7OlCiQic17z3Dq4m0K5vQDoHaF/NTtNOWV7WtXzE9X86TY+K7OFwVp1PU3en5XmRRJPfHycMElkRMuiZwomjcDpy/+/VKvroebM8XzZ2Lr/rNky5DCipW/vxRJPalcOg9KKfJnT4udUjwKeI63eUgHILOfLy6JnDh35Q4pknqS3MfT0mtStWxeJsXx4BNhMNKy7wxqVyxI5TJ53rqtk6ODZdgvd9bU+KX05sqN++TJloaKJXJSsUROAOat3ItdLAWf/24XwcsUcDrKnJ9cWuuK5nWzgO+11rmAwUDU6Pr8dTvTWv+utS6otS6YxNsnRgu/9/Cp5et1O05Y7uwIDg23dIfuOHgOB3t7ssTTOR/vsv3geTKlTUbKZF6WZQ+fBGI0Tzi+dushV24+wC+lt7VK/CQPzMM6t+4+5q/tx6nzRQHLssjISMbN3EDzWsUBWPNbZ/xXDMJ/xSBa1y9N5+YV4n3oAfiyVC4WrjHdJLBwzQEqlc5tWfc0KIQ9/peoHGVZfPPwSSBPA03D1CGh4Ww/cI4sfr48Cwrh0nVTL8e2A+fJ7GeaI/Gi5wNg457TZEgds+eZmHTl5j9tWb/rJBnTmoLNl6VycfD4FQwGI8Gh4fifuU4mv2SvvFY7DpmO//jiy1K52ON/ETC9jxEGI0k8Xbh+2zSkA3DzzmMu3bhH6uSJSZrEnZTJPLlkvnt11+ELZI7D53KtNV1HLiRT2mS0blD2nds/ehJkOVdf//shV28+IE3KJIDpuAAIeBbMrOW7aVStaMwVHsV/tcfn384DPkqpolrrfeahr8xa69OAG3DHvKwx8Le1imwzYDZ7j17icUAQ+WoMoHvLSuz1v8Spi3+jFKROnoQxPb4CTD8wDX/4FTul8PXxYNKAJpb9DPllJX9uPEJIaAT5agygUbWidG8Z9+eEtOg7kz1HLvIoIIgcVfrRq1VlmtYoxvKNr37a33v0EiN//QsHB3vs7BQ/9WoQb4dBvuk9nSdPn5PAwZ4fu9XDw82Z3xZvZ4Z5SKBKmTw0qlrEylVGn9e9zz80r8A3vWcwb9U+UvsmZubIby3b/7XtOGULZ8UlUfwd3rv38BntBs/DGBlJZKSm5uf5+KJkTn7u05DmvaZhpxSe7s5M6t8YgKlLdrLj4HkSONjj6e7MLwObWrkF76f1gFns8Tedw/JU70+PlpXZvO8Ml2/cRylFal8vxphvZc7s50vZItko03QUdnZ2NK5WhGwZUnD60t90GDIPY6RGa031cnktvQJxzevO2Q2rFuGH4Qso3XgkjgkcmNivMUopDh6/wqR5m0ngYI+dUozqWo8knqZeoOE/1KHd4LlERBhIm8Kbn/s2snLL3uzgiSssXX+IbBmS83lz0/TX3q2rEB5hoN/4ZTwKCKJp99/IkSkVC8e3Zf+xS4yZts5yrh7V/Su83E3n6v4/L+fMJdMl94dvvnypty8m/VdvZw/SWrv+a1leYCLggSnw/ay1nqqUagv0AB4ABwA3rfXXSqlZwBqt9dK3PVd03s4eX8TU7exxWUzdzh6XxdTt7HHZf/F8+C7ReTt7fBFdt7PHJ9F1O3t88bbb2f+TPT7/Dj3mZceAV8YEtNZTgFcG1rXWX8dEbUIIIYSwHtv7SCeEEEIImyXBRwghhBA2Q4KPEEIIIWzGG+f4KKUmAW+cDqW1jrk/mCOEEEIIEQPeNrn5cKxVIYQQQggRC94YfLTWs6N+r5Ry1loHx3xJQgghhBAx451zfJRSRZVSZ4Bz5u/zKKX+F+OVCSGEEEJEs/eZ3Pwz8AXwCEBrfZzX/D4cIYQQQoi47r3u6tJa3/zXolf+cKcQQgghRFz3Pr+5+aZSqhigzX/PqhNwNmbLEkIIIYSIfu/T49MGaA+kBG4Dec3fCyGEEELEK+/s8dFaP8T0V8uFEEIIIeK197mrK71SarVS6oFS6r5SaqVSKn1sFCeEEEIIEZ3eZ6hrAfAHkBxIASwBFsZkUUIIIYQQMeF9go+z1nqu1tpg/jcPSBjThQkhhBBCRLe3/a2uxOYv1ymlegGLMP3trvrA2lioTQghhBAiWr1tcvMRTEFHmb9vHWWdBnrHVFFCCCGEEDHhbX+rK11sFiKEEEIIEdPe5xcYopTKCWQnytwerfWcmCpKCCGEECImvDP4KKUGAmUwBZ+1QCVgNyDBRwghhBDxyvvc1VUXKA/c1Vp/A+QBPGK0KiGEEEKIGPA+wSdEax0JGJRS7sB9IHXMliWEEEIIEf3eZ47PYaWUJzAV051eQcC+mCxKCCGEECImvM/f6mpn/vJXpdR6wF1rfSJmyxJCCCGEiH5v+wWG+d+2TmvtHzMlCSGEEELEjLf1+Pz0lnUaKBfNtcRLGk2YIdLaZcSqBPbvMzXsv8VOqXdvJOK9IZsuWLuEWNe3fCZrlxDr7G3weA4MjrB2CbHKqPUb173tFxiWjZFqhBBCCCGsxPY+ugshhBDCZknwEUIIIYTNkOAjhBBCCJvxzuCjTJoopQaYv0+jlCoU86UJIYQQQkSv9+nx+R9QFGho/j4Q+CXGKhJCCCGEiCHv85ubC2ut8yuljgJorZ8opRxjuC4hhBBCiGj3Pj0+EUope0y/uwellA9gW7+4RgghhBD/Ce8TfCYCfwJJlVLDgd3AiBitSgghhBAiBrzP3+qar5Q6ApQHFFBTa302xisTQgghhIhm7ww+Sqk0QDCwOuoyrfWNmCxMCCGEECK6vc/k5r8wze9RQEIgHXAeyBGDdQkhhBBCRLv3GerKFfV7819tbxdjFQkhhBBCxJAP/s3NWmt/oHAM1CKEEEIIEaPeZ45Plyjf2gH5gdsxVpEQQgghRAx5nzk+blG+NmCa87MsZsoRQgghhIg5bw0+5l9c6Ka17hZL9QghhBBCxJg3zvFRSjlorY1A8VisRwghhBAixrytx+cgpvk8x5RSq4AlwPMXK7XWy2O4NiGEEEKIaPU+c3wSAo+Acvzz+3w0IMFHCCGEEPHK24JPUvMdXaf4J/C8oGO0KiGEEEKIGPC24GMPuPJy4HlBgo8QQggh4p23BZ87WushsVaJEEIIIUQMe9tvbn5dT48QQgghRLz1tuBTPtaqEEIIIYSIBW8c6tJaP47NQgSEhkXwVYfJhEcYMBiNVC6Thy7fVqL7qEWcPH8TrTXpUvvwU+9GuDg7MW/lHuYs34O9vcI5kRMju39FZj9fwiMM9Bm7hBPnbmJnpxjYsRZF82W0dvPem9EYSfmvx5Dcx4OF49rQfshc9vpfwt01EQCTBzQhV+ZUlu39z1zny5bjmDb0a6qXz2etsj9a3poDcXV2wt7ODnt7O7bO7sGTp89p0W8mN28/JnWKxMwY/i2e7s7sPnKRJt1/J22KJABULZOH7i0rWbkFH+/W3Se0HTSHB48DUUDzWsVp07AsAL8v3s60Jbuwt1NUKJGTIR1rWrXWdwkMCGTD0k0EBwWDUuT6LAf5iuVl76b9XDl7BZTC2TURFet8jqu7K+eOnefwziNowNEpAeWql8EnuQ+PHzxh7aL1lv0+e/KUIuWLkL94XgCO7TvO8f0nUHZ2pMviR8kv4+avWvt14TbmrdqHUopsGZIzsV9jOg9fwLFzN0ngYE++7Gn4qVcDEjjY8ywohLYD5/D3vScYjJG0a1yORlWLWLsJ79Rx2Hw27TmNt5cbuxb0BmDllqOMmbaOC9fusXFGV/JmSwPA9gPnGPq/VUQYjCRwsGdQh5qULJgZgPAIA73GLmWP/0Xs7BR9WlelWrm81mrWezEaI6nVdjzJvD2YOqIl+/wvMurX1UQYjOTMnIoR3b/Cwd6eA8cu0ab/TFL5JgagYslcdGhWkSs37tNp6FzL/m7eeUSnr7/km7qlYrz297md/aMopYK01q5Rvv8aKKi1/j6an2ct0EhrHRCd+7UGJ0cHFv7cDhdnJyIMRuq2n0iZwtkY0KEmbi4JARgyeQWzl++iXZPPqfF5AZrUMJ30Nu0+xbDJK5kztjULV+8HYOPsHjx8Ekjz7r+z+vcfsLP74L9JaxW/Ld5OZr9kBD4PtSwb3KHma0ON0RjJ4MkrKVsoa2yWGO1W/q8jSTwthwsT5myiVMHMdG5ekZ9nb+TnOZsY9H0NAIrmzcDCcW2sVWq0cnCwY1jn2uTJmprA56GUbfYjZQpn5cHjQNbuOMmuBb1wckzAg8eB1i71nezs7ChVqQRJUyYlPCycBb8sJk3GNBQomZ9iFUwX8aN7j3Ng6yHK1yyLu5c7db+rTcJECbl6/hqbV2yjYduvSOzjRZMODQGIjIxk2o8zyZg9PQA3r9zi8tkrNO7QCAcHe1PIioPu3A9g6h872L2wD4kSOtKi7wz+3ORPnS8LMmVwMwBaD5jNvJV7+aZOSaYv3UWWdL7M/6k1D58EUrT+cOp+URDHBDF2iYoWDaoUpkXdUnw/ZJ5lWbb0yZk1qgVdRy1+advEni7MH9saXx8Pzl6+zVedp3By9VAAxs/aiLeXKweW9CcyMpInz+Lm+xrV7OW7yJAmGUHBoURGRtLjx4XMGduWdKl9+Hnmev7ccJh6lU1/z7xgrnRMHdHypcenT5OU1VO7AqbzeImvhlCxRM5YqT1+XAnfQmtd+b8QegCUUrg4OwFgMBiJMBhRSllCj9aasLAIlDJNv3qxHCA4NNwyK+vitbsUy2/q4fH2csPdNREnzt2MxZZ8vL/vPWHjntM0qVH0vbaf+scOqpXNi3di13dvHI+s3XmSBlVMJ40GVQqzdscJK1cUM3y9PciTNTVg+nnO7OfLnQcBzFi2i87NK+DkmAAAn8Rub9tNnODi7kLSlEkBcHRyJLGPF0HPgnBK6GjZJiIiwnKcpkibnISJTMdw8jS+BD0NemWfNy/fwiOxB+5e7gCcOHCSz0oVwMHBHgBnV+eYbNInMRgjCQ2LwGAwEhIaga+POxWK5UAphVKK/NnTcvv+UwCUgqDgMLTWPA8Jx9PdGQf7uH95KpYvI17uL78HmdP5kjFtsle2zZ0lNb4+HgBkTZ+c0LAIwsIjAFiwej+dmlcATAE66oeguOjOgwC27z/DV+Zg8+RZMAkcHEiX2geA4gUys2Hn+5+z9vpfJE2KJKQ09wrFNKv8ZCmlqimlDiiljiqlNiulkpmXD1JKzVVK7VNKXVRKfWdeXkYptVMp9ZdS6rxS6lellJ153TWllLdSyk8pdVYpNVUpdVoptVEplci8TQal1Hql1BGl1C6lVFbz8npKqVNKqeNKqZ3mZTmUUgeVUseUUieUUpli87UxGiOp9O0Y8tfoT8mCWciXPS0A3UYupGDNAVy6cZ+v65S0bD97+W5KNhjGyCmrGdyxNgDZM6Zg057TGAxGbtx+xKkLN7l9PyA2m/HR+o5fzqDva2CnXv7RHPbrGko2Hknf8cssJ4vb9wP4a8cJvq1TwhqlRhsF1O34C+WajWb2n3sAePA4EF9v00kyWRL3l3o8Dp28SqnGI/mq8/84d+WONUqOETduP+LE+VsUyOHHpev32XfsMp9/PYYqrX7G//R1a5f3QZ4+ecaDOw/wTeULwJ6N+5g2eibnj52n6OevDuGcPnwGv8xpX1l+/sQFsuT+5xT05GEAf1+7zcIpf7Bk6jLu3roXc434BMmTetKucTny1hxIzqr9cHdJSNnC2SzrIwxG/lh3iHJFTcta1i3FhWt3yVm1P6Uaj2T4D3XiTQ/1x1i97Ri5M6fCyTEBTwNNvTujfvuLcs1G822fGdx/9MzKFb7d8F9W0qN1VezsTCk+sYcLRmMkJ8+bPmCv33mCOw8CLNsfO3Odai3H0qLXVC5evfvK/v7adpSq5WJvmkJM/mQlMoeHY0qpY0DUW+N3A0W01vmARUCPKOtyY/ot0UWBAUqpFOblhYAOQHYgA1D7Nc+ZCfhFa50DCADqmJf/DnTQWhcAugH/My8fAHyhtc4DVDcvawNM0FrnBQoCtz686R/P3t6OdTO6s3/pII6du8F584VtbO+GHFw+mIxpk7F661HL9s1rl2DXon70alOVSXM2AvBV5cIk9/GgWqtxDJm0gvw50mEfDz49bdh9Cu/ErpYx8Rf6t6vOgT/6sXlmN548C2binM0A9B2/jAHtq8f7E+Rfv//Atjk9WfxzW6Yv3cneo5deWm/6hGz6OneWVBxbOYSd83vzXb3SNO0+1QoVR7+g4DCa9ZzGyC51cHdNhMEYyZNnz9k0sxtDOtXkmz4z0Dp+/Pqw8LBw/lqwltJVSlp6e4pXLErLHt+QJW8Wju87/tL2N6/c4tSRM5T4sthLy40GI1fOXSVTrn+Cj46MJDQkjAZt6lHyy+KsXbQ+Tr4uAc+CWb/zJEeWD+TkmmEEh4azZN0hy/oeo/+gaL4MFM2bAYCtB86SM3MqTq0ZyrY5Pek9dgmBz0OsVX6MOnflDkN/WcXYXvUBU8/Y7fsBfJY7HVvn9OCznH4MmrTCukW+xdZ9Z0ji6UrOzKkty5RS/Ny/CSP+t5I6bX/GJZGT5bycPVMqti/sx+pp3WhaswRtB8x8aX/hEQa27j1NpdJ5Yq0NMXnFCNFa533xD1PIeCEVsEEpdRLoDuSIsm6l1jpEa/0Q2IYp8AAc1FpfMf/h1IXA6z7mX9VaHzN/fQTwU0q5AsWAJeYA9huQ3LzNHmCWuWfJ3rxsH9BHKdUTSKu1fuXoU0q1UkodVkodfvTw4Xu/IB/Cwy0RxfJlZPuBc5Zl9vZ2VC+Xj3WvGfaoXj4fG3efAsDBwZ4BHWqxbkZ3po1swbOgEEsXZFx24PgV1u88Rd6aA/mu30x2Hb5A64Gz8fX2QCmFk2MCGlUtgv8Z06f/Y2dv8F3/WeStOZDVW4/Rfcwf/LXj+DueJe5JkdQTMA3nVCmTB//T1/FJ7Mbdh6ZhgLsPn+LtZRrqcXdNhKt5OLRC8RxEGI08Cnh1iCQ+iTAYad5zKvW+LGiZ0JkyqSfVyuZFKUWBHH7YKRUv2mk0GlmzYB1Z82QhY45XbyjImicLl05ftnz/4O5DNv+5hepNqpDIOdFL2167cJ2kKXxwiTKc5erhSsYcGVBK4ZvaF6UgJDiUuGbHofOkSZEEby83EjjYU6VMHg6dvArAmGnreBQQxNBOtSzbL1xzgCpl8qCUIn1qH9KkSMLFa/etVX6MuX3/Cc17TmPygKakS2U6Jyf2cME5oSNVy5gu/NXL5+PE+Vj9vP1B/E9dZcve05RpOIzOQ+ex/+gluo6YT74cfiyc8D3LpnTms9zpLe1zc0mISyLTOatMkWwYDEYeRxnW3XnwHNkzpcI7FoezrfVReRIwWWudC2iN6e+BvfDvjy/6HcujCovytRHT5G07ICBqCNNaZwPQWrcB+gGpgSNKqSRa6wWYen9CgLVKqXL/fhKt9e9a64Ja64JJvL3fp73v5VFAEE8DTTkrNCycXYfPkyGND9duPXjxvGzac4oMaUzzCK7efGB57NZ9Z/BLZaolJDSc4BDTS7Hr0Hkc7O3I7OcbbXXGlAHtq3NqzVCOrRjM1GHfULJgZn4b3NwSALTWrN1xgqwZTLn16IrBHDP/q1YuL2O6f0WVWPzUEB2eh4RZJnE/Dwlj24FzZMuQnEolc7HorwMALPrrAJVL5QLg3qNnlk/4R05fIzJSk9jDxTrFRwOtNR2Gziezny/tG//zGzQql8nNrsMXALh0/R7hEYY4P+9Ba83m5VtInNSL/CX+6bZ/8jDA8vWVs1fw8vEC4FlAIGvmr+WLuhXx8vZ6ZX+mYa7MLy3LkC09t67cMu/3CUZjJImcE77yWGtLlcyLI6euERwajtaanYcvkMkvGXNX7mXbgbP8NqT5Sz21qZJ5sevQeQDuP3rGpRv3SZsyibXKjxFPA4Np1OU3+rerTuE86S3LlVJULJGTPf6mnt6dhy6QOV3cPV93+64Ku/8YwPaF/fi5fxOK5MvIT30a8+iJaTg+LNzA1EVbaVjNNE/zweN/zlnHz94gUmu83P85Z63ZGrvDXBCDd3W9gwfwt/nr5v9aV0MpNRJwAcoAvYDMQCGlVDrgOlAf0/DVO2mtnymlriql6mmtlyjTzODcWuvjSqkMWusDwAGlVCUgtVLKA7iitZ6olEqDaeht66c19/3cf/SMLiMWEGmMJFJrqpbNS7mi2an7/SSCnoeh0WTLkILhXesBpln1u49cIIGDPe5uzozr0wiAh0+CaNbtV9OnQh8PxvdrHBvlx5jWA2bzKCAIrSFn5pT81LOBtUuKNg8eB9Ksh2m4ymCMpM4XBSlfNDv5sqfl2z4zmL9qP6mSezFj+LcArNp6lJnLduNgb0dCJ0emDfvaMtk9Ptp//AqL1x4ke8YUlGw0EoD+7avTpHpRvh8yn6L1h+OYwJ4pg5rG+Xbevn6Hs8fO450sCfMmLQRMQ1ynj5zhyYMnphsVPN0oX8N0u/6BrQcJDQ5l66rtgGlSa6P2puGPiPAIbly6SfmaZV96jhwFsrNp+RbmTpiPnb09X9T5PE6+LgVy+lGtXF7KNx+Ng709uTKnpFnNYqQt253Uvl5U+m48AFXL5KZbi0p0/fZLOgydR6nGI9EaBrSrHueDLkCr/rPY43+JxwFB5K7Wnx7fVcbL3ZnePy3lUUAQjbr8Ro7MKVkyoR3Tluzi6q2HjJ2xnrEzTL+uYMmEdvgkdmNA++q0GzyXfuOXk8TLlYn9Glm5ZR9u6uLtbNt/Bh2paVi9GEXzm4Zo1+84wYJVe3Gwt8PJKQE/92ti+ZkNDgljz5ELDP2hbqzWqmJqfPhtt7MrpWoA44EnmELFZ1rrMkqpQUB6THN1vIHRWuupSqkymOYIBQIZMQ2BtdNaRyqlrmGai+MKrNFa5zQ/XzfAVWs9yByYpmAa4koALNJaD1FKLTc/lwK2AJ2BnkBTIAK4i+lW+Tf+TqO8+QvojTv2f+KrFb+4OsXtW0xF9HgxcdGWDN543tolxLq+5WP1/g1hJQHBEdYuIVZVLleME0ePvPYkFmNXsKihx/z9LGCW+euVwMo3PPSE1rrZa5Y/01pXfc3z+Jm/fAjkjLJ8bJSvrwJfvuaxr5sgPcr8TwghhBD/MfH7dhghhBBCiA8Qp8YstNaD3rB8O7A9NmsRQgghxH+P9PgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGQ7WLiC+09r0z5bYWHNtVliE0dolxLouJdNbu4RYd+52oLVLiHU5Urlbu4RYl8Detvo51FvW2dYrIYQQQgibJsFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgib4WDtAsQ/QsMiqN9xMmERBoxGI5VK56HLt5XoOnIBB45dxs01IQBjezUiR6aUlscdP3uD2u0nMGlAUyqXyQvAyF9Xs23/GQA6NKtItXL5Yr09H+ri9Xt813em5ftrfz+iV6vKPHn6nHW7TmKnFN5ebkwa0ITkPh48CwqhzcA5/H33MQZjJO0bl6dRtSJWbMHHeRoYTOfhCzl75TZKKSb2a8zW/WeZu3Iv3p6uAPRtW40KxXMA8POsjcxfvQ87OztGdq1LuSLZrFn+e+k8fAGb9pzG28uVHfN7A9Cq/ywu37gPwNPAEDzcErFldg8AJs7ZxILV+7G3t2NY59qUNbdx6/6z9P95OUZjJI2rFaFDswrWadA7hIZFUK/DZMIjDBiMRiqXyUPXbyvRcchcTpy/iYODPXmzpWFkt69I4GDPnxuPMGXBFrQGV2cnhnetS/aMKbl97wk/jFjAg8eBKAWNqhWlRb3S1m6excjJy9h7+DxeHi7MmdAJgG17TzJj8Vau33rA7z+2IWvGVIDp57z/mAWcu/Q3lcrm44fvqr+yv14j5nL73mPLvmYs2sLqzYfwdHcBoFXjihQtkCWWWvdhQsMiqNr6Z8LCDRiMkVQvn5feraqw4+B5Bk5aQWSkxsXZiV8GNCF9ah/6jFvG7iMXAQgJDefBkyCubR1t5Va825uuU/W+n0hQSBgAj54EkSdbGqYObwHAvqOXGDL5TwwGI14ervwx8XvAdNz3GrOI81fvooDRPRtSIKdfjLchTgQfpVRfoBFgBCKB1lrrA+/xOD9gjdY6Z8xWGDucHB1YML4dLs5ORBiM1P1+ImUKm074fdpWs4SaqIzGSEb9tpqSBf85GWzdd5rTF26xdlo3wiMMNOj0C2UKZ8PNJWFsNeWjZEqbjO3zegGmduWq2o8qZfLg6ZaI3m2qAvD74u2Mnb6On3o1YPrSnWRJ58uCn1rz8EkgRb4aRt0vC+KYIE78WL+3PuOWUa5oNmaOakF4hIGQ0HC27j9LmwZl+b5J+Ze2PX/lDn9uOsLuhX24+/Apdb7/hQNL+mNvH7c7b+tXLsS3dUvSYcg8y7Lfh35t+XrgxD9xd00EwPmrd1mx2Z8d83tz9+FTvur4C3sX9wOg99gl/DGhHcmTevJli5+oWDIXWdL5xmpb3oeTowOLfv7nWK7TfiJlC2ejZoUCTOjfBIAOQ+ayaM1+mtYsTurkiflj0vd4ujmzbf9Zeo35g1W//YC9vR392lUnV5bUBAWHUqXlOEp+loXMfnGjzZXK5qd2pSIMn7jUsixdmmQM79GIMb+ufGlbxwQOtGz4OVdu3OPqjXuv7GvH/tMkSuT4yvKvqhanYc2S0V98NHNydGDF/zrian7PK303ns+LZqfbj4uZN7YVWdL5Mn3pTn6asZ5fBjZlRJc6lsf+vngHJy7csmL17+9N16klkztatmnTfyYVipsuy08DQ+g/fimzx7QmZTIvHj4JtGw3eNJyShfKxpQh35jPfRGx0garny2VUkWBqkB+rXVu4HPgpnWrsg6lFC7OTgAYDEYMBiNKqbc+ZtbyXVQqnYckXq6WZRev3aNQngw4ONjjnMiJrBlSsOPA2RitPbrtPHQev1TepE6eGDfzBREgOCTc8pooFEHBoWiteR4Shpe7Mw5xPAD827OgEPYdvUST6kUB08XBw835jduv23mSWhUK4OSYgLQpvEmXyhv/M9djq9yPVjRfRjzdX98urTWrtx6jVoX8AGzYdZKan+fHydGBtCmSkC6VD0fPXOfomeukS+VD2pTeOCZwoObn+dmw62RsNuO9velYLlc0O0oplFLkzZaGOw8CACiYKx2e5vc9X4603HnwFIBk3h7kypIaAFfnhGRMm4y75nVxQd4c6XD/18+rX6qkpEnp88q2iRI6kjubH44JEryyLjgkjMWr9tCsbtkYqzWmKaVwNb/nEVHec6UUgc9DAXgWFIqvj8crj1228Qh1KhaI1Xo/1ruuU4HPQ9nrf5GKJXMBsGrzEb4slZuUybwA8PZyA0znvoPHr1C/SmHgxbkvEbEhLlwlkgMPtdZhAFrrh1rr20qpAUqpQ0qpU0qp35X5lVVKFVBKHVdKHQfav9iJUuprpdRypdR6pdRFpdToKOsqKqX2KaX8lVJLlFKu5uWjlFJnlFInlFJjzcvqmZ/zuFJqZ2y+EGDq6ajUYgwFavanRMEs5MueFoCx09by5TejGTL5T8LCDQDcfRDAhl0naVKj2Ev7yJYxBTsOniUkNJzHAUHsO3rRcoKNL/7c5E/tKCeC4VNWk7taf5ZuOEyvVpUBaFGvFBeu3iNHlX6UajSS4T/Uwc4uLvxIv7/rtx+RxMuVDkPnUbbpj3QavoDn5u7i6Ut3UqrxSDoOnU/As2AA7jwIIIX5BAKQIqknd+4HWKP0aLP/2GW8E7uRPnVSAO48eEqKpJ6W9cmTenDnwVPT8mRRlvt4WgJCXGQ0RvLlt2PIV+PlYxlMF8blGw5TulDWVx63eM0ByhZ+dfnNO485ffHWS/v5r5i2cDMNqhcnodOroWj5uv00/2EiIycvIzAoxArVvT+jMZJSjUeR5YvelCmUlYI5/ZjQtyH1O08hR9X+LF53iE7/Gp69eecxN24/olTBzFaq+sO96ToFsHHXSYoXyGQZYbhy6wFPA4Op32kyVb/7iWXrDwGmdifxdKXbqIVUbjGWnqMXEWw+98W0uHCV2AikVkpdUEr9Tyn1YgB7stb6M/MwViJMvUIAM4EOWus8r9lXXqA+kAuor5RKrZTyBvoBn2ut8wOHgS5KqSRALSCHuadpmHkfA4AvzPt/dRA6htnb27Fuenf2LRnE8bM3OH/lDj1bVWHL3N6s/K0LAc+C+XXBFgCGTFpBr9ZVX7nYl/osK2WLZKd2+wl0HDKX/Dn84lUgCI8wsH7XSapHmZfUt201TqweSt0vCjJtiSmPbtt/lpyZU3L6r2Fsm9uLXmOXxPkT478ZjJGcOH+Lb2qXZNvcnrgkdGTi7E18U7sEh5cNZPvcniTzdmfAhD+tXWqM+XOzP7U+z2/tMqKdvb0d62d058DSQRw/ZzqWX+g7bimF8mSgcJ4MLz1mr/9FFv+1n95tqr20/HlwGK37z2Rgh1pxfsj6Q128epvbdx9TqkiOV9bV/LIwi/7XlZk/fU8SLzcmz1prhQrfn729HTvn9+LUmqH4n7nOmcu3mbJwG4t/bsvpNUNpVLUw/X5++VhevvEI1cvljfPD1VG97jr1wqot/lQv/8/xbDRGcvLCLWaO+o45Y1ozac5Grty8j9Fo5NTFWzSpUZy107uRKKEjU8zXtphm9Vdaax0EFABaAQ+AxUqpr4GySqkDSqmTQDkgh1LKE/DUWr/oiZn7r91t0Vo/1VqHAmeAtEARIDuwRyl1DGhuXv4UCAWmK6VqA8HmfewBZimlvgPsX1ezUqqVUuqwUurw40cPP/k1eB0Pt0QUzZeRHQfPkTSJB0opnBwdqFepMMfP3QDgxPmbdBgyh+L1h7Bux3H6j19m6fr/vmkF1k3vzrxxbdEa0qd+tes5rtq89wy5s6QmaRL3V9bV/bIga7YdB2DBmv1ULZMHpRTpU/uQJkUSLl5/de5AXJYiqScpknpaJvRVK5eX4+dvkjSJO/b2dtjZ2dG0RjHLcFZyH09u33tiefzt+wEkj9I7Et8YDEbWbj9OjSjBJ7mPB7ej9GLduf+U5D4epuX3oix/EEDy1wwbxDUvjuXtB84BMH7meh4HBDHg+xovbXf28m16jF7MtJEt8PJwsSyPMBhp3X8mtSoUoFLp3LFae2w4df4m5y7/Tb3WY2jf53du3nlEh/7TAEjs6Wo5DqpV+IyzF+PHPBgPN2dKFMjE5r1nOHXxNgXNx3ftCvk5ePLqS9su3+RP7S/ixzDXv0W9TgE8Dgji+LkblC2S3bKNr48HpT7LgnMiJxJ7ulIoTwbOXrqNr48nvj4elt6iyqXzcCqW5jlZPfgAaK2NWuvtWuuBwPdAY+B/QF2tdS5gKvA+H3Oi9pMZMU3eVsAmrXVe87/sWusWWmsDUAhYiqk3ab25ljaYeohSA0fMPUP/rvd3rXVBrXXBxEm8P7bZr3gUEMTTQFOPRWhYOLsPnydDmqTcf/T0xfOycfdJMpsnc+5e3J89iwewZ/EAKpXOw9Af6vBFyVwYjZE8efocMJ1Mz125/dLk57hu+cYjLw1zvbjzB0xzXDKlTQZAKt/E7Dx8AYD7j55x6cZ90qaMvvcjNiRL4k7KpJ6WwLbz8AWypEvO3Yf/DOH8teM4WdMnB+DLUrn4c9MRwsIjuH77IVduPiB/PB762Hn4AhnTJntpaKtiiZys2OxPWLiB67cfceXWA/JlT0vebGm4cusB128/IjzCwIrN/lQsETfva/j3sbzr8HkypE3KwjX72XnwPJMHNn2pF/bve09o1W8mP/dtbBnyA9Mx3/3HRWRMm4zv6peJ7WbEilpfFmbF9F4s+a07v4xoRerkSZg0tCUADx8/s2y388AZ0qVJZq0y3+nhk0CeBpo+P4eEhrP9wDmy+PnyLCiES9dN57BtB86T2e+fNly4dpeAwGAK5UpnlZo/xpuuUwBrdxynXNHsLw1ZViyei8Mnr2IwGAkJDefY2etkTJuMpEncSeHjaTm/7/G/SKZYmrRv9dtflFJZgEit9UXzorzAeSA38NA8H6cusFRrHaCUClBKldBa78YUkN5lP/CLUiqj1vqSUsoFSAncBpy11muVUnuAK+Z6MpjvKDuglKqEKQA9ir4Wv9n9R8/oOmIBkZGRRGpNlTJ5KV8sBw07/8LjgOdoNNkzpmR4l3pv3U+EwUi9DpMAcHVJyPi+TXBweG3nVZzzPCSMHQfPMa53A8uyob+s4tKN+9jZKVL5JuannvUB6Prtl3QYMo+SjUagNQxoX4Mknq5v2nWcNbJbPdoMmE2EwUjaFEmY1L8JvX9ayqmLt1BKkTp5Yn7qZXo9sqZPTo3P81O8wQjs7e34sXu9eNFF3mbAbPYevcTjgCDy1RhA95aVaFStKCs2+1smNb+QNX1yqpfLR6lGI3BwsGdk17qWNo7oUoeGP0zBaIykYdUilkAY19x/9IwuIxZgNJqO5apl8/J5sRykK9uVlMm8qNl2AgBflspN56+/YMKsDTx5+px+4013R9nb2/HX1K4cOnmV5RsOkzV9cr78dgwAPb6rQrmi2d/43LFp0LjFHD11haeBwdRu+SPfNiiPu2sifp62hoBnz+kxfA4Z0yVn3IBvAKjXegzPQ8IwGIzsOnCWnwZ+Q7ooQe/fpszdwKWrd0BBch8vurWp8cZtre3ew2e0GzwPY2QkkZGamp/n44uSOfm5T0Oa95qGnVJ4ujszqf8/l63lG/2pXSH/O29iiUvedJ0CWL31KG0bvXwnaka/ZJQulJUvvx2DnZ2ifpUiZDEft4M61aHzsLlERBhJnSIJY3s1jJU2KK11rDzRGwtQqgAwCfAEDMAlTMNenYGGwF3gAnBdaz3IvP0MQGOaH1RZa53TPDxWUGv9vXm/a4CxWuvtSqlywI+Ak/lp+wGHgJWYepKUedvZSqnlQCbzsi1AZ/2WFylPvgJ644790fRqxA+uCa2el0UsMBgjrV1CrAs32F6brz8MfvdG/zE5Ur06jP5f9yzEYO0SYlXF0kU4fvTIaxOl1YNPfCfBR/xXSfCxDRJ8bIMEn3/E/T5yIYQQQohoIsFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2Q4KPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgib4WDtAuI7O6VwSmBb+dHeTlm7BBEL7O3srV1CrIswamuXEOuypXS3dgmx7vHzCGuXEOtcnWzreLZTb75O2dYVWwghhBA2TYKPEEIIIWyGBB8hhBBC2AwJPkIIIYSwGRJ8hBBCCGEzJPgIIYQQwmZI8BFCCCGEzZDgI4QQQgibIcFHCCGEEDZDgo8QQgghbIYEHyGEEELYDAk+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIQQQghhMyT4CCGEEMJmSPARQgghhM2Q4COEEEIImyHBRwghhBA2w8HaBYh//DB8AZv2nMbby5Xt83sDcOrCLXqO+YOwcAP29naM6laPfNnT8r/5W1i+8QgABoORi9fvcWrtcLzcXV67n/jg+yHz2LD7FN5ebuxb3PeldZPnbaH/hD+5tGkUSTxd2X3kAo26/k7aFEkAqFY2Lz2+q2SNsj/J69p88sItuo5aRFBwGGmSJ+H3oc1xd01EhMFIx2HzOX7uJkZjJPUrF6LLN19YuQUf7kPe5xf8T1+nYoufmD78G2qUzxfbJX+w2/ee0Hn4fB4+DkQpRaPqRWlRrzRnLv1N77F/8DwknNS+iZk4oCluLgkJjzDQa8wfnDh/EzulGNypFkXzZQKgSddfuf/oGUZjJIXypGfYD3Wxt4/7n1mfBgbTefhCzl65jVKKif0as3X/Weau3Iu3+b3t27YaFYrnsDzm1t3HFG8wnO4tK/N9k/LWKv2DGY2R1GwzHl9vD6aObEmPUQs5ePwybi4JAfixV0OyZ0xJYFAIXUbM5869JxiMkbSsX5a6lQoBkLl8V7KkSw5A8mRe/D68hdXa8zado1xfdpivL636z+LyjfsAPA0MwcMtEVtm97A85tbdx5RqPJJuLSrRrlE5/r73hA5D5/HAfHw0rV6U7+qXibU2xIngo5TqCzQCjEAk0FprfSAGnmct0EhrHRDd+44OX1UuxDd1S9JxyDzLsqG/rKLLt19Svmh2tuw9zdBfVrH8lw60a1yedo1NJ4aNu0/x+6LteLm7vHE/8UHDqkX47qvStBk456Xlt+4+YduBs6Ty9XppedF8GVg8vm1slhjtXtfmTsMWMLRTLYoXyMS8VfuYNHcLfdtWZcVmf8LCDexd1Jfg0HCKfDWMul8UJI05/MUXH/o+G42RDJq8krKFs8ZmmZ/E3t6O/u1rkCtLaoKCQ6nc4idKFsxC9x8X0a9dDYrmy8iiv/bz68KtdG9ZmQWr9wGweXZPHj4JpFm331gztQt2dnZMGfI1bi4J0VrTuv9M1mw7Ro3P81u5he/WZ9wyyhXNxsxRLQiPMBASGs7W/Wdp06DsG0NN/5//pHzR7LFc6aebtWwnGdMkJSg4zLKsZ5tqVCqd56Xt5q7YQ6a0yZg6oiWPAoKo2Gwk1T/Pj2MCBxI6JmD1tG6xXfoHq1+5EN/WLUmHKNeX34d+bfl64MQ/cXdN9NJjBk5cQbki/7yvDvZ2DOpQk9xZUhP0PJSK346lVKGsZEnnG+P1QxwY6lJKFQWqAvm11rmBz4Gb7/nY9wpuysROa105roYegKL5MuLl7vzSMqUUQc9DAXgWFIqvt/srj1ux6Qg1K/xzInzdfuKD4vlfX3ff8csY1KEmSikrVBWzXtfmSzfuUyx/RgDKFMrK6m3HANPPQnBIOAaDkdDQcBwT2Fs+UcYnH/o+/754B9XK5sHHyy22Svxkybw9yJUlNQCuzgnJ6JeMuw+fcvXmA4rkzQBAqYJZWLf9OAAXr92jeH5TD4+3lxvurok4fs50GnzxHhuMkUREGIkPh8GzoBD2Hb1Ek+pFAXBM4ICH29vPSWt3HCdNiiRkSZ88NkqMNnceBLB9/1m+qlLkndsqBUHBYWitCQ4Jw8PNGYd40HsXVdF8GfF8w/VFa83qrceoFeV6tG7HCdP7GiXUJPP2IPeL48MlIZnSJuPug4AYrTuquPCKJwceaq3DALTWD7XWt5VS15RS3gBKqYJKqe3mrwcppeYqpfYAc5VSXyulViqltiulLiqlBpq381NKnVdKzQFOAalf7FMp5aKU+kspdVwpdUopVd/8mAJKqR1KqSNKqQ1KKasfgUM612LILyspUHMgQyavpHebai+tDw4NZ9v+c1Qpm+cNe4jf1u44QXIfT3JlTvXKukMnr1Ki0UjqdvwfZy/fsUJ1MSNr+uSs3XECgJVb/Pn73hMAapTPh3MiR7JW6kuuagP4vnF5vDxcrFlqtHnT+3z7fgBrth+nRd2SVqrs092884jTF26RL3taMqfzZcOukwCs2XaM2/cDAMieMQWb9pzCYDBy4/YjTl64yR3zOoDGXaaQr1o/XJydqFImb+w34gNdv/2IJF6udBg6j7JNf6TT8AU8DzH1hkxfupNSjUfSceh8Ap4FA6YwMHHOZrq3jH/D1cMmr6Bn66oou5cT6bjpa6nSYgzDfllBWLgBgKa1SnD5xj2K1R1ElW/H0P/7WtjZmS7DYeEGarYeR512P7Np98lYb0d02H/sMt6J3UifOikAz4PDmDxvC92+/fKNj7lx5xGnLt4ifw6/WKoybgSfjZhCyQWl1P+UUqXf4zHZgc+11g3N3xcC6gC5gXpKqYLm5ZmA/2mtc2itr0d5/JfAba11Hq11TmC9UioBMAmoq7UuAMwAhr/uyZVSrZRSh5VShx8+fPCh7f0gc5bvYXDHWhxZMZjBnWrRdeTCl9Zv2n2Kz3Knswxz/ZcEh4YzbuYGerep8sq63FlSc2LVUHYv6E2r+qVp0v13K1QYMyYPaMz0pbso0/RHgoLDSJDAHoAjp69hb2fH2XXDObZyML/M38q1Ww+tXO2ne9v73GfcMgZ1qGG5OMQ3z4PDaN1vJoM61sLNJSFjezVkzoo9VG4xluch/7y39SsXxtfHkyrf/cSgSX9SIGc67KJcSOePa8vhFUMIjzCwx/+itZrz3gzGSE6cv8U3tUuybW5PXBI6MnH2Jr6pXYLDywayfW5Pknm7M2DCnwCMnrqWNg3L4ursZOXKP8zWfadJ4ulKTnPvxQvdvqvCxtm9WD7lB54+C+b3hVsA2HXoPNkypmTv0kGsmtaVwROXE2ju0d+xqB8rfuvC+H5NGTZ5Bdf/jn/H9p+b/akVZRh2zPR1tGpQBpc3vK/Pg8No2WcGQzrVjtXea6vP8dFaBymlCgAlgbLAYqVUr3c8bJXWOiTK95u01o8AlFLLgRLACuC61nr/ax5/EvhJKfUjsEZrvUsplRPICWwyd7XbA6/tRtBa/w78DpAvf0H9fi39OH+sO8jQH2oDUK1c3leCz4rN/i8Nc/2XXL31gOu3H1Gy0UjA9Om/dJMf2TKrO8miDPlVLJ6Dbj8u5lFA0EsTYuOrzH6+LJ/8PQCXrt9j4+7TACxdf5jyxbKTwMEen8RuFM6TnqNnb+CXytua5X6yt73PR8/eoEXfmQA8Dghi097TONjbUaVM3O/hjDAYadVvBjUrFLDM9ciYNhkLxpnmpV25cZ8t+84A4OBgz6COtSyPrdn2Z8un5hcSOiWgYomcbNx9klKfZYmlVnycFEk9SZHUkwI5/QDTuWvCnE0kTfLPcdu0RjEadf0NAP/T11i97RiDJ6/kaWAIdnaKhE4OtKz3Pp+DrefIqats2XuaHQfOEhZuICg4lC7D5zGubxMAnBwdqFOpENMXbwdg2bqDtG5UHqUUfil9SJU8MVdu3CNPtrT4+ngCkCZFEgrnzciZS3+TNmX8ObYNBiNrtx9n48zulmVHz1xnzbbjDP1lFc+CQrBTCidHB1rULUWEwUiLPjOoXbFgrB/PVg8+AFprI7Ad2K6UOgk0Bwz80yP17yj4/N+7eMP3/97uxfNdUErlByoDw5RSW4A/gdNa66If1YgYkszbg31HL1EsfyZ2H7lAutQ+lnXPgkLYf/QyvwxsasUKY06OjCm5uHGU5fvc1QewbU4Pkni6cu/hM5ImcUMpxZHT14iM1CT+jwz7PHgciE9iNyIjIxk7YwPf1CkBQCrfxOw6dJ4GlQvxPCSMw6eu0aZhWStX++ne9j4fXznYsrzdoLl8UTJnvAg9Wmu6j1pIJr9ktGrwz3v08Ekg3l6m93binI00qVEMgJDQcLTWOCdyYueh89jb25E5nS/Pg8MICg4lmbcHBoORLfvOUDh3Bms1670lS+JOyqSeXLx+j0xpk7Hz8AWypEvO3YdP8fX2AOCvHcfJap7Ps+b3HyyP/XHqWlwSOcX50APQ/buqdP+uKgD7j11i+uLtjOvbhPuPnpE0iTtaazbvPkkm8/yWFMm82Ot/gc9yp+fh40Cu3rxP6hRJeBoYTEInR5wcHXj8NIgjp67yXYP4dWzvPHyBjGmTkSKpp2XZyimdLF+PmbYOF2cnWtQthdaaH0aYjg9rnMOsHnyUUlmASK31i/7bvMB1IBFQAFiHaRjrbSoopRIDIUBN4Nt3PGcK4LHWep5SKgBoCYwCfJRSRbXW+8xDX5m11qc/qmEfoe2A2ew9eonHAUHkrzGAbi0rMbZXffr/vByjMRInxwSM6dnAsv26HScoXSgLzomc3rmfRtXiVJ57rRZ9Z7LnyEUeBQSRo0o/erWqTFPzheHfVm49ysylu7B3sCeRUwKmD/8mXk5+fl2bnweHMW3pTgCqlslL42qmSZMt65Xi+yHzKPrVMDTQqFoRcmZKacXqP86HvM/x1aGTV1m24TBZ0yfni29GA9CzVVWu3nrA7OW7AahUOjf1KxcGTIGoSddfsbNT+Hp7MqGfqccgODScb3tPIzzcQKTWFMuXyRKW4rqR3erRZsBsIgxG0qZIwqT+Tej901JOXbyFUorUyRPzU68G795RPNRl+DweBwShNWTLmIKhXeoB0L5pBXr8uJDK345Ga+jeqiqJPVzxP3WVfuOWYKcUkVrTumE5MvnFzh1OH6pNlOtLvhoD6G6+vqzY7P/SpOa3OXjiCkvXHyJbhuSUb246Pnq3rsLnxXK845HRQ2kdoyM17y7ANMw1CfDE1MtzCWgFZAOmA88w9QYV1FqXUUoNAoK01mPNj/8aU9jxAFIB87TWg5VSfpiGsXJGea5rQEFMgWoMplvnI4C2WuvDSqm8wETzvhyAn7XWU99Wf778BfW2PdF+532cltA8L0GI/5qgUIO1S4h1iRxt73gOCI6wdgmxztXJtt7nMsULc9T/8Gs/DVu9x0drfQR43UeYXUDm12w/6DXb3tJa1/zXdtcwzdmJuszP/OUG879/7/sYUOqdRQshhBAiXoqft0oIIYQQQnwEq/f4fCqt9SxglpXLEEIIIUQ8ID0+QgghhLAZEnyEEEIIYTMk+AghhBDCZkjwEUIIIYTNkOAjhBBCCJshwUcIIYQQNkOCjxBCCCFshgQfIYQQQtgMCT5CCCGEsBkSfIT4f3v3HV5FtT18/LsSAgRCDTXSexOCdJEqoFTFBiqWKwhYQHlFvderiA3xCoqKXBuKIHpFqSLSpfdeQu9KCR0jJW2/f+ydcEgjlOSE36zP8+TJnH3mzOw17azZs8+MUkopz9DERymllFKeoYmPUkoppTxDEx+llFJKeYYmPkoppZTyDE18lFJKKeUZmvgopZRSyjM08VFKKaWUZ2jio5RSSinP0MRHKaWUUp6hiY9SSimlPEMTH6WUUkp5hiY+SimllPIMTXyUUkop5RnZ/F2BG92RqPN8sGCXv6uRqV5sVsHfVch08cb4uwqZLlug986LPl68299VyHQ965f2dxUy3bnoOH9XIdNV6PKJv6uQqS7sOpLqe947simllFLKszTxUUoppZRnaOKjlFJKKc/QxEcppZRSnqGJj1JKKaU8QxMfpZRSSnmGJj5KKaWU8gxNfJRSSinlGZr4KKWUUsozNPFRSimllGdo4qOUUkopz9DERymllFKeoYmPUkoppTxDEx+llFJKeYYmPkoppZTyDE18lFJKKeUZmvgopZRSyjM08VFKKaWUZ2jio5RSSinP0MRHKaWUUp6hiY9SSimlPEMTH6WUUkp5hiY+SimllPIMTXyUUkop5Rma+CillFLKM7L5uwJedubUX0wbN5OzUWcBoVb9GtS5LZx50xaxa8seAgIDyF8wH23vb03O4BwARB46xsyJc4k+H42I8MizXYiPj+f7z35OnG7U6Siq1a5Cy45NmfvLAvbv/gOA2JhYzkadpe/A3v4IN0XPvT2WWUs2U6hAHhaM/RcAgz//ld8WbiQgQChUIIRPXu1GscL5Ej+zNmIf7Xp+yBdvPkbHlrUBeGP4ZGYv2Ux8vKFZ/cq80+9eRMQvMV3O8+98z6zFmylUIIT5LmaAr35awKjxCwkIDKDVrdUY8MxdAETs/JMX3xvHX2fPEyDC9JEvkDNHEJ2f+YTI42fImSMIgP99+BSFC+bxS0xX6vRfZ3n+nR/YsvsgIsLHrz5MvZvL8uW4+Yz8eQGBAQG0blydgX3u5qfpK/n0uzmJn9288yBzR7/EzZVK+DGC5K50f45Yu5UVC9Ykfv7o4WM82udBioYVZuGMJWxes5Xz5y7w/JtPJY6zcuEaNq7cjAQEkCt3MHfe14p8BfL6IdrUxcXF0/mpDylaKB9fDurB0jU7GPzZL8TExlGjUgkGvfgA2QIDMcbw1vBJzF++heCc2Xnvpa5Ur1SCPw+f4OkBo4g3htjYOB7pfBsPdbrV32GlaM+BSF56d2zi6z8On+DpR9rQqVUdXhw0loNHThBWtCBDXnmYvHly8evcNXw9bh4GyB2cg1f7dKZyuTAABnwwjvnLt1AwfwgTP3/BTxGlLSBA+H1YNw4d/4uub0zi03530LhGSc6cvQDA0x9OZ9Puo4nj165YlJlDH6L7e1OZsngHAMem9CNi3zEA/jj6Fw+9OQmAJzuE0/uuWygXVoDyD47gxJlzGRbHDZv4iEgJ4FOgGrblairwonsdZoyZ5sYbCEQZY4b4qaqpCggIoEX7JhS9qQjRF6IZ/cn/KF2xJKUrlKTpHbcSEBjA/N8Ws3zeKpq1bUx8XDy//jiD9g+0oUhYYc79fY6AwACyBWXj8eceSpzu6E9+oGL18gC07Ng0sXzN4vUcOXg0WT38qWv7BnS/vynPvvldYtkz3Vryz17tAfhy3HyGfD2dIS93AexB9a0RU2hev0ri+Cs27GbFht3MG/NPADr0HsaStTtpfEvFTIwk/bq0q88T9zWhj0/Mi1bvYMbCjcwZ/TI5smfj6Im/AIiNjeOZN8YwfMAjVK94EydO/01QtsDEz336+iOEVy2V6TFcq1c+GE/LRlX5ZnB3omNiOXc+moWrtvPbgg3M/+6f5MgelLgM7r+zHvffWQ+AiJ0HefSlL7Nc0gNXvj9Xq12FarXtdnz08DEmjp5K0bDCAJSvWpbajWrx1ZDRl8yjaFhhwp/tSlD2INYu28D83xbT6aG2mR5rWr6dsJDypYoSdfY88fHxvPTeD4we8hRlSxZm2DfTmThjFfe3a8D85VvZ9+cxZo/5F+u27GfAsPGMH/EchUPzMm54X3Jkz8bf5y7Q/on3uf3W6hQtlO/yM89kZUsW4acR/QB7bGrV7W1uv7UGI3/8nQbhFejepQUjf/ydkePm0a97O24qVpBv3u9N3jy5WLhyK298NJ7vP+oDQKfWdena8Vb+PeRHf4aUpt6dbmH7gePkyZU9sWzA1/MTkxpfAQHCwH805fc1ey8pPxcdS9M+Y5KNvyziINNX7Gbq4Aeue72T1S3D55ABxJ7KTwAmGWMqApWAEOAdIBxodx3nFXj5sa5OSN7cFL2pCADZc2QntHABos78TdlKpQkItKumeMli/HU6CoC9O/ZTuFghiriDY3DuYAICLl2FJ46e5GzUOUqUDUs2vy3rt1E1vFJGhXNVGtWuQP68uS4py5M7OHH47LkL+DbcfPXTfNo3r0WhAiGJZSLChegYomNiuRATS2xsXJZu+Ugp5m8nLqLPI63Ikd2eiyTUf96KrVQrH0b1ijcBUDBfbgIDb8jdNtGZqHMsXbuTbp0aAZA9KBv58uRi1IRFPPdoa3Jkty1YKa3DCTNX0bn1LZla3/S60v3Z15Z126la6+K+GVaqOCF5cycbr1T5kgS55ROWyrT86dDRU8xbFsED7RoAcPLMWYKyZaNsSXvMalynEjMWbABg9pJN3N26DiJC7Wql+SvqHJHHz5A9KFvifhAdHUu8Mf4J5gotX7eTksVDCStagN+XbqZTqzoAdGpVh7lLNgEQXq0MefPYfb9WlVJEHjud+Pm6N5cjX55cySecRYSFhtCmXllGz9iYrvF7dqzNL4t3cPT02XSNv3F3JAciz1xLFdPtRj2CtgTOG2O+ATDGxAH9gB7Af4AuIrJORLq48auJyDwR2S0ifRMmIiLdRGSFG/fzhCRHRKJEZKiIrAcaZUZAp0+c4cjBoxQvWfSS8k2rNlO2cmkAThw7iQj8NHIS3378A8vnr042na3rt1O5ZsVkl3lOnzzD6ZNnKFU+650pp2TQZ1MJv2sA42eu5uUnbR57KPIU0+Zv4B/33HbJuPVuLkvjWypxc8fXuLnDq7RoUJVKZYr5o9pXbfeBoyxbv4u2PT7g7qc/Zm3EvsRyEaHr8/+l9ePvM9znkg/Yy2a3P/YfPvhmBuYG+YLYd/A4oQVC6PPWd7R45D2ee+d7/j53gV37I1m6bhdtnhhCx94fscYtA1+TZq/lnjZ1/FDrK5Oe/dnX1g3bqVKr8hXNY+OqCMpVSj4tf3rn08m81KsDAQH2+FMwX27i4uLZuO0AANMXbODQ0VMAHDl2muJF8id+tljhfBxxicChyJN06DGEpl3fomfXFlmytSep6fPX0bZ5OAAnTkVRONRegixUMA8nTiVPUCfMWEnjule2zv1pUM8WvP7NgmSJ6KuP3sai4Y/yzpPNye5ao4uHhtChUQVGTluXbDo5s2dj7rCHmTn0Qdo1rJAZVU/mRk18qgOXfOsbY84Ae4G3gR+NMeHGmIQ2wyrAHUB94HURCRKRqkAXoLExJhyIAx524+cGlhtjahljFiWduYj0FJFVIrLq7OmT1xxM9IVoJo/9lZYdm5IjZ47E8qVzVyIBAVQLtztHfLzhz72HaN/1Dh7qfR87Nu9i384Dl0xr64btVE3hALp1/XYq1aiQrIUoq3qldwfWTX6Te9vUYeTPCwF4ddgEXnumU7IYdh84yo59h1k3+U3WT3mLhau3s2zdLn9U+6rFxsZx6sxZpn3ZjwHP3kXP10ZhjCE2Lp7lG3bz6cBHmPzZc/w2fwMLV20DYMTAR5j33T+ZPKIvy9ft4qfpK/0cRfrExsWzYdsf/OOeJvw+5mVy58zOx9/OIjYunlNnzjJj5Au80ecuerzy9SXJ3OpNewnOGUTV8slbM7OS9O7PCQ7uP0xQUBCFi4Wmex6b127l8B9HqNcs67R+zV0aQWj+EGpUKplYJiIMe60bg0ZM5t6nhpE7OEe6jkHFixRg6lf9mT3mX0ycsYpj7rJnVhUTE8u8ZRG0aVIz2XsiAklORFes38nEGSvp1/26XZzIUHfUK8ex02dZvzPykvI3Ry2ifq9vaPn8WAqE5OS5++0l6UE9mzPwm4WkdC5W8x9f0vL5sTz5/jTe7dmcMsUyP6m9Yfv4XKFfjTEXgAsiEgkUBW4H6gArXetIMJCwVuOA8alNzBjzBfAFQFilGtd0mh0XF8fk76ZRNbwylWpczH43rYpg19Y9dOnRObH1Jk++EEqUDSOXuxRUrnIZjvwZSekK9kATefAo8fGGYiWKJJvP1vXbaXV3i2upql/ce0ddHnrhc15+sh3rt+6n12vfAnD8dBRzlkYQGBjI7gNHqVO9DCG57JfM7Q2rsnLTHhqGl/dn1a9IWJH8tGtWCxHhlmqlCRDh+Km/CSucn4bh5QnNby/t3X5rNTZs+4MmdStTvHB+AEJy56RzmzqsjdjPA23r+zGK9Akrkp+wIvmpU6MMAB1bhvPR6FmEFclP++ZuGVQvQ0BAAMdPRVGogL3kNWHW6izf2nMl+3OCreu3X9El6L079rNs7kq69rqXbNmyziF8zaY9zFmymfnLt3AhOpaos+d5YdBYhr7yMD989CwAC1duY+8ftp9h0UL5OBR5KvHzh4+eTtayU7RQPiqWLcbKjbtp26xWpsVypRat2kbVCjcR6rbVgvlDOHr8DIVD83L0+BkK5rt42XL77kMMHPYzI97qTv4ULmdmRQ2qhXFng/K0rluWHNmzkSc4O5/3b0uvIb8BEB0bx9jZm+hzT10AalcoxsiXbT/NgnmDaV23HLFxhmnLdnLouG392nf4NIs2HqBm+SLsPXw65RlnkBvj9D+5CGzSkkhE8gKlgNgUxr/gMxyHTfgE+Na1DIUbYyobYwa6cc67y2cZyhjD9J/nEFqkIPWaXDxz27NtLysWrOaeRzskXs8HKFuxFEcPHycmOob4uHgO7PmT0KIFE9/fsn47VWolP4AejzzB+XMXCCt1Y1z+2X3g4lnF9IUbqVDaJnKrJgxk9UT717FFOO/1v592zWpSolgBlqzdSWxsHDGxcSxdu4tKpYumNvks6c6mN7N4je0guGt/JDGxcYTmz03zBlXYuusQZ89HExsbx9K1O6lUphixsXEcd83nMbFxzFq8mSrlboz1WzQ0LzcVyc+OfUcAWLBqO5XLFqdts5osWm2Xwc79kUTHxCYmfPHx8Uyes5bOrbNu4nOl+zOAiTds27iDKjXTl/gc+TOSmRPncs9jHckdkrX6g/R/sj2Lxg1g3g+vMuy1bjSsXYGhrzzM8ZO2teZCdCxf/m8uD3a0vQduv7U6k2atxhjD2oh95MmdkyKheTl09BTnL8QA9td/qzftoVzJ5CdzWclv8y5e5gJo3rAaU2bbixJTZq+mRaPqgL2E1++t0Qx6sStlShT2R1WvypvfLqLGY19Q64mv6P7eVBZu2E+vIb9RtMDFxK19wwps2XccgPDuX1HrCfs3ZfF2+o+YzbRlO8kXkiPxcljBvME0qHoT2/Yfz/R4ss7pwpWZAwwWkUeNMaNd35yhwCjgCNAgndOYLCIfGmMiRaQgkMcYk7xjQQb5c98hItZupVCxUEZ99D0ATe+4lTm/zCcuNo5xIycBEFaqGG06tyRnrpzUbVKbMcN/RATKVi5D+SplE6e3beMO7n28U7L5bHUJUVb8eXevAaNYvGYnJ05FUavTa7zUox2zl0awa38kIkLJYgV4/6UuaU6jY4twFq7aTrNugxGBFg2rckeTmzMpgivXe8C3LFlrY6591wBe7NGWBzs0pN8739Ps4XfJHpSNj199GBEhf95c9OranDu7D0WwLT6tG1fn73MXeLDff4mJjSMu3tC0biW6ZdGf/Kbk3f7303vAt8TExlE6LJRPXutGruDs9H17LLc9OIigoECGv94tcZtdsnYXNxUpQJmbCvm55qm70v0Z4MCeP8mTL4T8oZe2dMybtogt67YRExPDfweNpGa96jRu3ZB5vy0mJjqGyWOnAZA3fx7ueaxj5gV5Fb78cR6/L4vAxBse7HQrjdyvLZs3qMr85Vu4vdu7BOcMYvBLXQHYte8Igz/7BQEM0P2B5lQuV9x/AVzG2fPRLF2zg9f63pNY1r1LC/oPGsvEGSsoXqQAQ/7dDYDPxs7m1F9neWf4RAACAwP43yfPAfDSu2NZtWE3p878Tatu7/B0t9bcc2fWbsH94sV2FMoXjCBs3BPJ/xs+O83xK5cM5cNnWxEfbwgIEIb9vIJtB04AtjN03/vqUbRAbhYNf5RZq/bw3MczM6TecqN0iExKREoCI7D9dwKAaUB/bP+cGUAQ8C5QFZ+fs4vIJqCDMWav6/z8L/f5GOAZY8wyEYkyxoQknWdKwirVMD0+mXB9g8viXmzmnw5p/nSj/LLkesp2g/967Gq893vyn+X+X9ezftbqIJ0ZzkVneIN+llPz0f/6uwqZ6sKyYcSfPpDi2f6N2uKDMeYAkNKpzgWgXhqfq+Ez/COQ7KYJ6U16lFJKKXVj8d4pnVJKKaU8SxMfpZRSSnmGJj5KKaWU8gxNfJRSSinlGZr4KKWUUsozNPFRSimllGdo4qOUUkopz9DERymllFKeoYmPUkoppTxDEx+llFJKeYYmPkoppZTyDE18lFJKKeUZmvgopZRSyjM08VFKKaWUZ2jio5RSSinP0MRHKaWUUp6hiY9SSimlPEMTH6WUUkp5hiY+SimllPIMTXyUUkop5Rma+CillFLKMzTxUUoppZRnaOKjlFJKKc/QxEcppZRSnqGJj1JKKaU8Q4wx/q7DDU1EjgL7/DT7QsAxP83bX7wWs9fiBY3ZKzRmb/BXzKWNMYVTekMTnxuYiKwyxtT1dz0yk9di9lq8oDF7hcbsDVkxZr3UpZRSSinP0MRHKaWUUp6hic+N7Qt/V8APvBaz1+IFjdkrNGZvyHIxax8fpZRSSnmGtvgopZRSyjM08fEDETEiMtTndX8RGXiV08ovIk9f5Wf3ikihq/ns9SAid7tlUcVfdchIIhInIutEZLOIrBeRF0QkwL1XV0Q+zoQ6lBGRhzJ6Punls0wS/sr4u06XIyJRSV4/LiLDM2A+00Qk//We7vUkIv922/MGt/4apPNzZURkU0bXLyNcbcxXMZ8bYf2XEJHJIrJDRHaJyEcikl1EwkWknc94A0Wkvz/rmhZNfPzjAnDPdUo68gMpJj4iku06TD8jPQgscv8zjB+XwzljTLgxpjrQGmgLvA5gjFlljOmbCXUoA2SZxIeLyyThb++1TOwG2MbTzRjTzhhzyt/1SI2INAI6ALcYY2oCrYAD/q1VxrqWmNO7bYoVcAOsfwEmAJOMMRWBSkAI8A4QDrRL/dNXPK/A6zWtlGji4x+x2A5f/ZK+ISKFRWS8iKx0f41d+SUZtIhscmfLg4Hy7kzkfRFpLiILRWQKEOHGnSQiq91ZS8/MCPByRCQEuA3oDnR1Zc1FZJ6I/CwiW0VkrNvZEJF2rmy1iHwsIlNdeW4R+VpEVojIWhG5y5U/LiJTRGQuMMc/UV5kjIkEegLPugNdc58Ymvm0gKwVkTwiEiAiI1zMs9zZ4H1u/MSWOtdyNC+16WC3jyauLNn2lhWISB0Rme/W7QwRKe7Kn3T7wHq3T+Ry5aNE5DMRWQ78x8917ygiy93yni0iRV35QBEZIyJL3dnxk668uYgsEJFfRWSbiyOhFXCviBQS2zqyRUS+dPvsTBEJduOUF5HpblktFNdaKiL3u2PCehFZ4Mqqu/1indjWiorXGG5x4Jgx5gKAMeaYMeagiAxw62mTiHzhs8/WcfVZDzzjs8weF5EJLo4dIvIfn/fauGW2RkR+cscJRGSwiES4OIakFnMGSC3m1PbBhPW+GBjjYp0s9ri2Q0Red+OVcet/NLAJKOmz/nO77WO9i6+Lz/JMtp9kopbAeWPMN25ZxGG/w3pg98Mublvr4sav5uLeLSKJJ3ki0s1nu/xcXJIjIlEiMtRtL40yNBJjjP5l8h8QBeQF9gL5gP7AQPfe98BtbrgUsMUNDwT6+0xjE/Zsvgywyae8OfA3UNanrKD7H+w+F+pe7wUK+WkZPAyMdMNLgDqu7qeBEtikfCk2OcqJPcsq68b/AZjqhgcB3dxwfmA7kBt4HPgjIXZ/recUyk4BRV2sCTH8AjR2wyFANuA+YJpbDsWAk8B9SdcbUBeYl8Z0EueTFf6AOGCd+5sIBLn1X9i93wX42g2H+nzubaCPGx4FTAUC/VDndcB+YLh7rwAXfyTSAxjqhgcC690+V8htv2FufZwHygGBwKyk6xW7T8cC4a58nM82Pgeo6IYbAHPd8EbgpoT9wP3/BHjYDWcHgq9xOYS4+LcDI4BmrrygzzhjgI5ueAPQ1A2/jztOYffN3dhjX07sne9LutgXALndeC8DA4BQYJvPcs6fWswZsO5Ti3kvKe+DA4HVCcvaxXrIxZBw/K3r1nE80NBnXgnr/17gS5/yfKSxn2TivtsX+DCF8rXuveE+ZQNdfXO4mI67GKpij1NBbrwRwKNu2AAPZEYs/2eaiW80xpgzLtvvC5zzeasVNlNOeJ034aznCqwwxuzxed1XRDq74ZJAReyG6E8PAh+54f+511Oxdf8DQETWYQ8QUcBun5h+wLaeALQBOsnF1rCc2IQRYJYx5kQGxnC9LAY+EJGxwARjzB8ichvwkzEmHjgsIr9f5XQysNpX5ZwxJjzhhYjUAGoAs1xdA7FfFAA1RORtbEIbAszwmc5Pxp5xZoakdX4c++UFNkn/0Z19Zwd897vJxphzwDm3/upjE98Vxpjdblo/YJP7n5PMc48xZp0bXg2UcceBW4GffNZrDvd/MTBKRMZhL0eAPXH4t4iUwG4PO64qescYEyUidYAmQAsX9z+Bv0TkJSAXUBDYLCILsclIQkvMGOyl3gRzjDGn3TKIAEpj13M1YLGLL7uL4TQ2WRwptpV0ahoxX1dpxJyWKW69J5hljDkOICITsOt7ErDPGLMshc9vBIaKyHvYk5aFl9lPsqpfjW0puyAikdgTvtuxJ7krXRzBQKQbPw4YnxkV08THv4YBa4BvfMoCsGcB531HFJFYLr00mTON6f7t87nm2GSqkTHmrGuSTeuzGU5ECmKbTW8WEYPdiQ3wK7b/U4I4Lr+NCnCvMWZbknk0wGc5ZAUiUg4bUyT2zAcAY8xgEfkVe418sYjccZlJ+W4LievyKqaTFQiw2RiTUtP2KOBuY8x6l2w093kvq6zbT4APjDFT3L420Oe9pPcKMZcp95V0PwjGrvNTvklY4gSM6e22+fbAahGpY4z5XuzlwPbANBHpZYyZm66oUuGSzXnAPBHZCPQCagJ1jTEHxP5IIz3Hl5T2c8EmCcn6/IlIfeyX5n3As0DLVGK+7id0KcT8GKnsg07SbTO19Z3iNmyM2S4it2D347dFZA62dTS1/SSzRGCXfyIRyYs90YxNYfzU1vG3xph/pTD++cw6mdE+Pn7kWiPGYfu5JJgJ9El4ISLhbnAvcIsruwUo68r/AvKkMZt8wEmX9FQBGl6Pul+j+4AxxpjSxpgyxpiS2DPlJqmMvw0oJxd/AdTF570ZQB+RxH4FtTOoztdERAoDn2Gbg02S98obYzYaY94DVgJVsGez94rt65NwaSzBXuxZE9hm8bSmc7ntw9+2AYXFdiJFRIJEpLp7Lw9wSESCsJdGs6J8wJ9u+LEk790lIjlFJBS7/la68voiUlZs354u2A7+l2WMOQPsEZH7IbFTbC03XN4Ys9wYMwA4iu0zUg7bUvoxMBmboFw1Eaksl/YTCseuP4BjrkXqPlfXU8Ap13IJ6Vt/y4DGIlLBzS+3iFRy081njJmG7VOSaszXEl9KUol5H6nsg6loLSIFxfbTuhu7b6c1zzDgrDHmO+wlwltIez/JLHOAXCLyqKtDIDAUe4JyhPQdZ+YA94lIETeNgiJSOmOqmzpNfPxvKPYaaIK+QF2xnfgigN6ufDxQUEQ2Y894tgO4M5zFYjvBvZ/C9KcD2URkC7aja0pNq5ntQewZjK/xpPLrLtds/DQwXURWY7/MT7u338JeO97gls1bGVLjqxMs7ufswGxsUvtGCuM979bfBiAG+A27PP7AnmV9h20ZTIj5DeAjEVmFPZNKazobgDixHSWzXOdmY0w09svyPbGdGtdhL+cAvAYsx35RbPVLBS9vIPbS02qSP4F6A/A7dp97yxhz0JWvBIYDW7AJf9J9IS0PA93dstoM3OXK3xeRjWJ/Mr4E27/oAWCT2EvGNYDRVxZaMiHAt+I6GWMvSw0EvsT2XZnBxeQO4B/Ap27+l73maow5iu0T84Ob/lJs8p4HmOrKFgH/z30kpZivt9RiTm0fTMkK7P68ARhvjFl1mfFvBla45fY68PZl9pNM4U7YOgP3i8gO7HfQeeAV7HZeTS7t3JzSNCKAV4GZbnnOwnYgz1R652Z1QxCREHe9XYBPgR3GmA/9Xa+M5BNzKPbg2dgYc9jf9VKX5y75RBljhiQpb479kUIHP1RLZTJ3ibauMeZZf9dFXaR9fNSN4kkReQzb4XEt8Lmf65MZpoq9oVl2bIuBJj1KKXWNtMVHKaWUUp6hfXyUUkop5Rma+CillFLKMzTxUUoppZRnaOKjlPIbufi09k1in82U6xqmNUouPs/sKxGplsa4zUXkin8OLD7PaEpPeZJxotJ6P4XxL3k+n1Lq+tDERynlTwlPa68BRHPxvlXA1T993RjTw90zJDXNyeT7oCilsgZNfJRSWcVCoIJrjVkoIlOACBEJFJH3xT4BfIOI9ILEOxcPF/uU69lAkYQJiX0qdF03fKfYp32vF5E5Yu8A3hvo51qbmohIYbFPgF/p/hq7z4aKfTr6ZhH5inTciE9EJol9gvZmEemZ5L0PXfkcsXfzTvWJ60qpjKH38VFK+Z1r2WmLvdM42Nv01zDG7HHJw2ljTD0RyYG9U/lMoDZQGXs33aLYu1x/nWS6hbF3Fm7qplXQGHNCRD7D5waDIvI99snTi0SkFPYuxFWxd85dZIx5U0Tac+njZVLzhJtHMPZhjOPdHdZzA6uMMf1EZICb9rPAF0BvY8wOsc+eGoF9lp1SKgNo4qOU8qdgd2t+sC0+I7GXoFYYYxKedN4GqJnQfwf7fKyKQFPgB/dgw4MiktIDOBsCCxKm5Z6Pl5JW2FvuJ7zOK/YZUU2Be9xnfxWRk+mIqa+IdHbDJV1djwPxwI+u/DtggqT9xHWlVAbQxEcp5U/nkj5t3CUAvk+uFqCPMWZGkvHaXcd6BAANjTHnU6hLurlHUrQCGrkHA88j9aeVG9J44rpSKmNoHx+lVFY3A3hK7FPaEfvE7tzAAqCL6wNUHGiRwmeXAU1FpKz7bEFXnvSp9TOBPgkvRCTcDS4AHnJlbYECl6lrPuCkS3qqYFucEgTgnl7uprkorSeuK6UyhiY+Sqms7its/501Yp/E/Tm2tXoisMO9Nxr7NO9LuCd+98ReVlrPxUtNvwCdEzo3A32Buq7zdAQXf132BjZx2oy95LX/MnWdDmQTkS3AYGzileBvoL6LoSXwpitP7YnrSqkMoM/qUkoppZRnaIuPUkoppTxDEx+llFJKeYYmPkoppZTyDE18lFJKKeUZmvgopZRSyjM08VFKKaWUZ2jio5RSSinP0MRHKaWUUp7x/wE7S2/0wB3jBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=['Neutral','Anger','Disgust','Fear','Happiness','Sadness','Surprise','Other']\n",
    "IC = type('IdentityClassifier', (), {\"predict\": lambda i : i, \"_estimator_type\": \"classifier\"})\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "def plt_conf_matrix(y_true,y_pred,labels):\n",
    "    print(y_pred.shape,y_true.shape, (y_pred==y_true).mean())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_confusion_matrix(IC, y_pred,y_true,display_labels=labels,cmap=plt.cm.Blues,ax=ax,colorbar=False,values_format='d') #,normalize='true'\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plt_conf_matrix(y_val,y_pred,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enet_b0_8_best_vgaf\n",
    "aligned\n",
    "112\n",
    "Acc: 0.36997808749986594 F1: 0.21352704404593095\n",
    "(0.21352704404593095, 0.36997808749986594, [0.45700583162587527, 0.07635619242579324, 0.003076194983435873, 0.009468317552804079, 0.34928095010272137, 0.21187660892709106, 0.1647308567096285, 0.4364214000400981])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.20843684874655494 F1: 0.0910746772554131\n",
    "\n",
    "\n",
    "224\n",
    "Acc: 0.47395701146384794 F1: 0.3045351324629094\n",
    "(0.3045351324629094, 0.47395701146384794, [0.5518323928131282, 0.11104639875752281, 0.028970239662891757, 0.029782898346265387, 0.42825757737346165, 0.5113845517526626, 0.2515561703388993, 0.5234508306584433])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.42862351608048643 F1: 0.3395506137533413\n",
    "\n",
    "\n",
    "cropped\n",
    "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.500285172458044 F1: 0.3807067519117502\n",
    "(0.3807067519117502, 0.500285172458044, [0.608643679809698, 0.15128569174948728, 0.5162256615077384, 0.01599360255897641, 0.4778312968664514, 0.4611138100075078, 0.3029224246739377, 0.5116378481202044])\n",
    "\n",
    "\n",
    "enet_b0_8_va_mtl\n",
    "aligned\n",
    "112\n",
    "Acc: 0.36310406828978836 F1: 0.21416588541497295\n",
    "(0.21416588541497295, 0.36310406828978836, [0.5104795189391993, 0.1258546760922471, 0.010939722131057872, 0.009548019096038193, 0.33523095946425735, 0.18541315145321896, 0.19094959313671342, 0.3449114430070513])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.17444566379147022 F1: 0.09599142979803564\n",
    "\n",
    "\n",
    "224\n",
    "\n",
    "\n",
    "cropped\n",
    "Acc: 0.44668344431294826 F1: 0.3355545672821115\n",
    "(0.3355545672821115, 0.44668344431294826, [0.510145234564414, 0.16641097373883224, 0.3162162162162162, 0.0352055352055352, 0.5013185136754931, 0.4799950349621416, 0.2053190850693402, 0.4698259448249195])\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.4230711647869049 F1: 0.30920724751192785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 8) (8,)\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNormAct2d(\n",
      "    32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNormAct2d(\n",
      "    1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classifier): Linear(in_features=1280, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "w0,b0=mlpModel.layers[0].get_weights()\n",
    "print(w0.shape,b0.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    l0=nn.Linear(X_train.shape[1],num_classes)\n",
    "    l0.weight.copy_(torch.from_numpy(np.transpose(w0)).float())\n",
    "    l0.bias.copy_(torch.from_numpy(b0).float())\n",
    "model=feature_extractor_model\n",
    "model.classifier=l0\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINETUNED_PATH='enet_b0_vgaf_finetuned_logreg_expr.pt'\n",
    "FINETUNED_PATH='enet_b0_vgaf_finetuned_expr.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 128) (128,)\n",
      "(128, 8) (8,)\n",
      "EfficientNet(\n",
      "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNormAct2d(\n",
      "    32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNormAct2d(\n",
      "    1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "w0,b0=mlpModel.layers[0].get_weights()\n",
    "print(w0.shape,b0.shape)\n",
    "\n",
    "w1,b1=mlpModel.layers[1].get_weights()\n",
    "print(w1.shape,b1.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    l0=nn.Linear(X_train.shape[1],128)\n",
    "    l0.weight.copy_(torch.from_numpy(np.transpose(w0)).float())\n",
    "    l0.bias.copy_(torch.from_numpy(b0).float())\n",
    "    l1=nn.Linear(128,num_classes)\n",
    "    l1.weight.copy_(torch.from_numpy(np.transpose(w1)).float())\n",
    "    l1.bias.copy_(torch.from_numpy(b1).float())\n",
    "model=feature_extractor_model\n",
    "model.classifier=nn.Sequential(l0,\n",
    "          nn.ReLU(),\n",
    "          l1)\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_PATH='enet_b0_vgaf_finetuned_2layers_expr.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_vgaf_finetuned_expr.pt\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    torch.save(model, FINETUNED_PATH)\n",
    "else:\n",
    "    print(FINETUNED_PATH)\n",
    "    model = torch.load(FINETUNED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_5/VA_AU_FER/cropped\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'cropped')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename2Expr(dirname,step=1):\n",
    "    dirpath=os.path.join(DATA_DIR,'EXPR_Classification_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    numConstant=0\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                prev_val=None\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        expression=int(line)\n",
    "                        if expression>=0:\n",
    "                            if prev_val is None:\n",
    "                                prev_val=expression\n",
    "                                numConstant=1\n",
    "                            elif prev_val==expression:\n",
    "                                numConstant+=1\n",
    "                            else:\n",
    "                                prev_val=expression\n",
    "                                numConstant=1\n",
    "                            if i%step!=step-1:\n",
    "                                continue\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if os.path.exists(os.path.join(data_dir,imagename)):\n",
    "                                X.append(imagename)\n",
    "                                y.append(expression)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    y=np.array(y)\n",
    "    print(len(X),y.shape,num_missed)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585317 (585317,) 12044\n",
      "56087 (56087,) 729\n"
     ]
    }
   ],
   "source": [
    "filenames_train,y_train=get_filename2Expr('Train_Set',1)\n",
    "filenames_val,y_val=get_filename2Expr('Validation_Set',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-6b4e797efb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m train_transforms = transforms.Compose(\n\u001b[0m\u001b[1;32m     17\u001b[0m     [\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#transforms.Resize((IMG_SIZE_ORIG,IMG_SIZE_ORIG)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "class ABAW2_Exp_data_img(data.dataset.Dataset):\n",
    "    def __init__(self,filenames,y,transform):\n",
    "        self.transform=transform\n",
    "        self.filenames=filenames\n",
    "        self.y=y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(data_dir, self.filenames[index]))\n",
    "        img = self.transform(img)\n",
    "        return img,self.y[index]\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        #transforms.Resize((IMG_SIZE_ORIG,IMG_SIZE_ORIG)),\n",
    "        #transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size=64\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_dataset = ABAW2_Exp_data_img(filenames_train,y_train,train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_dataset = ABAW2_Exp_data_img(filenames_val,y_val,test_transforms)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [177198  16573  10771   9080  95463  78751  31615 165866] dict_values([1.0, 10.691968865021419, 16.451397270448425, 19.515198237885464, 1.856195594104522, 2.2501047605744686, 5.6048711054879, 1.0683202102902343])\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "num_classes=len(unique)\n",
    "print(num_classes,counts, class_weights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Label smooth \"\"\"\n",
    "def label_smooth(target, n_classes: int, label_smoothing=0.1):\n",
    "    # convert to one-hot\n",
    "    batch_size = target.size(0)\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    soft_target = torch.zeros((batch_size, n_classes), device=target.device)\n",
    "    soft_target.scatter_(1, target, 1)\n",
    "    # label smoothing\n",
    "    soft_target = soft_target * (1 - label_smoothing) + label_smoothing / n_classes\n",
    "    return soft_target\n",
    "\n",
    "def cross_entropy_loss_with_soft_target(pred, soft_target):\n",
    "    #logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "    return torch.mean(torch.sum(- weights*soft_target * torch.nn.functional.log_softmax(pred, -1), 1))\n",
    "\n",
    "def cross_entropy_with_label_smoothing(pred, target):\n",
    "    soft_target = label_smooth(target, pred.size(1)) #num_classes) #\n",
    "    return cross_entropy_loss_with_soft_target(pred, soft_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "weights = torch.FloatTensor(list(class_weights.values())).cuda()\n",
    "if False:\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion=cross_entropy_with_label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41608572396455507, 0.2999480217211319)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        labels,preds=[],[]\n",
    "        epoch_val_accuracy,epoch_val_f1=0,0\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            #label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_preds=val_output.argmax(dim=1).cpu()\n",
    "            \n",
    "            labels.extend(label)\n",
    "            preds.extend(val_preds)\n",
    "\n",
    "    labels=np.array(labels)\n",
    "    preds=np.array(preds)\n",
    "    epoch_val_accuracy = (preds == labels).mean()\n",
    "    epoch_val_f1=f1_score(y_true=labels,y_pred=preds, average=\"macro\")\n",
    "    return epoch_val_accuracy,epoch_val_f1\n",
    "\n",
    "test(model) #(0.39825628042148803, 0.2818708210857309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../affectnet')\n",
    "from robust_optimization import RobustOptimizer\n",
    "import copy\n",
    "def train(model,n_epochs, learningrate, use_sam=False, optimizer=optim.Adam, need_train_acc=True):\n",
    "    # optimizer\n",
    "    if use_sam:\n",
    "        optimizer = RobustOptimizer(filter(lambda p: p.requires_grad, model.parameters()), optimizer, lr=learningrate)\n",
    "    else:\n",
    "        optimizer=optimizer(filter(lambda p: p.requires_grad, model.parameters()), lr=learningrate)\n",
    "    # scheduler\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    best_f1=0\n",
    "    best_model=None\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        model.train()\n",
    "        for data, label in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            if use_sam:\n",
    "                #optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "  \n",
    "                # second forward-backward pass\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if need_train_acc:\n",
    "                acc = (output.argmax(dim=1) == label).float().sum()\n",
    "                epoch_accuracy += acc / len(train_dataset)\n",
    "            epoch_loss += loss / len(train_loader)\n",
    "\n",
    "        epoch_val_accuracy,epoch_val_f1=test(model)\n",
    "        if need_train_acc:\n",
    "            print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_f1: {epoch_val_f1:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\")\n",
    "        else:\n",
    "            print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - val_f1: {epoch_val_f1:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\")\n",
    "        if best_f1<epoch_val_f1:\n",
    "            best_f1=epoch_val_f1\n",
    "            best_model=copy.deepcopy(model.state_dict())\n",
    "        #scheduler.step()\n",
    "    \n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best f1:{best_f1}\")\n",
    "        epoch_val_accuracy,epoch_val_f1=test(model)\n",
    "        print(\n",
    "            f\"val_f1: {epoch_val_f1:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No best model Best acc:{best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "def set_parameter_requires_grad(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "set_parameter_requires_grad(model, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941cf360de664fac9a2e7921dcfe3e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 - loss : 2.5846 - acc: 0.9725 - val_f1: 0.3553 - val_acc: 0.4595\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cacee10a9ee46e09aed281fbee1378e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 - loss : 2.5213 - acc: 0.9853 - val_f1: 0.3565 - val_acc: 0.4713\n",
      "\n",
      "Best f1:0.37740892891459465\n",
      "val_f1: 0.3774 - val_acc: 0.4903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model,5,1e-4,use_sam=True)\n",
    "#Epoch : 5 - loss : 2.5206 - acc: 0.9855 - val_f1: 0.3805 - val_acc: 0.4829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_vgaf_finetuned_expr.pt\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    torch.save(model, FINETUNED_PATH)\n",
    "else:\n",
    "    print(FINETUNED_PATH)\n",
    "    model = torch.load(FINETUNED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280532 (280532,) 3698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd8c0b5cfeb4b09a92ae66664a21bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.eval()\n",
    "filenames_val_all,y_val_all=get_filename2Expr('Validation_Set',1)\n",
    "val_scores=[]\n",
    "imgs=[]\n",
    "for filename in tqdm(filenames_val_all):\n",
    "    filepath=os.path.join(data_dir,filename)   \n",
    "    img = Image.open(filepath)\n",
    "    img_tensor = test_transforms(img)\n",
    "    if img.size:\n",
    "        imgs.append(img_tensor)\n",
    "        if len(imgs)>=64: #96: #48: #32:        \n",
    "            scores = model(torch.stack(imgs, dim=0).to(device))\n",
    "            scores=scores.data.cpu().numpy()\n",
    "            #preds=np.argmax(scores,axis=1)\n",
    "            #print(scores.shape,preds.shape)\n",
    "\n",
    "            if len(val_scores)==0:\n",
    "                val_scores=scores\n",
    "            else:\n",
    "                val_scores=np.concatenate((val_scores,scores),axis=0)\n",
    "            imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    scores = model(torch.stack(imgs, dim=0).to(device))\n",
    "    scores=scores.data.cpu().numpy()\n",
    "    #preds=np.argmax(scores,axis=1)\n",
    "    #print(scores.shape,preds.shape)\n",
    "\n",
    "    if len(val_scores)==0:\n",
    "        val_scores=scores\n",
    "    else:\n",
    "        val_scores=np.concatenate((val_scores,scores),axis=0)\n",
    "    imgs=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4836667474655298 0.3801234273402112\n",
      "(0.3801234273402112, 0.4836667474655298, [0.580467222914545, 0.2462413652986591, 0.47159423685135293, 0.05278283748229103, 0.5092937576754157, 0.4012854191639675, 0.2608122114388015, 0.5185103678966566])\n"
     ]
    }
   ],
   "source": [
    "val_preds=np.argmax(val_scores,axis=1)\n",
    "acc= (val_preds == y_val_all).mean()\n",
    "f1=f1_score(y_true=y_val_all,y_pred=val_preds, average=\"macro\")\n",
    "print(acc,f1)\n",
    "print(metric_for_Exp(y_val,val_preds))\n",
    "#first model 0.4836667474655298 0.3801234273402112\n",
    "#2 layers:0.4426197367858212 0.3418797148135464\n",
    "#1layer and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.37755217409013575, 0.48992271826387007, [0.565062109777239, 0.2572753280063135, 0.4055436081242533, 0.054577097111033764, 0.5136565742113064, 0.41232826235721426, 0.25534346014249226, 0.5566309529912339])\n"
     ]
    }
   ],
   "source": [
    "print(metric_for_Exp(y_val,val_preds)) #logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n"
     ]
    }
   ],
   "source": [
    "#y_val_preds=mlpModel.predict(X_val)\n",
    "y_pred=np.argmax(y_val_preds,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "print(metric_for_Exp(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.3801234273402112, 0.4836667474655298, [0.580467222914545, 0.2462413652986591, 0.47159423685135293, 0.05278283748229103, 0.5092937576754157, 0.4012854191639675, 0.2608122114388015, 0.5185103678966566])\n",
      "0.1 (0.3827371740485952, 0.487245661813982, [0.5854303801455072, 0.24899334374229598, 0.4796374694412974, 0.05061279123269335, 0.5097745922925105, 0.4046989422294548, 0.2619399930737021, 0.5208098802313003])\n",
      "0.2 (0.3848571300247635, 0.4908851753097686, [0.5909438312054427, 0.25137522920486743, 0.4864209505334627, 0.04656435298221137, 0.5097381070777391, 0.40697143437008476, 0.26393406385195944, 0.5229090709723402])\n",
      "0.30000000000000004 (0.3877536218010715, 0.4955584389659647, [0.5974731152665433, 0.25398710553104853, 0.4949894841024372, 0.04293495674463313, 0.5098946498657302, 0.4096733350215244, 0.26678473166566524, 0.5262915962109895])\n",
      "0.4 (0.3904217485408135, 0.5004206293756149, [0.6047069590274428, 0.2561782109293421, 0.5042567951062622, 0.035819739580812235, 0.5105966876987843, 0.41341149123250287, 0.26952244962716165, 0.5288816551241998])\n",
      "0.5 (0.3937842464461888, 0.5057462250295867, [0.612246652745363, 0.2554478342079516, 0.5153524299967815, 0.0312339463680263, 0.5108036877134331, 0.41841846882001965, 0.27506065636572596, 0.5317102953522094])\n",
      "0.6000000000000001 (0.3971101746519401, 0.5122944975974221, [0.6226320854702937, 0.2507189072609633, 0.5272943037974684, 0.02347859792901047, 0.5112977036855438, 0.42690380761523045, 0.2798004184773861, 0.5347555729796247])\n",
      "0.7000000000000001 (0.4007284600565896, 0.5195129254416608, [0.6335573225142334, 0.2409484724122207, 0.5351810939278302, 0.018159951894167168, 0.5110523467731232, 0.441167709264224, 0.28779126371130004, 0.5379695199556179])\n",
      "0.8 (0.4051360355253487, 0.5243287753268789, [0.6378242074927953, 0.22352622551232285, 0.537062363238512, 0.01793903425950904, 0.5099218404061415, 0.47957471943295926, 0.3005083420229406, 0.5347315518376093])\n",
      "0.9 (0.3977041872431498, 0.5142942694594556, [0.6222866973989462, 0.20052816901408452, 0.5326689592252088, 0.016837877500579284, 0.4989875196297215, 0.488337401681584, 0.302406819857065, 0.5195800536380089])\n",
      "1.0 (0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_val_preds+(1-w)*val_scores\n",
    "    y_ensemble_pred=np.argmax(y_ensemble,axis=1)\n",
    "    print(w,metric_for_Exp(y_val,y_ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.3952488491649343, 0.517563058759785, [0.6016788248226242, 0.1918739931984965, 0.5253380888690742, 0.016344229486324215, 0.48850525596102906, 0.49619380261508145, 0.2903130634322242, 0.5517435349346206])\n",
      "0.1 (0.40953213649205417, 0.5274407197752841, [0.6148188421290555, 0.17785527462946818, 0.5444070332959222, 0.017477562588568727, 0.5067708555124983, 0.5583590338004264, 0.3141117359331847, 0.5424567540473093])\n",
      "0.2 (0.4074720160149119, 0.5272410990546533, [0.6116878860768102, 0.13929040735873852, 0.5155406391361447, 0.03301680058436816, 0.5130563701884057, 0.5855199682173329, 0.3228455116263024, 0.5388185449311923])\n",
      "0.30000000000000004 (0.3953708890368174, 0.5149002609327991, [0.5876591201161074, 0.11233642111454196, 0.4490543014032947, 0.06676266527032335, 0.5096215030170049, 0.5766154717248213, 0.32346439572386304, 0.5374532339245822])\n",
      "0.4 (0.37880367622786354, 0.49849927993954346, [0.5566701701635113, 0.09710902124695228, 0.3909755322529393, 0.07857573928786964, 0.4992648765766463, 0.553218127604896, 0.31798787334381323, 0.5366280693462803])\n",
      "0.5 (0.36408085511963023, 0.48252605763335377, [0.5217361221623342, 0.08609271523178808, 0.3484446587894864, 0.0858924036019395, 0.489214849938513, 0.535450988949329, 0.30971782103515916, 0.5360972812484927])\n",
      "0.6000000000000001 (0.35209537838264715, 0.4692013745312478, [0.49100915859430216, 0.079488, 0.3151452162365032, 0.0919770614108346, 0.48011019650970327, 0.522696217547337, 0.30086089714544634, 0.5354762796170509])\n",
      "0.7000000000000001 (0.34319871033413785, 0.4590848815821368, [0.4671776269599813, 0.07448327229842963, 0.2933034463435136, 0.09541424141870206, 0.472073995019566, 0.5134129912727698, 0.29486112162264433, 0.5348629877374959])\n",
      "0.8 (0.3361536745996882, 0.45145651832945977, [0.44956922549946754, 0.07096342279836894, 0.27575242585384574, 0.09636111407533882, 0.46535976832256626, 0.5067016023380025, 0.29011950088588984, 0.534402337024026])\n",
      "0.9 (0.32973407824768636, 0.4453395691044159, [0.4352391095802458, 0.06863805745882919, 0.25553754727174494, 0.09709351305812974, 0.46098096714128023, 0.5010363135629312, 0.2852739983462377, 0.534073119562092])\n",
      "1.0 (0.32483321668376286, 0.4405950123337088, [0.4240743711376431, 0.06527802504302416, 0.2422075149444919, 0.0975381252277104, 0.4575306382123803, 0.496758497517895, 0.28145869287911757, 0.5338198685078406])\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    y_pred_new=y_pred.copy()\n",
    "else:\n",
    "    w=0.8\n",
    "    y_ensemble=w*y_val_preds+(1-w)*val_scores\n",
    "    y_pred_new=np.argmax(y_ensemble,axis=1)\n",
    "y_preds_other_inds=y_pred_new!=7\n",
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_scores_all+(1-w)*y_val_preds\n",
    "    y_ensemble_pred=np.argmax(y_ensemble,axis=1)\n",
    "    y_pred_new[y_preds_other_inds]=y_ensemble_pred[y_preds_other_inds]\n",
    "    print(w,metric_for_Exp(y_val,y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.31628854771760845 0.42296422511513837\n",
      "0.0 0.1 0.33351319443379285 0.43878773188085496\n",
      "0.0 0.2 0.35001497045027763 0.45577688106882636\n",
      "0.0 0.30000000000000004 0.36505587960731756 0.4720174525544323\n",
      "0.0 0.4 0.3781678458913733 0.4860764547360016\n",
      "0.0 0.5 0.387350397497928 0.49730868492720975\n",
      "0.0 0.6000000000000001 0.3929559903501187 0.5055394749975047\n",
      "0.0 0.7000000000000001 0.39871138770705294 0.5128185019890779\n",
      "0.0 0.8 0.3981373406751429 0.5147327221136982\n",
      "0.0 0.9 0.3975421585544657 0.5150749290633511\n",
      "0.0 1.0 0.3934100528686891 0.5109256697988108\n",
      "0.1 0.0 0.3212405732052011 0.4277622517217287\n",
      "0.1 0.1 0.3399231588671779 0.4456140475952832\n",
      "0.1 0.2 0.35757414961998873 0.46411104615516235\n",
      "0.1 0.30000000000000004 0.37418430652299184 0.48159211783325967\n",
      "0.1 0.4 0.385944677637158 0.4950344345743088\n",
      "0.1 0.5 0.39326409457250483 0.5056072034562902\n",
      "0.1 0.6000000000000001 0.39963161160788646 0.5137061012647398\n",
      "0.1 0.7000000000000001 0.3999661268009579 0.5163760284031769\n",
      "0.1 0.8 0.3994261351760848 0.517024795745227\n",
      "0.1 0.9 0.39522069596148846 0.513007428742532\n",
      "0.2 0.0 0.3276497856324089 0.43387920094677257\n",
      "0.2 0.1 0.34765616695338586 0.4544044886144896\n",
      "0.2 0.2 0.36681755348346684 0.4741455520225857\n",
      "0.2 0.30000000000000004 0.38335203857086936 0.49172643406099836\n",
      "0.2 0.4 0.3928253824851334 0.504491466214193\n",
      "0.2 0.5 0.4007610175048399 0.5146756876220895\n",
      "0.2 0.6000000000000001 0.40505776445520575 0.5202472445211241\n",
      "0.2 0.7000000000000001 0.40088706662806345 0.5189425805255728\n",
      "0.2 0.8 0.3964490952090012 0.5150535411289978\n",
      "0.30000000000000004 0.0 0.33476444978931585 0.4415218228223518\n",
      "0.30000000000000004 0.1 0.3569826391710018 0.4644104772361085\n",
      "0.30000000000000004 0.2 0.3779454756354539 0.4859338685069796\n",
      "0.30000000000000004 0.30000000000000004 0.3924263949738754 0.5024417891720018\n",
      "0.30000000000000004 0.4 0.40140925491281226 0.5149965066373889\n",
      "0.30000000000000004 0.5 0.40861159657931145 0.523480387264198\n",
      "0.30000000000000004 0.6000000000000001 0.402966145852942 0.5212132662227482\n",
      "0.30000000000000004 0.7000000000000001 0.3982557301255214 0.5176450458414726\n",
      "0.4 0.0 0.3437141241418305 0.45164188042718834\n",
      "0.4 0.1 0.3690337015911378 0.4775034577160538\n",
      "0.4 0.2 0.3900090136377007 0.4989662498395905\n",
      "0.4 0.30000000000000004 0.401704317902953 0.5135492564128157\n",
      "0.4 0.4 0.410914297355207 0.5252413271926197\n",
      "0.4 0.5 0.4056893215162033 0.5241184606390715\n",
      "0.4 0.6000000000000001 0.39943472591386486 0.5200832703577488\n",
      "0.5 0.0 0.35569748324772577 0.46489527041478335\n",
      "0.5 0.1 0.3831449278419225 0.4923609427801463\n",
      "0.5 0.2 0.4010817282092441 0.510797342192691\n",
      "0.5 0.30000000000000004 0.41300866990781626 0.526182396304165\n",
      "0.5 0.4 0.41278735521071663 0.5298504270457559\n",
      "0.5 0.5 0.400808861387248 0.5226284345457916\n",
      "0.6000000000000001 0.0 0.3706947720957845 0.4809968203270928\n",
      "0.6000000000000001 0.1 0.39712294868238057 0.506591048436542\n",
      "0.6000000000000001 0.2 0.4119382869318323 0.5227353742175581\n",
      "0.6000000000000001 0.30000000000000004 0.41613799562599263 0.5323991558895242\n",
      "0.6000000000000001 0.4 0.40206010690321015 0.5256298746667047\n",
      "0.7000000000000001 0.0 0.38766874830452747 0.4974584004676828\n",
      "0.7000000000000001 0.1 0.4088630677128243 0.5177626794804158\n",
      "0.7000000000000001 0.2 0.41522458931019224 0.5279611595112144\n",
      "0.7000000000000001 0.30000000000000004 0.4024988127832412 0.5280217586585487\n",
      "0.8 0.0 0.3991088131752204 0.50926810488643\n",
      "0.8 0.1 0.40922461119223497 0.5177733734475924\n",
      "0.8 0.2 0.40432369896511494 0.5273230861363409\n",
      "0.9 0.0 0.3990138102717483 0.5071827812869834\n",
      "0.9 0.1 0.39656398709070273 0.5136847133303866\n",
      "1.0 0.0 0.3844313672414089 0.49544436998274705\n",
      "0.6000000000000001 0.30000000000000004 0.41613799562599263\n"
     ]
    }
   ],
   "source": [
    "if True: #0.6000000000000001 0.30000000000000004 0.41613799562599263\n",
    "    y_pred_new=y_pred.copy()\n",
    "else: #0.6000000000000001 0.2 0.418041991345558\n",
    "    w=0.8\n",
    "    y_ensemble=w*y_val_preds+(1-w)*val_scores\n",
    "    y_pred_new=np.argmax(y_ensemble,axis=1)\n",
    "y_preds_other_inds=y_pred_new!=7\n",
    "\n",
    "best_f1=0\n",
    "best_w1,best_w2=0,0\n",
    "for w1 in np.linspace(0,1,11):\n",
    "    for w2 in np.arange(0,1.05-w1,0.1):\n",
    "        y_ensemble=w1*y_val_preds+w2*val_scores+(1-w1-w2)*y_scores_all\n",
    "        y_ensemble_pred=np.argmax(y_ensemble,axis=1)\n",
    "        y_pred_new[y_preds_other_inds]=y_ensemble_pred[y_preds_other_inds]\n",
    "        f1,acc,_=metric_for_Exp(y_val,y_pred_new)\n",
    "        print(w1,w2,f1,acc)\n",
    "        if best_f1<f1:\n",
    "            best_f1=f1\n",
    "            best_w1,best_w2=w1,w2\n",
    "\n",
    "print(best_w1,best_w2,best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b786484dfca44db4b13ec876cf90b69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirpath=os.path.join(DATA_DIR,'EXPR_Classification_Challenge/Validation_Set')\n",
    "test_videos={}\n",
    "ind=0\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,expressions,scores,cnn_preds=[],[],[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    expression=int(line)\n",
    "                    if expression>=0:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            X.append(y_val_preds[ind])\n",
    "                            indices.append(i)\n",
    "                            expressions.append(int(line))\n",
    "                            scores.append(filename2featuresAll[imagename][1][AFFECTNET2MTL])\n",
    "                            cnn_preds.append(val_scores[ind])\n",
    "                            ind+=1\n",
    "        test_videos[fn]=(np.array(X),indices,np.array(expressions),np.array(scores),np.array(cnn_preds))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5462585373504627 F1: 0.431761062689951\n",
      "(0.431761062689951, 0.5462585373504627, [0.6514788912381793, 0.1867602808425276, 0.5948337151433762, 0.01820367508157307, 0.5227065138189021, 0.6097208101978572, 0.34942028985507245, 0.5209643253421202])\n"
     ]
    }
   ],
   "source": [
    "delta=50\n",
    "total_true=[]\n",
    "total_preds=[]\n",
    "weight=0.1\n",
    "for videoname,(y_pred_expr,indices,expressions,scores,cnn_preds) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    \n",
    "    y_pred_test_new=weight*y_pred_expr+(1-w)*cnn_preds\n",
    "    y_preds_test_other_inds=np.argmax(y_pred_expr,axis=1)!=7    \n",
    "\n",
    "    y_ensemble=weight*scores+(1-weight)*y_pred_expr\n",
    "    y_pred_test_new=y_pred_expr.copy()\n",
    "    y_preds_test_other_inds=np.argmax(y_pred_expr,axis=1)!=7\n",
    "    y_pred_test_new[y_preds_test_other_inds]=y_ensemble[y_preds_test_other_inds]\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_test_new[cur_ind-1]+(1-w)*y_pred_test_new[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    preds=[]\n",
    "    for i in range(len(preds_proba)):\n",
    "        i1=max(i-delta,0)\n",
    "        proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "        preds.append(np.argmax(proba))\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_preds.append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "total_preds=np.array(total_preds)\n",
    "print('Acc:',(total_preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=total_preds, average=\"macro\"))\n",
    "print(metric_for_Exp(total_true,total_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5574194744271598 F1: 0.4326929159405485\n",
      "(0.4326929159405485, 0.5574194744271598, [0.68389709814856, 0.2779291553133515, 0.5947668112798264, 0.014085377154506704, 0.5126921923629709, 0.4894285642456696, 0.3112056009677065, 0.5775385280517961])\n"
     ]
    }
   ],
   "source": [
    "delta=50\n",
    "total_true=[]\n",
    "total_preds=[]\n",
    "weight=0.8\n",
    "for videoname,(y_pred_expr,indices,expressions,scores,cnn_preds) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    \n",
    "    y_pred_test_new=weight*y_pred_expr+(1-weight)*cnn_preds\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_test_new[cur_ind-1]+(1-w)*y_pred_test_new[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    preds=[]\n",
    "    for i in range(len(preds_proba)):\n",
    "        i1=max(i-delta,0)\n",
    "        proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "        preds.append(np.argmax(proba))\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_preds.append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "total_preds=np.array(total_preds)\n",
    "print('Acc:',(total_preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=total_preds, average=\"macro\"))\n",
    "print(metric_for_Exp(total_true,total_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5501725293371166 F1: 0.43916875305797154\n",
      "(0.43916875305797154, 0.5501725293371166, [0.6782491740007602, 0.17332314160137588, 0.5830826278597915, 0.08264081255771008, 0.5324214584529572, 0.6043088998814439, 0.3384857396894877, 0.520838170420246])\n"
     ]
    }
   ],
   "source": [
    "delta=50\n",
    "total_true=[]\n",
    "total_preds=[]\n",
    "weight=0.8\n",
    "w1,w2=0.6,0.2\n",
    "for videoname,(y_pred_expr,indices,expressions,scores,cnn_preds) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    \n",
    "    y_pred_test_new=weight*y_pred_expr+(1-weight)*cnn_preds\n",
    "    y_preds_test_other_inds=np.argmax(y_pred_expr,axis=1)!=7\n",
    "    y_ensemble=w1*y_pred_expr+w2*cnn_preds+(1-w1-w2)*scores\n",
    "    y_pred_test_new[y_preds_test_other_inds]=y_ensemble[y_preds_test_other_inds]\n",
    "\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_test_new[cur_ind-1]+(1-w)*y_pred_test_new[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    preds=[]\n",
    "    for i in range(len(preds_proba)):\n",
    "        i1=max(i-delta,0)\n",
    "        proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "        preds.append(np.argmax(proba))\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_preds.append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "total_preds=np.array(total_preds)\n",
    "print('Acc:',(total_preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=total_preds, average=\"macro\"))\n",
    "print(metric_for_Exp(total_true,total_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280532, 8) (280532,) 3698\n",
      "(0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n"
     ]
    }
   ],
   "source": [
    "dirpath=os.path.join(DATA_DIR,'EXPR_Classification_Challenge/Validation_Set')\n",
    "num_missed=0\n",
    "y_scores_all,y_val=[],[]\n",
    "\n",
    "for filename in os.listdir(dirpath):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    expression=int(line)\n",
    "                    #if expression>=0:\n",
    "                    if expression>=0:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            scores=filename2featuresAll[imagename][1]\n",
    "                            if False:\n",
    "                                scores=scores[:-2]\n",
    "                            y_scores_all.append(scores[AFFECTNET2MTL])\n",
    "                            y_val.append(expression)\n",
    "                        else:\n",
    "                            num_missed+=1\n",
    "y_scores_all=np.array(y_scores_all)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_all.shape,y_val.shape,num_missed)\n",
    "\n",
    "USE_OTHER=True\n",
    "if USE_OTHER:\n",
    "    y_scores=np.argmax(y_scores_all,axis=1)\n",
    "    print(metric_for_Exp(y_val,y_scores,8))\n",
    "else:\n",
    "    y_scores=np.argmax(y_scores_all[y_val!=7,:7],axis=1)\n",
    "    print(metric_for_Exp(y_val[y_val!=7],y_scores,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE_OTHER=True\n",
    "(280532,) (280532,) 3698\n",
    "(0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n",
    "\n",
    "USE_OTHER=False\n",
    "(174088,) (174088,) 1883\n",
    "(0.38315520007157966, 0.5219142043104636, [0.5941131445271728, 0.11673050704408232, 0.2563962686160057, 0.1146315414738341, 0.6221359518916038, 0.574566439059762, 0.40351254788859714])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280532,) (280532,) 0.32562417121754383\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=['Neutral','Anger','Disgust','Fear','Happiness','Sadness','Surprise','Other']\n",
    "IC = type('IdentityClassifier', (), {\"predict\": lambda i : i, \"_estimator_type\": \"classifier\"})\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "def plt_conf_matrix(y_true,y_pred,labels):\n",
    "    print(y_pred.shape,y_true.shape, (y_pred==y_true).mean())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_confusion_matrix(IC, y_pred,y_true,display_labels=labels,cmap=plt.cm.Blues,ax=ax,colorbar=False,values_format='d') #,normalize='true'\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plt_conf_matrix(y_val,y_scores,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14431557 0.04700894 0.7286932  ... 0.00801708 0.01772265 0.03276507]\n",
      " [0.12623148 0.05338586 0.74596107 ... 0.00828965 0.0161922  0.02721561]\n",
      " [0.12411553 0.05135258 0.74902546 ... 0.00888397 0.01757528 0.02525777]\n",
      " ...\n",
      " [0.61938715 0.09317015 0.15505028 ... 0.11088556 0.00744538 0.0130494 ]\n",
      " [0.4615972  0.0987     0.27191597 ... 0.15485528 0.00422211 0.00742036]\n",
      " [0.62540436 0.10433636 0.1733591  ... 0.08387769 0.00457728 0.00741982]]\n"
     ]
    }
   ],
   "source": [
    "e_x = np.exp(y_scores_all - np.max(y_scores_all,axis=0))\n",
    "y_probab_all=e_x / e_x.sum(axis=1)[:,None]\n",
    "print(y_probab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40469536452169447"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores=np.argmax(y_probab_all,axis=1)\n",
    "y_max_scores=np.array([y_probab_all[i,y] for i,y in enumerate(y_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.620563785949553 0.37943621405044703\n",
      "0.1 0.620563785949553 0.37943621405044703\n",
      "0.2 0.620563785949553 0.37943621405044703\n",
      "0.30000000000000004 0.6185319321859895 0.38146806781401055\n",
      "0.4 0.5953046354783055 0.40469536452169447\n",
      "0.5 0.5527497754266892 0.4472502245733107\n",
      "0.6000000000000001 0.5082165314473928 0.4917834685526072\n",
      "0.7000000000000001 0.47205666376741334 0.5279433362325866\n",
      "0.8 0.44366418091340737 0.5563358190865926\n",
      "0.9 0.4196455306346513 0.5803544693653487\n",
      "1.0 0.37948255457487917 0.6205174454251209\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    print(w,((y_max_scores<w)==(y_val==7)).mean(),((y_max_scores>=w)==(y_val==7)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n",
      "0.1 (0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n",
      "0.2 (0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n",
      "0.30000000000000004 (0.2597911730430537, 0.3275526499650664, [0.47211816735363765, 0.08163451869457902, 0.16895322458679918, 0.08002747724540615, 0.4611789865547216, 0.46926102518053847, 0.2843253425698052, 0.06083064215894236])\n",
      "0.4 (0.2725398854298629, 0.3382573111088931, [0.4533068150998954, 0.08461096205442699, 0.1692091312344477, 0.07889215274863619, 0.45454058398071256, 0.44727622929082866, 0.29571061474599725, 0.1967725942839586])\n",
      "0.5 (0.2792704298930966, 0.35221293827442146, [0.40001118325866175, 0.08849154376174477, 0.17688358749811262, 0.07985456504174522, 0.4371276887415568, 0.39594196138533044, 0.31378423013404, 0.3420686793235813])\n",
      "0.6000000000000001 (0.2701312351710332, 0.3661471775055965, [0.3419384852390504, 0.06984730035800395, 0.20335429769392033, 0.06273608145836755, 0.4109322351179333, 0.3342184671092336, 0.312201650680348, 0.4258213637114083])\n",
      "0.7000000000000001 (0.25480054775068295, 0.3779533172686182, [0.27285345356965607, 0.06590783917752892, 0.24801010045561836, 0.049856184084372, 0.3626678936098674, 0.27186624142263455, 0.2889932185706834, 0.478249451115103])\n",
      "0.8 (0.2308637084845556, 0.3895705302781857, [0.19213825502089485, 0.05032156154800858, 0.3215250675472831, 0.035114013488919814, 0.2948954044155683, 0.20654134900774024, 0.22878968129735142, 0.5175843355506784])\n",
      "0.9 (0.19404656489715782, 0.3997583163418077, [0.08681419405525731, 0.012089572743508725, 0.39492753623188404, 0.013232733604178757, 0.21955436035343837, 0.14412409139915835, 0.13391941391941392, 0.5477106168704231])\n",
      "1.0 (0.06886993095015415, 0.37948255457487917, [0.0, 0.0, 0.0, 0.0, 0.000810983027283786, 0.0, 0.0, 0.5501484645739494])\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_scores=np.argmax(y_scores_all,axis=1)\n",
    "    y_scores[y_max_scores<w]=7\n",
    "    print(w,metric_for_Exp(y_val,y_scores,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probab_sorted=np.sort(y_probab_all,axis=1)[:,6:]\n",
    "diff_probab=y_probab_sorted[:,1]-y_probab_sorted[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n",
      "0.05 (0.2681231420530048, 0.33464631485891094, [0.46212387682665557, 0.07746784217372453, 0.16895322458679918, 0.07394834625441533, 0.45749439549554255, 0.4582260333979346, 0.2945822454308094, 0.15218917225815703])\n",
      "0.1 (0.27388884984049766, 0.34275590663453726, [0.45001472561274913, 0.07235275851361143, 0.16895322458679918, 0.07036466358500257, 0.4508702540410587, 0.44050747365149334, 0.3046417619180373, 0.23340593681522961])\n",
      "0.15000000000000002 (0.27592473960131664, 0.34920436884205724, [0.43565206887758523, 0.06796116504854369, 0.1694596937301358, 0.06743928717022887, 0.4450506808400555, 0.42020299370538805, 0.3103675020092058, 0.2912645254293902])\n",
      "0.2 (0.2763043505776614, 0.35459056364336333, [0.4179745193037669, 0.0646645676919351, 0.17304713432175262, 0.06678841638403339, 0.43759338579539797, 0.40256134550881867, 0.3123713697690373, 0.33543406584654917])\n",
      "0.25 (0.27559754588175234, 0.3588146806781401, [0.39737839163473776, 0.06293388697852462, 0.18000921942224954, 0.06576680068925905, 0.4292174830245897, 0.38458520274996155, 0.3158439078722304, 0.3690454746824659])\n",
      "0.30000000000000004 (0.2739757112120928, 0.36247558210827996, [0.37457125267509017, 0.06231309548647333, 0.1888207775447653, 0.0642962274382214, 0.4216766634119124, 0.36577084236382024, 0.3181799310831569, 0.3961768996933028])\n",
      "0.35000000000000003 (0.2703664723795608, 0.36568733691700056, [0.35198718287826003, 0.06315157878946974, 0.19841540296472995, 0.05973597359735974, 0.41028588269967586, 0.34604836699077535, 0.3141735717400785, 0.41913381937613714])\n",
      "0.4 (0.2662347193927155, 0.3694551780189069, [0.33069812319088676, 0.06143399886832108, 0.20865162952583285, 0.05434876676763306, 0.3989543785398644, 0.3274624918460534, 0.30940798531436436, 0.43892038108876824])\n",
      "0.45 (0.261208202755798, 0.3725742517787632, [0.30853591958637083, 0.06217616580310881, 0.22079365846585144, 0.0502996186671509, 0.38575667655786344, 0.30491079161614415, 0.30146881772212863, 0.4557239736277655])\n",
      "0.5 (0.2554841648927956, 0.3758572997019948, [0.28561484918793506, 0.061284947231994076, 0.2352390365707746, 0.04723665564478035, 0.36988526403096494, 0.284087517505797, 0.2895137549487362, 0.4710112940213822])\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,0.5,11):\n",
    "    y_scores=np.argmax(y_scores_all,axis=1)\n",
    "    y_scores[diff_probab<w]=7\n",
    "    print(w,metric_for_Exp(y_val,y_scores,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic emotions w/o Other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o other: (0.4564635736682434, 0.6291358393456183, [0.7635503588911151, 0.24420428795537738, 0.5580413016270338, 0.048256128683009825, 0.6517256296865988, 0.5464432412247946, 0.383024067609774])\n",
      "other vs remaining: (array([False,  True]), array([204436,  76096])) 0.6733420786220466 0.4979840035060809\n"
     ]
    }
   ],
   "source": [
    "y_val_7=y_val[y_val!=7]\n",
    "#print(y_val_7.shape)\n",
    "y_pred_7=np.argmax(y_val_preds[y_val!=7,:7],axis=1)\n",
    "#print(y_pred_7.shape)\n",
    "print('w/o other:',metric_for_Exp(y_val_7,y_pred_7,7))\n",
    "#0.4564635736682434, 0.6291358393456183, [0.7635503588911151, 0.24420428795537738, 0.5580413016270338, 0.048256128683009825, 0.6517256296865988, 0.5464432412247946, 0.383024067609774])\n",
    "\n",
    "print('other vs remaining:',np.unique(y_pred==7,return_counts=True),((y_val==7)==(y_pred==7)).mean(),f1_score((y_val==7),(y_pred==7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.31628854771760845, 0.42296422511513837, [0.4155234848887438, 0.06360920752064665, 0.23902049507585837, 0.0983332462511103, 0.4447653591259179, 0.4795904014403466, 0.289364538586876, 0.500101648851368])\n"
     ]
    }
   ],
   "source": [
    "y_pred_new=y_pred.copy()\n",
    "y_preds_other_inds=y_pred!=7\n",
    "y_pred_new[y_preds_other_inds]=y_scores[y_preds_other_inds]\n",
    "print(metric_for_Exp(y_val,y_pred_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_other_inds=y_pred!=7\n",
    "y_pred_new=y_pred.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n",
      "0.1 (0.3990138102717483, 0.5071827812869834, [0.6051385462991303, 0.17309534175010885, 0.5479885490432425, 0.01929101401483924, 0.49132881348827945, 0.5413419423824309, 0.3141176470588235, 0.4998086281371316])\n",
      "0.2 (0.3991088131752204, 0.50926810488643, [0.6024987189185232, 0.13802840295656507, 0.5226733847065798, 0.03456902433477371, 0.49833186250242145, 0.5680585580460424, 0.3275767918088737, 0.5011337621279843])\n",
      "0.30000000000000004 (0.38766874830452747, 0.4974584004676828, [0.5783292290206479, 0.11204273948208057, 0.45502718326336794, 0.06921529175050302, 0.4954688731284476, 0.5593136035811987, 0.3304741054444963, 0.5014789607654776])\n",
      "0.4 (0.3706947720957845, 0.4809968203270928, [0.5475349216688707, 0.09621848739495799, 0.3932325044860293, 0.08038782523318605, 0.48535259809119835, 0.5355207507269363, 0.3259017850529591, 0.5014093041121384])\n",
      "0.5 (0.35569748324772577, 0.46489527041478335, [0.5126176585519685, 0.08491753328475855, 0.3479997579132119, 0.08741830065359478, 0.4757945613976743, 0.5173021992601495, 0.31810553794517993, 0.5014243169752687])\n",
      "0.6000000000000001 (0.3437141241418305, 0.45164188042718834, [0.48229631202661566, 0.07830134540585347, 0.3139864591169492, 0.09314606741573034, 0.46697074201802197, 0.5044322245259775, 0.30940381528353306, 0.501176027341963])\n",
      "0.7000000000000001 (0.33476444978931585, 0.4415218228223518, [0.4586949580563699, 0.07317825630900228, 0.2911739983188568, 0.09652678864906322, 0.4590912635202121, 0.495547222873213, 0.30320481657380055, 0.5006982940140089])\n",
      "0.8 (0.3276497856324089, 0.43387920094677257, [0.4410398982579634, 0.06948549369684541, 0.27296127936907827, 0.09727292248228472, 0.45243837084673094, 0.489128243527345, 0.29838409412465555, 0.5004879827543678])\n",
      "0.9 (0.3212405732052011, 0.4277622517217287, [0.4267340997088574, 0.06703113857855955, 0.25249420266407807, 0.09798941798941799, 0.4481910469120343, 0.48377706780262697, 0.2934451785316606, 0.500262433454374])\n",
      "1.0 (0.31628854771760845, 0.42296422511513837, [0.4155234848887438, 0.06360920752064665, 0.23902049507585837, 0.0983332462511103, 0.4447653591259179, 0.4795904014403466, 0.289364538586876, 0.500101648851368])\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_scores_all+(1-w)*y_val_preds\n",
    "    y_ensemble_pred=np.argmax(y_ensemble,axis=1)\n",
    "    y_pred_new[y_preds_other_inds]=y_ensemble_pred[y_preds_other_inds]\n",
    "    print(w,metric_for_Exp(y_val,y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n",
      "0.1 (0.3869468990999296, 0.49833530577616814, [0.599990480496918, 0.18471392711849735, 0.5263917972416782, 0.017994222038794885, 0.48338330572620725, 0.48817029502866804, 0.2950404858299595, 0.49989067931871356])\n",
      "0.2 (0.3892900688667766, 0.5014436855688478, [0.6026704990546645, 0.18197454420364634, 0.5286951623125132, 0.018593171534348005, 0.48816650573972753, 0.4908756291713785, 0.3017421602787456, 0.5016028786391887])\n",
      "0.30000000000000004 (0.3899076400262561, 0.5043773972309754, [0.6044550286062788, 0.17687307560725282, 0.5215391898289037, 0.018482172064115145, 0.49458047194825655, 0.4926622850454668, 0.30669245157404174, 0.5039764455357336])\n",
      "0.4 (0.38589448364177026, 0.5058353414227253, [0.604190753914237, 0.1681992977762916, 0.4781281790437436, 0.021141987667173862, 0.504546850272811, 0.4882703407186743, 0.3162379574576325, 0.506440502283598])\n",
      "0.5 (0.3747651976451156, 0.4988806981021773, [0.59262686683651, 0.14600942478869028, 0.4004940852297021, 0.03437050495874025, 0.5066153866988069, 0.4736842105263158, 0.3360876369327074, 0.5082334651894522])\n",
      "0.6000000000000001 (0.3426857946964438, 0.4690231417449703, [0.5662002746510332, 0.10902188741918264, 0.30180449540961696, 0.06301351259591227, 0.4245366131734871, 0.43675404654204586, 0.3331268582755203, 0.5070286695047523])\n",
      "0.7000000000000001 (0.3072011775553471, 0.43735474027918386, [0.540085182744125, 0.08776609128881284, 0.24125520188955127, 0.0844880441446965, 0.2911130021164714, 0.387884213667562, 0.31980484830004574, 0.505212836291512])\n",
      "0.8 (0.28706203747869863, 0.41742475011763364, [0.5167835163101061, 0.07566868388229316, 0.21607371513219012, 0.10254362951979011, 0.22182896498947774, 0.35270465539988693, 0.30680085391887774, 0.5040922806769672])\n",
      "0.9 (0.2770370986828573, 0.4046062481285557, [0.4955802187417165, 0.06384943494129545, 0.20330176424741978, 0.11041322314049587, 0.21131910977647542, 0.33108108108108114, 0.2978125381889283, 0.5029394193454457])\n",
      "1.0 (0.2696310437723727, 0.3941083370168109, [0.47665763749852785, 0.052958317496515896, 0.1933884669986705, 0.11606663084363245, 0.2040696680264797, 0.3210061094501495, 0.2911299676454429, 0.5017715522195625])\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_probab_all+(1-w)*y_val_preds\n",
    "    y_ensemble_pred=np.argmax(y_ensemble,axis=1)\n",
    "    y_pred_new[y_preds_other_inds]=y_ensemble_pred[y_preds_other_inds]\n",
    "    print(w,metric_for_Exp(y_val,y_pred_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth validation predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:22<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'faces')\n",
    "dirpath=os.path.join(DATA_DIR,'EXPR_Classification_Challenge/Validation_Set')\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,expressions,scores=[],[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    if imagename in filename2featuresAll:\n",
    "                        X.append(filename2featuresAll[imagename][0])\n",
    "                        indices.append(i)\n",
    "                        expressions.append(int(line))\n",
    "                        scores.append(filename2featuresAll[imagename][1][AFFECTNET2MTL])\n",
    "        test_videos[fn]=(mlpModel.predict(np.array(X)),indices,np.array(expressions),np.array(scores))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0 Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "mean 2 Acc: 0.5069760312549014 F1: 0.3941767294737465\n",
      "median 2 Acc: 0.504380961886701 F1: 0.39215704057456224\n",
      "mean 7 Acc: 0.5185326451171346 F1: 0.40358838037718475\n",
      "median 7 Acc: 0.5156880498481456 F1: 0.40149206796741554\n"
     ]
    }
   ],
   "source": [
    "hyperparams=[(isMean,delta) for delta in [0,2,7]  for isMean in [1,0] if not (isMean==0 and delta==0)]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(hyperparams))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            if isMean:\n",
    "                proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            else:\n",
    "                proba=np.median(preds_proba[i1:i+delta+1],axis=0)\n",
    "            preds.append(np.argmax(proba))\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print('mean' if isMean else 'median',delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "5 Acc: 0.5147255928022472 F1: 0.40041647458913604\n",
      "15 Acc: 0.5290234269174283 F1: 0.41233375265784433\n",
      "25 Acc: 0.5352187985684342 F1: 0.41830667436931435\n",
      "50 Acc: 0.542572683330244 F1: 0.4236698679610459\n",
      "100 Acc: 0.5408224373689989 F1: 0.4197549134058517\n",
      "200 Acc: 0.5397387820284317 F1: 0.41970605922798776\n",
      "500 Acc: 0.5307736728786734 F1: 0.4031952312654022\n"
     ]
    }
   ],
   "source": [
    "#deltas=[0,1,5,7,15]\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            preds.append(np.argmax(proba))\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.49302753340082417 F1: 0.3830806902655762\n",
      "5 Acc: 0.5112928293385425 F1: 0.3984449112888923\n",
      "15 Acc: 0.5252484565040708 F1: 0.4102184763684504\n",
      "25 Acc: 0.5313440177947614 F1: 0.4164778611208603\n",
      "50 Acc: 0.5389545577688107 F1: 0.42223307250557535\n",
      "100 Acc: 0.5359317297135443 F1: 0.41796605670219833\n",
      "200 Acc: 0.5328589964781202 F1: 0.4164616736756614\n",
      "500 Acc: 0.5271769352515934 F1: 0.4067049624885466\n"
     ]
    }
   ],
   "source": [
    "#deltas=[0,1,5,7,15]\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            best_ind=np.argmax(proba)\n",
    "            best_ind_no_other=np.argmax(proba[:7])\n",
    "            if best_ind==7 and proba[best_ind]-proba[best_ind_no_other]<0.05:\n",
    "                best_ind=best_ind_no_other\n",
    "            preds.append(best_ind)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.546454593415368 F1: 0.4312567829587687\n"
     ]
    }
   ],
   "source": [
    "delta=50\n",
    "total_true=[]\n",
    "total_preds=[]\n",
    "weight=0.1\n",
    "def get_probab(x):\n",
    "    #print(x)\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    \n",
    "    y_ensemble=weight*scores+(1-weight)*y_pred_expr\n",
    "    #y_ensemble=weight*get_probab(scores)+(1-weight)*y_pred_expr\n",
    "    \n",
    "    y_pred_test_new=y_pred_expr.copy()\n",
    "    y_preds_test_other_inds=np.argmax(y_pred_expr,axis=1)!=7\n",
    "    y_pred_test_new[y_preds_test_other_inds]=y_ensemble[y_preds_test_other_inds]\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_test_new[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_test_new[cur_ind-1]+(1-w)*y_pred_test_new[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    preds=[]\n",
    "    for i in range(len(preds_proba)):\n",
    "        i1=max(i-delta,0)\n",
    "        proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "        preds.append(np.argmax(proba))\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_preds.append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "total_preds=np.array(total_preds)\n",
    "print('Acc:',(total_preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=total_preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022656 ['image_location,Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise,Other', '14-30-1920x1080/00001.jpg,', '14-30-1920x1080/00002.jpg,', '14-30-1920x1080/00003.jpg,', '14-30-1920x1080/00004.jpg,']\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_DIR,'test_set','CVPR_5th_ABAW_EXPR_test_set_sample.txt'),'r') as f:\n",
    "    test_set_sample=f.read().splitlines()\n",
    "print(len(test_set_sample),test_set_sample[:5])\n",
    "\n",
    "test_set_videos={}\n",
    "for s in test_set_sample[1:]:\n",
    "    videoname,img_name=s[:-1].split('/')\n",
    "    if videoname not in test_set_videos:\n",
    "        test_set_videos[videoname]=[]\n",
    "    test_set_videos[videoname].append(img_name)\n",
    "    \n",
    "print(len(test_set_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29b24e392504aa5b6c158871f729647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames,scores=[],[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][0])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            scores.append(filename2featuresAll[k][1][AFFECTNET2MTL])\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    test_videos[videoname]=(mlpModel.predict(np.array(X)),indices,filenames,np.array(scores))\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14-30-1920x1080': (5311, 0), '16-30-1920x1080': (5474, 0), '40-30-1280x720': (8767, 893), '43-30-406x720': (2129, 745), '44-25-426x240': (301, 0), '48-30-720x1280': (1543, 50), '55-25-1280x720': (1476, 30), '79-30-960x720': (2479, 16), '83-24-1920x1080': (5344, 0), '92-24-1920x1080': (8164, 0), '119-30-848x480': (1652, 0), '126-30-1080x1920': (4378, 216), '130-25-1280x720_left': (8086, 376), '130-25-1280x720_right': (8462, 0), '134-30-1280x720': (3681, 194), '136-30-1920x1080': (7209, 321), '166': (4515, 0), '167': (4718, 0), '168': (2979, 0), '169': (2863, 0), '171': (3931, 46), '172': (11333, 312), '175': (2503, 0), '176': (6416, 0), '177': (3127, 0), '178': (5841, 0), '179': (4451, 0), '181': (5848, 14), '182': (4356, 0), '183': (2770, 0), '184': (3791, 0), '185': (4053, 0), '186': (4158, 8), '187': (4377, 28), '188': (5987, 0), '189': (3855, 0), '190': (5421, 6), '191': (5249, 0), '192': (3592, 7), '193': (3984, 0), '194': (4537, 0), '195': (6118, 0), '196': (5453, 1), '197': (1784, 86), '199': (2850, 68), '200': (5040, 0), '201': (1359, 1), '202': (940, 0), '203': (3954, 11), '204': (5879, 46), '206': (4449, 27), '208': (5118, 41), '209': (2455, 401), '210': (3238, 0), '211': (2162, 0), '212': (4140, 422), '213': (6397, 0), '214': (2526, 29), '215': (2818, 591), '216': (456, 1), '218': (3787, 62), '219': (3576, 315), '220': (4321, 704), '221': (4355, 769), '223': (2794, 3), '224': (2077, 156), '226': (4027, 69), '227': (4417, 0), '228': (2155, 0), '229': (3563, 0), '230': (3893, 77), '231': (4179, 29), '232': (2372, 0), '233': (4328, 151), '234': (2905, 14), '235': (3683, 0), '236': (3673, 0), '237': (5434, 0), '238': (3013, 0), '239': (1964, 0), '240': (6791, 0), '241': (3512, 0), '242': (6558, 452), '243': (4121, 0), '244': (2286, 35), '245': (2530, 0), '246': (1345, 0), '247': (2270, 0), '248': (2267, 0), '249': (2621, 0), '250': (2928, 0), '251': (2106, 0), '252': (2726, 31), '253': (2277, 0), '254': (3386, 0), '255': (1677, 15), '256': (3336, 0), '257': (4389, 0), '258': (1446, 18), '259': (2393, 0), '260': (2387, 18), '261': (2866, 0), '262': (4753, 0), '264': (4745, 0), '265': (6691, 28), '266': (2465, 0), '267': (3841, 0), '268': (4364, 2), '269': (4697, 0), '270': (3935, 2), '271': (2224, 0), '272': (3205, 128), '273': (4619, 0), '274': (3526, 0), '275': (2447, 0), '276': (1583, 0), '277': (5038, 133), '278': (4287, 0), '279': (2212, 0), '280': (3857, 88), '281': (7011, 0), '283': (4615, 153), '284': (4054, 0), '285': (2988, 0), '286': (2678, 0), '287': (1273, 0), '288': (3199, 0), '289': (4203, 0), '290': (3159, 3), '291': (1818, 13), '292': (4698, 5), '293': (2110, 0), '294': (3285, 3), '295': (3769, 0), '296': (6486, 0), '297': (3286, 2), '298': (2836, 0), '299': (2337, 0), '303': (3897, 53), '304': (2694, 0), '305': (4579, 0), '306': (2297, 0), '307': (3311, 0), '308': (4634, 17), '309': (2498, 0), '311': (1930, 0), '312': (5090, 19), '313': (3140, 0), '314': (2203, 57), '315': (3932, 5), '317': (1685, 0), '318': (4046, 61), '319': (2137, 0), '320': (4587, 151), '321': (3401, 154), '322': (2429, 0), '323': (2936, 0), '324': (5472, 142), 'video9': (3773, 22), 'video11': (4132, 248), 'video12': (5580, 0), 'video13': (10551, 16), 'video14': (7583, 3), 'video15': (4288, 0), 'video16': (12486, 1), 'video17': (21938, 0), 'video18': (3784, 0), 'video19': (775, 10), 'video20': (11272, 0), 'video21': (6787, 22), 'video22': (10458, 12), 'video23': (8783, 7), 'video25': (3641, 4), 'video26': (11021, 0), 'video27': (16410, 9), 'video28': (8728, 0), 'video30': (8209, 5), 'video32': (2751, 25), 'video33': (7538, 16), 'video35': (3568, 0), 'video36': (2386, 39), 'video37': (8820, 367), 'video38': (2936, 9), 'video39': (10671, 8), 'video40': (5877, 0), 'video41': (3466, 29), 'video42': (9217, 10), 'video44': (7778, 8), 'video45_1': (805, 8), 'video45_2': (1096, 0), 'video45_4': (1039, 0), 'video46': (3167, 6), 'video49_right': (6071, 51), 'video51': (4406, 2), 'video52': (10671, 9), 'video53': (7967, 13), 'video54': (3591, 0), 'video56': (10661, 34), 'video57': (8273, 106), 'video59': (6693, 9), 'video60': (1906, 13), 'video62': (5562, 17), 'video64': (6087, 13), 'video65': (3313, 1259), 'video69': (8609, 13), 'video70': (11826, 42), 'video71': (11204, 0), 'video75': (580, 60), 'video76': (3912, 362), 'video77': (3004, 0), 'video78': (419, 0), 'video80': (369, 50), 'video81': (7709, 724), 'video82': (10362, 309), 'video83': (2490, 212), 'video84': (525, 0), 'video85': (7946, 0), 'video86_1': (1770, 1), 'video86_2': (886, 0), 'video86_3': (402, 0), 'video87': (1808, 14), 'video88': (8828, 22), 'video89': (2241, 0), 'video90': (3518, 52), 'video91': (710, 0), 'video92': (2476, 77), 'video95': (9455, 1400), 'video96': (7905, 141)}\n"
     ]
    }
   ],
   "source": [
    "print(test_videos_num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=50\n",
    "resdir=os.path.join(DATA_DIR,'test_set/test_results/EXPR')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(resdir,'predictions_1_emb.txt'), 'w') as f:\n",
    "with open(os.path.join(resdir,'predictions_5_emb_train_val.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_expr,indices,filenames,scores) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        preds_proba=[]\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_pred_expr[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "        pred=y_pred_expr[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds_proba.append(pred)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(np.argmax(proba))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.1\n",
    "with open(os.path.join(resdir,'predictions_2_emb_scores.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_expr,indices,filenames,scores) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        preds_proba=[]\n",
    "        y_ensemble=weight*scores+(1-weight)*y_pred_expr\n",
    "        #y_ensemble=weight*get_probab(scores)+(1-weight)*y_pred_expr\n",
    "        y_pred_test_new=y_pred_expr.copy()\n",
    "        y_preds_test_other_inds=np.argmax(y_pred_expr,axis=1)!=7\n",
    "        y_pred_test_new[y_preds_test_other_inds]=y_ensemble[y_preds_test_other_inds]\n",
    "\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds_proba.append(y_pred_test_new[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_pred_test_new[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_pred_test_new[cur_ind-1]+(1-w)*y_pred_test_new[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "        pred=y_pred_test_new[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds_proba.append(pred)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(np.argmax(proba))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304880d9ec574382a525aa28209fdc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    indices,filenames,test_scores=[],[],[]\n",
    "    imgs=[]\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        filepath=os.path.join(data_dir,videoname,img_name)   \n",
    "        if os.path.exists(filepath):\n",
    "            img = Image.open(filepath)\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                imgs.append(img_tensor)\n",
    "                indices.append(int(img_name[:-4]))\n",
    "                filenames.append(k)\n",
    "                if len(imgs)>=64: #96: #48: #32:        \n",
    "                    scores = model(torch.stack(imgs, dim=0).to(device))\n",
    "                    scores=scores.data.cpu().numpy()\n",
    "                    if len(test_scores)==0:\n",
    "                        test_scores=scores\n",
    "                    else:\n",
    "                        test_scores=np.concatenate((test_scores,scores),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "    if len(imgs)>0:        \n",
    "        scores = model(torch.stack(imgs, dim=0).to(device))\n",
    "        scores=scores.data.cpu().numpy()\n",
    "\n",
    "        if len(test_scores)==0:\n",
    "            test_scores=scores\n",
    "        else:\n",
    "            test_scores=np.concatenate((test_scores,scores),axis=0)\n",
    "        imgs=[]\n",
    "    test_videos[videoname]=(test_scores,indices,filenames)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "FT_TEST_PREDS='enet_b0_vgaf_finetuned_expr_test.pickle' \n",
    "if True:\n",
    "    with open(FT_TEST_PREDS, 'wb') as handle:\n",
    "        pickle.dump(test_videos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    test_videos_ft=test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "with open(FT_TEST_PREDS, 'rb') as handle:\n",
    "    test_videos_ft=pickle.load(handle)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(resdir,'predictions_3_ft.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_ft,indices,filenames) in test_videos_ft.items():\n",
    "        cur_ind=0\n",
    "        preds_proba=[]\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds_proba.append(y_pred_ft[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_pred_ft[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_pred_ft[cur_ind-1]+(1-w)*y_pred_ft[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "        pred=y_pred_ft[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds_proba.append(pred)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(np.argmax(proba))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.8\n",
    "with open(os.path.join(resdir,'predictions_4_emb_ft.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_expr,indices,filenames,scores) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        preds_proba=[]\n",
    "        y_pred_ft=test_videos_ft[videoname][0]\n",
    "        y_ensemble=weight*y_pred_expr+(1-weight)*y_pred_ft\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds_proba.append(y_ensemble[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "        pred=y_ensemble[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds_proba.append(pred)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(np.argmax(proba))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valence-Arousal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1653757, 10) (1653757, 2) 26387\n",
      "(376323, 10) (376323, 2) 5698\n"
     ]
    }
   ],
   "source": [
    "def get_image2VA(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'VA_Estimation_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        splitted_line=line.split(',')\n",
    "                        valence=float(splitted_line[0])\n",
    "                        arousal=float(splitted_line[1])\n",
    "                        if valence>=-1 and arousal>=-1:\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if imagename in filename2featuresAll:\n",
    "                                X.append(filename2featuresAll[imagename][1])\n",
    "                                y.append((valence,arousal))\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2VA('Train_Set')\n",
    "X_val,y_val=get_image2VA('Validation_Set')\n",
    "TRAIN_VAL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2030080, 10) (2030080, 2)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_train=np.concatenate((y_train,y_val))\n",
    "    print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ccc_for_val_preds(y_val_preds):\n",
    "    gt_V=y_val[:,0]\n",
    "    gt_A=y_val[:,1]\n",
    "    pred_V=y_val_preds[:,0]\n",
    "    pred_A=y_val_preds[:,1]\n",
    "    print(metric_for_VA(gt_V,gt_A,pred_V,pred_A))\n",
    "    print(CCC_numpy(gt_V,pred_V),CCC_numpy(gt_A,pred_A))\n",
    "\n",
    "def print_ccc():\n",
    "    y_val_preds=mlpModel.predict(X_val)\n",
    "    print_ccc_for_val_preds(y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376323, 2)\n",
      "(0.28258248565203836, 0.3319371832442485, 0.3072598344481434)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "res=RandomForestRegressor(n_estimators=10,max_depth=3, n_jobs=-1)\n",
    "\n",
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "\n",
    "res.fit(X_train, y_train)\n",
    "y_val_preds = res.predict(X_val)\n",
    "print(y_val_preds.shape)\n",
    "\n",
    "gt_V=y_val[:,0]\n",
    "gt_A=y_val[:,1]\n",
    "pred_V=y_val_preds[:,0]\n",
    "pred_A=y_val_preds[:,1]\n",
    "print(metric_for_VA(gt_V,gt_A,pred_V,pred_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "if False:\n",
    "    automl = TabularAutoML(\n",
    "        task = Task(\n",
    "            name = 'reg',\n",
    "            metric = lambda y_true, y_pred: CCC_score(y_true, y_pred),\n",
    "            greater_is_better =True),\n",
    "        timeout=600#,cpu_limit=4\n",
    "    )\n",
    "else:\n",
    "    automl = TabularAutoML(\n",
    "        task = Task(\n",
    "            name = 'reg'),\n",
    "        timeout=1200#,cpu_limit=4\n",
    "    )\n",
    "\n",
    "import pandas as pd\n",
    "def get_df(X,y):\n",
    "    #xy=np.concatenate((y.reshape((-1,1)),X),axis=1)\n",
    "    df=pd.DataFrame(data=X,columns=['f'+str(i) for i in range(X.shape[1])])\n",
    "    df['y']=y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0 -0.856850 -0.980964 -2.897677  1.878489  1.875324 -0.136829 -1.996574   \n",
      "1 -0.967150 -1.147540 -2.688983  1.967857  1.798332 -0.150944 -1.944596   \n",
      "2 -1.044203 -0.984244 -2.608128  1.913518  1.709237 -0.250167 -1.958941   \n",
      "3 -1.181610 -0.557486 -1.883281  1.390435  1.850232 -0.227555 -2.620486   \n",
      "4 -0.938104 -0.570756 -1.308646  1.305721  1.405185  0.012821 -2.574656   \n",
      "\n",
      "         f7        f8        f9      y  \n",
      "0  4.760030  0.507206  0.745402  0.701  \n",
      "1  4.828946  0.498256  0.767358  0.701  \n",
      "2  4.655427  0.483607  0.754648  0.701  \n",
      "3  4.311441  0.534481  0.691723  0.701  \n",
      "4  3.889822  0.449230  0.653974  0.701  \n",
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0  2.257816 -0.336461  1.935838 -2.232281 -0.734275  1.416191 -1.842518   \n",
      "1  2.543057 -0.586280  1.028857 -1.770419 -0.725319  1.601804 -1.894101   \n",
      "2  2.513208 -0.559739  1.128592 -1.599575 -0.891215  1.550411 -2.040169   \n",
      "3  2.663307 -0.487385  1.403275 -1.855448 -1.041836  1.614423 -1.727581   \n",
      "4  2.546333 -0.551208  1.510843 -1.734837 -0.905420  1.587841 -1.996134   \n",
      "\n",
      "         f7        f8        f9    y  \n",
      "0  1.522441 -0.245796  0.520590  0.0  \n",
      "1  2.318928 -0.241154  0.581099  0.0  \n",
      "2  2.037113 -0.252706  0.578838  0.0  \n",
      "3  1.604249 -0.320088  0.535692  0.0  \n",
      "4  1.700374 -0.291751  0.540065  0.0  \n",
      "[16:46:53] Stdout logging level is INFO.\n",
      "[16:46:53] Task: reg\n",
      "\n",
      "[16:46:53] Start automl preset with listed constraints:\n",
      "[16:46:53] - time: 1200.00 seconds\n",
      "[16:46:53] - CPU: 4 cores\n",
      "[16:46:53] - memory: 16 GB\n",
      "\n",
      "[16:46:53] \u001b[1mTrain data shape: (1653757, 11)\u001b[0m\n",
      "\n",
      "[16:46:56] Layer \u001b[1m1\u001b[0m train process start. Time left 1196.84 secs\n",
      "[16:46:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:46:57] Time left 1195.96 secs\n",
      "\n",
      "[16:47:03] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:47:10] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:47:10] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:52:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:52:23] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:52:23] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:57:25] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:57:28] Time left 564.77 secs\n",
      "\n",
      "[16:57:28] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:57:28] Blending: optimization starts with equal weights and score \u001b[1m-0.12227247658618863\u001b[0m\n",
      "[16:57:29] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.12214332476818883\u001b[0m, weights = \u001b[1m[0.1300542  0.2591489  0.46940076 0.         0.14139616]\u001b[0m\n",
      "[16:57:29] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.12212674432245148\u001b[0m, weights = \u001b[1m[0.1813051  0.26551464 0.38086453 0.         0.17231566]\u001b[0m\n",
      "[16:57:30] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.12212664573036092\u001b[0m, weights = \u001b[1m[0.18225773 0.25620162 0.38587382 0.         0.17566684]\u001b[0m\n",
      "[16:57:30] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-0.12212664393889239\u001b[0m, weights = \u001b[1m[0.18256697 0.2550815  0.38662153 0.         0.17573005]\u001b[0m\n",
      "[16:57:30] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-0.12212664373791898\u001b[0m, weights = \u001b[1m[0.18230385 0.2551636  0.386746   0.         0.1757866 ]\u001b[0m\n",
      "[16:57:30] \u001b[1mAutoml preset training completed in 637.18 seconds\u001b[0m\n",
      "\n",
      "[16:57:30] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.18230 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.25516 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.38675 * (1 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.17579 * (1 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "oof_pred:\n",
      "array([[ 0.09696145],\n",
      "       [ 0.13545461],\n",
      "       [ 0.14065892],\n",
      "       [ 0.05365848],\n",
      "       [ 0.07476036],\n",
      "       [ 0.00080519],\n",
      "       [ 0.031294  ],\n",
      "       [-0.03026773],\n",
      "       [ 0.01208194],\n",
      "       [ 0.0241767 ]], dtype=float32)\n",
      "Shape = (376323, 1)\n",
      "(376323, 1)\n",
      "(376323,) (376323, 1)\n",
      "Valence: 0.37053283592957337\n"
     ]
    }
   ],
   "source": [
    "#Valence\n",
    "df_train=get_df(X_train,y_train[:,0])\n",
    "print(df_train.head())\n",
    "\n",
    "df_val=get_df(X_val,y_val[:,0])\n",
    "print(df_val.head())\n",
    "\n",
    "oof_pred = automl.fit_predict(df_train, roles = {'target': 'y'}, valid_data=df_val,verbose=1)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))\n",
    "\n",
    "y_val_preds_v = automl.predict(df_val)\n",
    "print(y_val_preds_v.shape)\n",
    "gt_V=y_val[:,0]\n",
    "print(gt_V.shape,y_val_preds_v.data.shape)\n",
    "print('Valence:',CCC_score(gt_V, y_val_preds_v.data[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376323,) (376323, 1)\n",
      "Valence: 0.3750780432302715\n"
     ]
    }
   ],
   "source": [
    "print(gt_V.shape,y_val_preds.data.shape)\n",
    "print('Valence:',CCC_score(gt_V, y_val_preds.data[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0 -0.856850 -0.980964 -2.897677  1.878489  1.875324 -0.136829 -1.996574   \n",
      "1 -0.967150 -1.147540 -2.688983  1.967857  1.798332 -0.150944 -1.944596   \n",
      "2 -1.044203 -0.984244 -2.608128  1.913518  1.709237 -0.250167 -1.958941   \n",
      "3 -1.181610 -0.557486 -1.883281  1.390435  1.850232 -0.227555 -2.620486   \n",
      "4 -0.938104 -0.570756 -1.308646  1.305721  1.405185  0.012821 -2.574656   \n",
      "\n",
      "         f7        f8        f9      y  \n",
      "0  4.760030  0.507206  0.745402  0.385  \n",
      "1  4.828946  0.498256  0.767358  0.385  \n",
      "2  4.655427  0.483607  0.754648  0.385  \n",
      "3  4.311441  0.534481  0.691723  0.385  \n",
      "4  3.889822  0.449230  0.653974  0.385  \n",
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0  2.257816 -0.336461  1.935838 -2.232281 -0.734275  1.416191 -1.842518   \n",
      "1  2.543057 -0.586280  1.028857 -1.770419 -0.725319  1.601804 -1.894101   \n",
      "2  2.513208 -0.559739  1.128592 -1.599575 -0.891215  1.550411 -2.040169   \n",
      "3  2.663307 -0.487385  1.403275 -1.855448 -1.041836  1.614423 -1.727581   \n",
      "4  2.546333 -0.551208  1.510843 -1.734837 -0.905420  1.587841 -1.996134   \n",
      "\n",
      "         f7        f8        f9     y  \n",
      "0  1.522441 -0.245796  0.520590  0.14  \n",
      "1  2.318928 -0.241154  0.581099  0.14  \n",
      "2  2.037113 -0.252706  0.578838  0.14  \n",
      "3  1.604249 -0.320088  0.535692  0.14  \n",
      "4  1.700374 -0.291751  0.540065  0.14  \n",
      "[16:37:09] Stdout logging level is INFO.\n",
      "[16:37:09] Task: reg\n",
      "\n",
      "[16:37:09] Start automl preset with listed constraints:\n",
      "[16:37:09] - time: 1200.00 seconds\n",
      "[16:37:09] - CPU: 4 cores\n",
      "[16:37:09] - memory: 16 GB\n",
      "\n",
      "[16:37:09] \u001b[1mTrain data shape: (1653757, 11)\u001b[0m\n",
      "\n",
      "[16:37:12] Layer \u001b[1m1\u001b[0m train process start. Time left 1196.76 secs\n",
      "[16:37:13] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[16:37:13] Time left 1195.97 secs\n",
      "\n",
      "[16:37:19] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:37:24] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[16:37:24] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:42:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[16:42:33] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:42:33] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[16:45:41] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[16:45:42] Time left 686.63 secs\n",
      "\n",
      "[16:45:42] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:45:42] Blending: optimization starts with equal weights and score \u001b[1m-0.05218975424373731\u001b[0m\n",
      "[16:45:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.05217784032118552\u001b[0m, weights = \u001b[1m[0.17490457 0.17770986 0.18210869 0.11159484 0.353682  ]\u001b[0m\n",
      "[16:45:43] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.05217202482969164\u001b[0m, weights = \u001b[1m[0.16813712 0.21569492 0.18510999 0.         0.431058  ]\u001b[0m\n",
      "[16:45:43] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.05217189113469734\u001b[0m, weights = \u001b[1m[0.15961032 0.21497451 0.19617607 0.         0.42923915]\u001b[0m\n",
      "[16:45:44] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-0.05217187570408276\u001b[0m, weights = \u001b[1m[0.16131532 0.21294816 0.19860573 0.         0.42713085]\u001b[0m\n",
      "[16:45:44] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-0.05217187570408276\u001b[0m, weights = \u001b[1m[0.16131532 0.21294816 0.19860573 0.         0.42713085]\u001b[0m\n",
      "[16:45:44] Blending: no score update. Terminated\n",
      "\n",
      "[16:45:44] \u001b[1mAutoml preset training completed in 515.33 seconds\u001b[0m\n",
      "\n",
      "[16:45:44] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.16132 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.21295 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.19861 * (1 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.42713 * (1 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "oof_pred:\n",
      "array([[0.2796959 ],\n",
      "       [0.29722407],\n",
      "       [0.28203318],\n",
      "       [0.2721067 ],\n",
      "       [0.27553916],\n",
      "       [0.29188573],\n",
      "       [0.27646416],\n",
      "       [0.27547148],\n",
      "       [0.27743182],\n",
      "       [0.27863595]], dtype=float32)\n",
      "Shape = (376323, 1)\n",
      "(376323, 1)\n",
      "Arousal: 0.4418819604216678\n"
     ]
    }
   ],
   "source": [
    "#Arousal\n",
    "df_train=get_df(X_train,y_train[:,1])\n",
    "print(df_train.head())\n",
    "\n",
    "df_val=get_df(X_val,y_val[:,1])\n",
    "print(df_val.head())\n",
    "\n",
    "oof_pred = automl.fit_predict(df_train, roles = {'target': 'y'}, valid_data=df_val,verbose=1)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))\n",
    "\n",
    "y_val_preds_a = automl.predict(df_val)\n",
    "print(y_val_preds_a.shape)\n",
    "gt_A=y_val[:,1]\n",
    "print('Arousal:',CCC_score(gt_A, y_val_preds_a.data[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0 -0.856850 -0.980964 -2.897677  1.878489  1.875324 -0.136829 -1.996574   \n",
      "1 -0.967150 -1.147540 -2.688983  1.967857  1.798332 -0.150944 -1.944596   \n",
      "2 -1.044203 -0.984244 -2.608128  1.913518  1.709237 -0.250167 -1.958941   \n",
      "3 -1.181610 -0.557486 -1.883281  1.390435  1.850232 -0.227555 -2.620486   \n",
      "4 -0.938104 -0.570756 -1.308646  1.305721  1.405185  0.012821 -2.574656   \n",
      "\n",
      "         f7        f8        f9     y1     y2  \n",
      "0  4.760030  0.507206  0.745402  0.701  0.385  \n",
      "1  4.828946  0.498256  0.767358  0.701  0.385  \n",
      "2  4.655427  0.483607  0.754648  0.701  0.385  \n",
      "3  4.311441  0.534481  0.691723  0.701  0.385  \n",
      "4  3.889822  0.449230  0.653974  0.701  0.385  \n",
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0  2.257816 -0.336461  1.935838 -2.232281 -0.734275  1.416191 -1.842518   \n",
      "1  2.543057 -0.586280  1.028857 -1.770419 -0.725319  1.601804 -1.894101   \n",
      "2  2.513208 -0.559739  1.128592 -1.599575 -0.891215  1.550411 -2.040169   \n",
      "3  2.663307 -0.487385  1.403275 -1.855448 -1.041836  1.614423 -1.727581   \n",
      "4  2.546333 -0.551208  1.510843 -1.734837 -0.905420  1.587841 -1.996134   \n",
      "\n",
      "         f7        f8        f9   y1    y2  \n",
      "0  1.522441 -0.245796  0.520590  0.0  0.14  \n",
      "1  2.318928 -0.241154  0.581099  0.0  0.14  \n",
      "2  2.037113 -0.252706  0.578838  0.0  0.14  \n",
      "3  1.604249 -0.320088  0.535692  0.0  0.14  \n",
      "4  1.700374 -0.291751  0.540065  0.0  0.14  \n",
      "[09:12:57] Stdout logging level is INFO.\n",
      "[09:12:57] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[09:12:57] Task: multi:reg\n",
      "\n",
      "[09:12:57] Start automl preset with listed constraints:\n",
      "[09:12:57] - time: 1200.00 seconds\n",
      "[09:12:57] - CPU: 4 cores\n",
      "[09:12:57] - memory: 16 GB\n",
      "\n",
      "[09:12:57] \u001b[1mTrain data shape: (1653757, 12)\u001b[0m\n",
      "\n",
      "[09:13:02] Layer \u001b[1m1\u001b[0m train process start. Time left 1195.33 secs\n",
      "[09:33:34] \u001b[1mLvl_0_Pipe_0_Mod_0_RFSklearn\u001b[0m fitting and predicting completed\n",
      "[09:33:34] Time left -36.42 secs\n",
      "\n",
      "[09:33:34] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "[09:33:34] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[09:33:34] \u001b[1mAutoml preset training completed in 1236.43 seconds\u001b[0m\n",
      "\n",
      "[09:33:34] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_RFSklearn) \n",
      "\n",
      "oof_pred:\n",
      "array([[0.13198842, 0.2814972 ],\n",
      "       [0.20883214, 0.2616655 ],\n",
      "       [0.18320854, 0.27665052],\n",
      "       [0.26213622, 0.30856887],\n",
      "       [0.23022656, 0.29256853],\n",
      "       [0.10743932, 0.34168473],\n",
      "       [0.08179417, 0.30655575],\n",
      "       [0.09170152, 0.26083595],\n",
      "       [0.04025571, 0.3030013 ],\n",
      "       [0.08554899, 0.24478228]], dtype=float32)\n",
      "Shape = (376323, 2)\n"
     ]
    }
   ],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "automl = TabularAutoML(\n",
    "    task = Task(\n",
    "        name = 'multi:reg'),\n",
    "    timeout=1200#,cpu_limit=4\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "def get_df_multi(X,y1,y2):\n",
    "    #xy=np.concatenate((y.reshape((-1,1)),X),axis=1)\n",
    "    df=pd.DataFrame(data=X,columns=['f'+str(i) for i in range(X.shape[1])])\n",
    "    df['y1']=y1\n",
    "    df['y2']=y2\n",
    "    return df\n",
    "\n",
    "#Valence\n",
    "df_train=get_df_multi(X_train,y_train[:,0],y_train[:,1])\n",
    "print(df_train.head())\n",
    "\n",
    "df_val=get_df_multi(X_val,y_val[:,0],y_val[:,1])\n",
    "print(df_val.head())\n",
    "\n",
    "oof_pred = automl.fit_predict(df_train, roles = {'target': ['y1','y2']}, valid_data=df_val,verbose=1)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376323, 2)\n",
      "(0.37270991068427667, 0.43333181223266476, 0.4030208614584707)\n",
      "0.3727109115028784 0.43333298467999354\n"
     ]
    }
   ],
   "source": [
    "y_val_lama = automl.predict(df_val).data\n",
    "print(y_val_lama.shape)\n",
    "print_ccc_for_val_preds(y_val_lama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376323, 2)\n",
      "(0.37270991068427667, 0.43333181223266476, 0.4030208614584707)\n",
      "0.3727109115028784 0.43333298467999354\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.DataFrame(data=X_val,columns=['f'+str(i) for i in range(X_val.shape[1])])\n",
    "y_test_lama = automl.predict(df_test).data\n",
    "print(y_test_lama.shape)\n",
    "print_ccc_for_val_preds(y_test_lama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024 #512 #128\n",
    "mlpModel=Sequential()\n",
    "if True:\n",
    "    mlpModel.add(Dense(2, input_shape=X_train.shape[1:],activation='tanh',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_train.shape[1:],activation='relu')) #256\n",
    "    mlpModel.add(Dense(2,activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1615/1615 [==============================] - 9s 5ms/step - loss: 0.8139 - mae: 0.6754 - mse: 0.6544 - val_loss: 0.7772 - val_mae: 0.2682 - val_mse: 0.1216\n",
      "Epoch 2/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5022 - mae: 0.2752 - mse: 0.1256 - val_loss: 0.7775 - val_mae: 0.2706 - val_mse: 0.1237\n",
      "Epoch 3/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5016 - mae: 0.2751 - mse: 0.1254 - val_loss: 0.7767 - val_mae: 0.2705 - val_mse: 0.1237\n",
      "Epoch 4/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5022 - mae: 0.2752 - mse: 0.1254 - val_loss: 0.7767 - val_mae: 0.2689 - val_mse: 0.1220\n",
      "Epoch 5/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5017 - mae: 0.2750 - mse: 0.1253 - val_loss: 0.7784 - val_mae: 0.2719 - val_mse: 0.1247\n",
      "Epoch 6/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5019 - mae: 0.2752 - mse: 0.1254 - val_loss: 0.7764 - val_mae: 0.2710 - val_mse: 0.1243\n",
      "Epoch 7/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5022 - mae: 0.2753 - mse: 0.1255 - val_loss: 0.7769 - val_mae: 0.2706 - val_mse: 0.1239\n",
      "Epoch 8/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5016 - mae: 0.2756 - mse: 0.1258 - val_loss: 0.7771 - val_mae: 0.2704 - val_mse: 0.1234\n",
      "Epoch 9/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5020 - mae: 0.2752 - mse: 0.1255 - val_loss: 0.7770 - val_mae: 0.2700 - val_mse: 0.1231\n",
      "Epoch 10/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5013 - mae: 0.2751 - mse: 0.1255 - val_loss: 0.7784 - val_mae: 0.2713 - val_mse: 0.1240\n",
      "Epoch 11/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5024 - mae: 0.2755 - mse: 0.1257 - val_loss: 0.7784 - val_mae: 0.2712 - val_mse: 0.1245\n",
      "Epoch 12/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5026 - mae: 0.2753 - mse: 0.1257 - val_loss: 0.7769 - val_mae: 0.2691 - val_mse: 0.1225\n",
      "Epoch 13/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5020 - mae: 0.2753 - mse: 0.1256 - val_loss: 0.7777 - val_mae: 0.2704 - val_mse: 0.1234\n",
      "Epoch 14/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5020 - mae: 0.2755 - mse: 0.1256 - val_loss: 0.7772 - val_mae: 0.2718 - val_mse: 0.1244\n",
      "Epoch 15/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5025 - mae: 0.2754 - mse: 0.1256 - val_loss: 0.7775 - val_mae: 0.2721 - val_mse: 0.1248\n",
      "Epoch 16/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5019 - mae: 0.2751 - mse: 0.1254 - val_loss: 0.7757 - val_mae: 0.2691 - val_mse: 0.1227\n",
      "Epoch 17/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5023 - mae: 0.2753 - mse: 0.1256 - val_loss: 0.7789 - val_mae: 0.2728 - val_mse: 0.1251\n",
      "Epoch 18/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5025 - mae: 0.2753 - mse: 0.1255 - val_loss: 0.7754 - val_mae: 0.2681 - val_mse: 0.1219\n",
      "Epoch 19/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5025 - mae: 0.2752 - mse: 0.1255 - val_loss: 0.7787 - val_mae: 0.2683 - val_mse: 0.1216\n",
      "Epoch 20/20\n",
      "1615/1615 [==============================] - 8s 5ms/step - loss: 0.5021 - mae: 0.2753 - mse: 0.1256 - val_loss: 0.7770 - val_mae: 0.2689 - val_mse: 0.1226\n",
      "0.7754276394844055\n"
     ]
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(lr=1e-3), loss=CCC_VA, metrics=['mae','mse'])\n",
    "#mlpModel.compile(optimizer=Adam(lr=1e-3), loss='mae', metrics=['mse'])\n",
    "mlpModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "mlpModel.fit(X_train,y_train, batch_size=batch_size, epochs=1 if TRAIN_VAL else 20, verbose=1, callbacks=[save_best_model], validation_data=(X_val,y_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.441334608674687, 0.5202774992344983, 0.48080605395459264)\n",
      "0.44133577393795315 0.5202789017080741\n",
      "Best weights:\n",
      "(0.442104359857453, 0.5205547252402459, 0.48132954254884946)\n",
      "0.4421055516316734 0.5205560853612039\n"
     ]
    }
   ],
   "source": [
    "print_ccc()\n",
    "print('Best weights:')\n",
    "mlpModel.set_weights(best_model_weights)\n",
    "print_ccc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
      "0.44533243932761624 0.5212474631941809\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    #mlpModel.save_weights('va_enet0_mtl.h5') #(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
    "    mlpModel.save_weights('va_enet0_vgaf.h5')#(0.442104359857453, 0.5205547252402459, 0.48132954254884946)\n",
    "else:\n",
    "    mlpModel.load_weights('va_enet0_mtl.h5')\n",
    "    #mlpModel.load_weights('../va_enet0_vgaf.h5')\n",
    "print_ccc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VA only emotions\n",
    "\n",
    "enet_b0_8_best_vgaf\n",
    "logreg: (0.4436768680313978, 0.5195607326809414, 0.48161880035616955)\n",
    "new: (0.4433857992438458, 0.5198270222465867, 0.48160641074521626)\n",
    "\n",
    "enet_b0_8_va_mtl\n",
    "logreg:(0.44436749382135277, 0.5207544767285259, 0.48256098527493935)\n",
    "new: (0.44533125143390107, 0.5212460625489065, 0.4832886569914038)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds=mlpModel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds_mt=y_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
      "0.44533243932761624 0.5212474631941809\n",
      "0.1\n",
      "(0.4472432373858708, 0.5243837427478731, 0.48581349006687197)\n",
      "0.4472444059862267 0.5243851355437936\n",
      "0.2\n",
      "(0.4486640037079531, 0.5268238739648625, 0.4877439388364078)\n",
      "0.4486652166588616 0.526825269082366\n",
      "0.30000000000000004\n",
      "(0.44958588759643003, 0.5285505539287618, 0.48906822076259593)\n",
      "0.4495870923742291 0.5285519721614755\n",
      "0.4\n",
      "(0.45000417068117793, 0.5295536347691299, 0.4897789027251539)\n",
      "0.4500053909838998 0.5295550471389583\n",
      "0.5\n",
      "(0.4499177402672424, 0.5298290663257271, 0.48987340329648477)\n",
      "0.4499189281574363 0.5298304787130718\n",
      "0.6000000000000001\n",
      "(0.44932871359207455, 0.5293784963776423, 0.48935360498485847)\n",
      "0.44932990405292494 0.52937990723402\n",
      "0.7000000000000001\n",
      "(0.4482425165740871, 0.5282096289840014, 0.48822607277904423)\n",
      "0.448243713587009 0.5282110467919442\n",
      "0.8\n",
      "(0.44666803339002187, 0.5263359082754697, 0.4865019708327458)\n",
      "0.4466692113810503 0.526337302635638\n",
      "0.9\n",
      "(0.444617073323084, 0.5237763519201131, 0.4841967126215985)\n",
      "0.4446182273865714 0.5237777286424512\n",
      "1.0\n",
      "(0.442104359857453, 0.5205547252402459, 0.48132954254884946)\n",
      "0.4421055516316734 0.5205560853612039\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_preds_mt\n",
    "    print(w)\n",
    "    print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VA predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.40439760158295573, 0.24760572372463172, 0.3260016626537937)\n",
      "0.4043986703619577 0.24760637766404267\n"
     ]
    }
   ],
   "source": [
    "va_val=X_val[:,-2:]\n",
    "print_ccc_for_val_preds(va_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4622121581507096 0.21993529738752612\n"
     ]
    }
   ],
   "source": [
    "va_train=X_train[:,-2:]\n",
    "print(CCC_numpy(y_train[:,0],va_train[:,0]),CCC_numpy(y_train[:,1],va_train[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(0.40439760158295573, 0.24760572372463172, 0.3260016626537937)\n",
      "0.4043986703619577 0.24760637766404267\n",
      "0.1\n",
      "(0.4110179099715824, 0.28532816169609304, 0.34817303583383774)\n",
      "0.4110190318160167 0.2853289110925135\n",
      "0.2\n",
      "(0.41722193234471355, 0.3241398315263659, 0.3706808819355397)\n",
      "0.4172230490479516 0.3241406976657168\n",
      "0.30000000000000004\n",
      "(0.42295215206955106, 0.3628579836388764, 0.39290506785421375)\n",
      "0.422953263607878 0.36285894350585873\n",
      "0.4\n",
      "(0.42815149525389584, 0.4000751525514553, 0.4141133239026756)\n",
      "0.4281526386078791 0.40007620822274853\n",
      "0.5\n",
      "(0.4327644223834461, 0.4342824222043513, 0.43352342229389873)\n",
      "0.4327655800176927 0.43428355854628065\n",
      "0.6000000000000001\n",
      "(0.4367377368849927, 0.4640391415563975, 0.4503884392206951)\n",
      "0.43673892123505276 0.46404036907212104\n",
      "0.7000000000000001\n",
      "(0.44002238392203763, 0.48815666718291845, 0.46408952555247807)\n",
      "0.4400235568344202 0.4881579564997686\n",
      "0.8\n",
      "(0.44257385531515087, 0.5058499274032312, 0.47421189135919106)\n",
      "0.4425750293078031 0.5058512494390425\n",
      "0.9\n",
      "(0.4443538675475203, 0.5168194601879664, 0.4805866638677434)\n",
      "0.4443550392568737 0.5168208492269166\n",
      "1.0\n",
      "(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
      "0.44533243932761624 0.5212474631941809\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_val_preds+(1-w)*va_val\n",
    "    print(w)\n",
    "    print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(0.40439760158295573, 0.5212460625489065, 0.4628218320659311)\n",
      "0.4043986703619577 0.5212474631941809\n",
      "0.1\n",
      "(0.4110179099715824, 0.5212460625489065, 0.46613198626024444)\n",
      "0.4110190318160167 0.5212474631941809\n",
      "0.2\n",
      "(0.41722193234471355, 0.5212460625489065, 0.46923399744681005)\n",
      "0.4172230490479516 0.5212474631941809\n",
      "0.30000000000000004\n",
      "(0.42295215206955106, 0.5212460625489065, 0.47209910730922877)\n",
      "0.422953263607878 0.5212474631941809\n",
      "0.4\n",
      "(0.42815149525389584, 0.5212460625489065, 0.47469877890140116)\n",
      "0.4281526386078791 0.5212474631941809\n",
      "0.5\n",
      "(0.4327644223834461, 0.5212460625489065, 0.47700524246617626)\n",
      "0.4327655800176927 0.5212474631941809\n",
      "0.6000000000000001\n",
      "(0.4367377368849927, 0.5212460625489065, 0.47899189971694955)\n",
      "0.43673892123505276 0.5212474631941809\n",
      "0.7000000000000001\n",
      "(0.44002238392203763, 0.5212460625489065, 0.48063422323547206)\n",
      "0.4400235568344202 0.5212474631941809\n",
      "0.8\n",
      "(0.44257385531515087, 0.5212460625489065, 0.4819099589320287)\n",
      "0.4425750293078031 0.5212474631941809\n",
      "0.9\n",
      "(0.4443538675475203, 0.5212460625489065, 0.48279996504821343)\n",
      "0.4443550392568737 0.5212474631941809\n",
      "1.0\n",
      "(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
      "0.44533243932761624 0.5212474631941809\n"
     ]
    }
   ],
   "source": [
    "y_ensemble=y_val_preds.copy()\n",
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble[:,0]=w*y_val_preds[:,0]+(1-w)*va_val[:,0]\n",
    "    print(w)\n",
    "    print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376323, 2)\n",
      "0.0\n",
      "(0.37270991068427667, 0.43333181223266476, 0.4030208614584707)\n",
      "0.3727109115028784 0.43333298467999354\n",
      "0.1\n",
      "(0.39129001376125133, 0.45826665032728586, 0.4247783320442686)\n",
      "0.39129103477967164 0.45826786912345396\n",
      "0.2\n",
      "(0.40713674817011875, 0.4789862168810887, 0.44306148252560373)\n",
      "0.4071378255383473 0.4789874687100041\n",
      "0.30000000000000004\n",
      "(0.42022403307022205, 0.49558779102277206, 0.45790591204649705)\n",
      "0.4202251365517627 0.4955891184646774\n",
      "0.4\n",
      "(0.43060394047792316, 0.5082827736165365, 0.46944335704722984)\n",
      "0.4306050743180796 0.5082841050059028\n",
      "0.5\n",
      "(0.4383938934882027, 0.517365185377603, 0.47787953943290284)\n",
      "0.4383950563011882 0.5173665696023647\n",
      "0.6000000000000001\n",
      "(0.4437619713537105, 0.5231821954650566, 0.4834720834093835)\n",
      "0.4437631292172675 0.5231835985782921\n",
      "0.7000000000000001\n",
      "(0.4469114379879105, 0.5261072554165196, 0.486509346702215)\n",
      "0.44691264343391773 0.5261086588279758\n",
      "0.8\n",
      "(0.4480673032488605, 0.5265186238286722, 0.4872929635387664)\n",
      "0.44806850657592673 0.5265200484346377\n",
      "0.9\n",
      "(0.44746300512438114, 0.5247834656334658, 0.48612323537892344)\n",
      "0.4474641960070375 0.5247848438505497\n",
      "1.0\n",
      "(0.44533125143390107, 0.5212460625489065, 0.4832886569914038)\n",
      "0.44533243932761624 0.5212474631941809\n"
     ]
    }
   ],
   "source": [
    "#y_val_lama=np.concatenate((y_val_preds_v.data,y_val_preds_a.data),axis=1)\n",
    "print(y_val_lama.shape)\n",
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_lama\n",
    "    print(w)\n",
    "    print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4480673032488605, 0.5265186238286722, 0.4872929635387664)\n",
      "0.44806850657592673 0.5265200484346377\n"
     ]
    }
   ],
   "source": [
    "w=0.8\n",
    "y_ensemble=w*y_val_preds+(1-w)*y_val_lama\n",
    "print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4499177402672424, 0.5298290663257271, 0.48987340329648477)\n",
      "0.4499189281574363 0.5298304787130718\n"
     ]
    }
   ],
   "source": [
    "w=0.5\n",
    "y_ensemble=w*y_val_preds+(1-w)*y_val_preds_mt\n",
    "print_ccc_for_val_preds(y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:00<00:00, 76.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirpath=os.path.join(DATA_DIR,'VA_Estimation_Challenge/Validation_Set')\n",
    "ind=0\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,y_true=[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    splitted_line=line.split(',')\n",
    "                    valence=float(splitted_line[0])\n",
    "                    arousal=float(splitted_line[1])\n",
    "                    if valence>=-1 and arousal>=-1:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            #X.append(y_val_preds[ind])\n",
    "                            X.append(y_ensemble[ind])\n",
    "                            indices.append(i)\n",
    "\n",
    "                            y_true.append((valence,arousal))\n",
    "                            ind+=1\n",
    "                        \n",
    "        test_videos[fn]=(np.array(X),indices,np.array(y_true))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0.45467808539350846, 0.5384962410483103, 0.49658716322090934)\n",
      "10 (0.4735034168577817, 0.5771482697977821, 0.5253258433277819)\n",
      "25 (0.4880783142242917, 0.6040955053246918, 0.5460869097744918)\n",
      "50 (0.4935198754791566, 0.6068185446719148, 0.5501692100755357)\n",
      "100 (0.4853385612499721, 0.5783366485114904, 0.5318376048807312)\n",
      "200 (0.4638047085529785, 0.5265323923684997, 0.4951685504607391)\n"
     ]
    }
   ],
   "source": [
    "deltas=[1,10,25,50,100,200]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_va,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if y_true[i][0]>=-1 and y_true[i][1]>=-1:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_va[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_va[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_va[cur_ind-1]+(1-w)*y_pred_va[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            cur_preds.append(pred)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if y_true[i][0]>=-1 and y_true[i][1]>=-1:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "gt_V=total_true[:,0]\n",
    "gt_A=total_true[:,1]\n",
    "\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    pred_V=preds[:,0]\n",
    "    pred_A=preds[:,1]\n",
    "    print(delta,metric_for_VA(gt_V,gt_A,pred_V,pred_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:11<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'faces')\n",
    "dirpath=os.path.join(DATA_DIR,'VA_Estimation_Challenge/Validation_Set')\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,y_true=[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    if imagename in filename2featuresAll:\n",
    "                        X.append(filename2featuresAll[imagename][1])\n",
    "                        indices.append(i)\n",
    "                        \n",
    "                        splitted_line=line.split(',')\n",
    "                        valence=float(splitted_line[0])\n",
    "                        arousal=float(splitted_line[1])\n",
    "                        y_true.append((valence,arousal))\n",
    "                        \n",
    "        test_videos[fn]=(mlpModel.predict(np.array(X)),indices,np.array(y_true))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0.4497322853156013, 0.5302893781650251, 0.4900108317403132)\n",
      "10 (0.46963786100578786, 0.5716260813822904, 0.5206319711940391)\n",
      "25 (0.4843495213418185, 0.6004171233716765, 0.5423833223567476)\n",
      "50 (0.48997545654787067, 0.6038755689432846, 0.5469255127455777)\n",
      "100 (0.48241128098915237, 0.5749223688356685, 0.5286668249124105)\n",
      "200 (0.46145788788100156, 0.5220036569168273, 0.4917307723989144)\n"
     ]
    }
   ],
   "source": [
    "deltas=[1,10,25,50,100,200]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_va,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if y_true[i][0]>=-1 and y_true[i][1]>=-1:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_va[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_va[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_va[cur_ind-1]+(1-w)*y_pred_va[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            cur_preds.append(pred)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if y_true[i][0]>=-1 and y_true[i][1]>=-1:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "gt_V=total_true[:,0]\n",
    "gt_A=total_true[:,1]\n",
    "\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    pred_V=preds[:,0]\n",
    "    pred_A=preds[:,1]\n",
    "    print(delta,metric_for_VA(gt_V,gt_A,pred_V,pred_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgaf:\n",
    "1 (0.44875087823993354, 0.5283116909318734, 0.48853128458590345)\n",
    "10 (0.4684252179690231, 0.5658810666512365, 0.5171531423101298)\n",
    "25 (0.4838215785829268, 0.5921912567094488, 0.5380064176461878)\n",
    "50 (0.48999702278941953, 0.5955375478706236, 0.5427672853300216)\n",
    "100 (0.4824520565285041, 0.5694326567832584, 0.5259423566558812)\n",
    "200 (0.46156615573225407, 0.5209989880709679, 0.49128257190161095)\n",
    "\n",
    "mtl:\n",
    "1 (0.4497322853156013, 0.5302893781650251, 0.4900108317403132)\n",
    "10 (0.46963786100578786, 0.5716260813822904, 0.5206319711940391)\n",
    "25 (0.4843495213418185, 0.6004171233716765, 0.5423833223567476)\n",
    "50 (0.48997545654787067, 0.6038755689432846, 0.5469255127455777)\n",
    "100 (0.48241128098915237, 0.5749223688356685, 0.5286668249124105)\n",
    "200 (0.46145788788100156, 0.5220036569168273, 0.4917307723989144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927211 ['image_location,valence,arousal', '2-30-640x360/00001.jpg,', '2-30-640x360/00002.jpg,', '2-30-640x360/00003.jpg,', '2-30-640x360/00004.jpg,']\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_DIR,'test_set','CVPR_5th_ABAW_VA_test_set_sample.txt'),'r') as f:\n",
    "    test_set_sample=f.read().splitlines()\n",
    "print(len(test_set_sample),test_set_sample[:5])\n",
    "\n",
    "test_set_videos={}\n",
    "for s in test_set_sample[1:]:\n",
    "    videoname,img_name=s[:-1].split('/')\n",
    "    if videoname not in test_set_videos:\n",
    "        test_set_videos[videoname]=[]\n",
    "    test_set_videos[videoname].append(img_name)\n",
    "    \n",
    "print(len(test_set_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:26<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames=[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][1])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    X=np.array(X)\n",
    "    test_videos[videoname]=(mlpModel.predict(X),indices,filenames)\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2-30-640x360': (19347, 6), '3-25-1920x1080': (6189, 0), '6-30-1920x1080_left': (7672, 314), '6-30-1920x1080_right': (7984, 2), '11-24-1920x1080': (5302, 88), '14-30-1920x1080': (5311, 0), '32-60-1920x1080': (4460, 0), '36-24-1280x720': (5124, 137), '38-30-1920x1080': (2401, 31), '40-30-1280x720': (8767, 893), '42-30-480x480': (1395, 0), '43-30-406x720': (2129, 745), '49-30-1280x720_left': (644, 204), '49-30-1280x720_right': (830, 18), '55-25-1280x720': (1476, 30), '56-30-1080x1920': (4168, 133), '58-30-640x480': (2843, 34), '62-30-654x480': (12034, 0), '70-30-720x1280': (2781, 3), '74-25-1920x1080': (5042, 0), '80-30-320x240': (5674, 0), '88-30-360x480': (3658, 65), '91-30-1920x1080': (10779, 143), '102-30-640x360': (2979, 5), '102': (4508, 270), '103-30-384x480': (772, 0), '103': (26551, 67), '105-30-1280x720': (1479, 23), '108-15-640x480': (466, 13), '109-30-1280x720': (1046, 0), '119': (4578, 0), '128-24-1920x1080': (3794, 19), '130-25-1280x720_left': (8086, 376), '130-25-1280x720_right': (8462, 0), '130': (4002, 0), '133-30-1280x720': (2401, 3), '134-30-1280x720': (3681, 194), '137-30-1920x1080': (8503, 50), '139': (7100, 1066), '147': (19406, 289), '159': (3366, 93), '164': (7044, 0), '165': (4350, 218), '171': (3931, 46), '194': (4537, 0), '197': (1784, 86), '199': (2850, 68), '204': (5879, 46), '209': (2455, 401), '212': (4140, 422), '219': (3576, 315), '234': (2905, 14), '239': (1964, 0), '241': (3512, 0), '244': (2286, 35), '265': (6691, 28), '266': (2465, 0), '267': (3841, 0), '268': (4364, 2), '270': (3935, 2), '274': (3526, 0), '281': (7011, 0), '284': (4054, 0), '286': (2678, 0), '289': (4203, 0), '303': (3897, 53), '304': (2694, 0), '307': (3311, 0), '311': (1930, 0), '313': (3140, 0), '322': (2429, 0), '336': (4344, 0), '344': (4263, 0), '349': (4054, 0), '353': (2775, 81), '357': (1373, 0), '358': (324, 0), '365': (1067, 0), '367': (4169, 0), '370': (1939, 0), '375': (2947, 10), '380': (2288, 87), '381': (1265, 0), '382': (2713, 0), '408': (2978, 0), '416': (6509, 3), '434': (5233, 0), '439': (2308, 0), '450': (9820, 87), '461': (7676, 0), '462': (3729, 28), '463': (22510, 0), '464': (14577, 0), '465': (25030, 33), '466': (22869, 0), '467': (15185, 0), '468': (9967, 261), '469': (18248, 0), '470': (9076, 25), 'video2': (1778, 287), 'video2_left': (144, 1921), 'video3': (7802, 0), 'video4': (1072, 479), 'video5_left': (2339, 130), 'video5_right': (2214, 255), 'video6': (4620, 705), 'video7': (3027, 351), 'video8': (5256, 112), 'video9': (3773, 22), 'video10_1_left': (4036, 221), 'video10_1_right': (4243, 14), 'video11': (4132, 248), 'video12': (5580, 0), 'video13': (10551, 16), 'video14': (7583, 3), 'video15': (4288, 0), 'video16': (12486, 1), 'video17': (21938, 0), 'video18': (3784, 0), 'video19': (775, 10), 'video20': (11272, 0), 'video21': (6787, 22), 'video22': (10458, 12), 'video23': (8783, 7), 'video24': (5202, 3), 'video25': (3641, 4), 'video26': (11021, 0), 'video27': (16410, 9), 'video28': (8728, 0), 'video29_left': (11243, 17), 'video29_right': (11227, 33), 'video30': (8209, 5), 'video32': (2751, 25), 'video33': (7538, 16), 'video34': (10262, 20), 'video35': (3568, 0), 'video36': (2386, 39), 'video37': (8820, 367), 'video38': (2936, 9), 'video39': (10671, 8), 'video40': (5877, 0), 'video41': (3466, 29), 'video42': (9217, 10), 'video44': (7778, 8), 'video45_1': (805, 8), 'video45_2': (1096, 0), 'video45_3': (295, 0), 'video45_4': (1039, 0), 'video45_5': (415, 0), 'video45_6': (309, 0), 'video45_7': (180, 0), 'video46': (3167, 6), 'video47': (812, 9), 'video48': (2532, 11), 'video49_left': (6109, 13), 'video49_right': (6071, 51), 'video51': (4406, 2), 'video52': (10671, 9), 'video53': (7967, 13), 'video65': (3313, 1259), 'video72': (120, 8), 'video73': (5759, 192)}\n"
     ]
    }
   ],
   "source": [
    "print(test_videos_num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=50\n",
    "resdir=os.path.join(DATA_DIR,'test_set/test_results/VA')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_va_results(res_filename):\n",
    "    with open(os.path.join(resdir,res_filename), 'w') as f:\n",
    "        f.write(test_set_sample[0]+'\\n')\n",
    "        for videoname,(y_pred_va,indices,filenames) in test_videos.items():\n",
    "            cur_ind=0\n",
    "            preds=[]\n",
    "            for i in range(indices[-1]):\n",
    "                if indices[cur_ind]-1==i:\n",
    "                    preds.append(y_pred_va[cur_ind])\n",
    "                    cur_ind+=1\n",
    "                else:\n",
    "                    if cur_ind==0:\n",
    "                        preds.append(y_pred_va[cur_ind])\n",
    "                    else:\n",
    "                        w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                        pred=w*y_pred_va[cur_ind-1]+(1-w)*y_pred_va[cur_ind]\n",
    "                        preds.append(pred)\n",
    "\n",
    "            pred=y_pred_va[cur_ind-1]\n",
    "            for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "                preds.append(pred)\n",
    "\n",
    "            preds=np.array(preds)\n",
    "            for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "                i1=max(i-delta,0)\n",
    "                pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "                f.write(videoname+'/'+img_name+','+str(pred[0])+','+str(pred[1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_filename='predictions_1_mt_mlp.txt'\n",
    "#res_filename='predictions_3_mt_mlp_train_val.txt'\n",
    "#res_filename='predictions_4_vgaf_mlp.txt'\n",
    "write_va_results(res_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_mt=test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.5\n",
    "\n",
    "with open(os.path.join(resdir,'predictions_5_mt_vgaf.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_va,indices,filenames) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        y_pred_va_mt,_,_=test_videos_mt[videoname]\n",
    "        y_ensemble=weight*y_pred_va+(1-weight)*y_pred_va_mt\n",
    "        preds=[]\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds.append(y_ensemble[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds.append(pred)\n",
    "\n",
    "        pred=y_ensemble[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds=np.array(preds)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(pred[0])+','+str(pred[1])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:45<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames=[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][1])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    X=np.array(X)\n",
    "    df_test=pd.DataFrame(data=X,columns=['f'+str(i) for i in range(X.shape[1])])\n",
    "    test_videos[videoname]=(mlpModel.predict(X),indices,filenames,automl.predict(df_test).data)\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.8\n",
    "\n",
    "with open(os.path.join(resdir,'predictions_2_mt_mlp_lama.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_va,indices,filenames,y_lama_va) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        y_ensemble=weight*y_pred_va+(1-weight)*y_lama_va\n",
    "        preds=[]\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds.append(y_ensemble[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds.append(pred)\n",
    "\n",
    "        pred=y_ensemble[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds=np.array(preds)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            f.write(videoname+'/'+img_name+','+str(pred[0])+','+str(pred[1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:01<00:00, 127.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames=[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][1])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    X=np.array(X)\n",
    "    test_videos[videoname]=(X[:,-2:],indices,filenames)\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))\n",
    "\n",
    "write_va_results('predictions_3_mt_pretrained.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AU (Action Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356694, 1280) (1356694, 12) 2829\n",
      "(445836, 1280) (445836, 12) 9\n"
     ]
    }
   ],
   "source": [
    "def get_image2AU(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'AU_Detection_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        splitted_line=line.split(',')\n",
    "                        aus=list(map(int,splitted_line))\n",
    "                        if min(aus)>=0:\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if imagename in filename2featuresAll:\n",
    "                                X.append(filename2featuresAll[imagename][0])\n",
    "                                #X.append(filename2featuresAll[imagename][1])\n",
    "                                y.append(aus)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2AU('Train_Set')\n",
    "X_val,y_val=get_image2AU('Validation_Set')\n",
    "TRAIN_VAL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1802530, 1280) (1802530, 12)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_train=np.concatenate((y_train,y_val))\n",
    "    print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_au():\n",
    "    y_val_preds=mlpModel.predict(X_val)\n",
    "    new_pred = ((y_val_preds >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(y_val_preds.shape[1])]))\n",
    "    print(f1_score_max(y_val,y_val_preds,thresh=np.arange(0.1,1,0.1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[[ 0.57051513  4.04533846]\n",
      " [ 0.53198811  8.31540342]\n",
      " [ 0.59103142  3.24630441]\n",
      " [ 0.67779727  1.90609581]\n",
      " [ 0.82975276  1.25814377]\n",
      " [ 0.76448554  1.44523126]\n",
      " [ 0.66392849  2.02505522]\n",
      " [ 0.51469358 17.51423463]\n",
      " [ 0.51536815 16.76740898]\n",
      " [ 0.5136215  18.85333863]\n",
      " [ 1.35901329  0.79103158]\n",
      " [ 0.54473359  6.08864103]]\n"
     ]
    }
   ],
   "source": [
    "num_labels=y_train.shape[1]\n",
    "print(num_labels)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = np.empty([num_labels, 2])\n",
    "for i in range(num_labels):\n",
    "    neg, pos = np.bincount(y_train[:, i])\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    class_weights[i][0]=weight_for_0\n",
    "    class_weights[i][1]=weight_for_1\n",
    "    #class_weights[i] = compute_class_weight('balanced', [0,1], y_train[:, i])\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    loss='binary_crossentropy'\n",
    "    #loss='hinge'\n",
    "else:\n",
    "    import tensorflow.keras.backend as K\n",
    "    def get_weighted_loss(weights):\n",
    "        def weighted_loss(y_true, y_pred):\n",
    "            y_true=tf.cast(y_true, tf.float32)\n",
    "            ce=K.binary_crossentropy(y_true, y_pred)\n",
    "            return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*ce, axis=-1)\n",
    "        return weighted_loss\n",
    "    loss=get_weighted_loss(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512 #128\n",
    "mlpModel=Sequential()\n",
    "if False:\n",
    "    mlpModel.add(Dense(y_train.shape[1], input_shape=X_train.shape[1:],activation='sigmoid',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_train.shape[1:],activation='relu')) #256\n",
    "    mlpModel.add(Dense(y_train.shape[1],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 165,516\n",
      "Trainable params: 165,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3521/3521 [==============================] - 30s 8ms/step - loss: 0.3661 - auc: 0.9135 - binary_accuracy: 0.8372 - recall: 0.8102 - precision: 0.5658 - val_loss: 0.2862 - val_auc: 0.9495 - val_binary_accuracy: 0.8765 - val_recall: 0.8517 - val_precision: 0.6543\n",
      "0.2862222194671631\n"
     ]
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(lr=1e-3), loss=loss, metrics=metrics)\n",
    "mlpModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "mlpModel.fit(X_train,y_train, batch_size=batch_size, epochs=1 if TRAIN_VAL else 5, verbose=1, callbacks=[save_best_model], validation_data=(X_val,y_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49187050179992964\n",
      "(0.5015130438723765, 0.6166666666666666, array([0.51754899, 0.36724473, 0.54567861, 0.61147033, 0.73053152,\n",
      "       0.73840495, 0.70563868, 0.29698362, 0.16128799, 0.19354461,\n",
      "       0.83596954, 0.31385295]), array([0.7, 0.6, 0.7, 0.6, 0.5, 0.5, 0.7, 0.7, 0.8, 0.8, 0.3, 0.5]), array([0.85382742, 0.87077535, 0.85694515, 0.80133951, 0.77028549,\n",
      "       0.80315183, 0.85623413, 0.94782835, 0.94788667, 0.93812972,\n",
      "       0.76932549, 0.810603  ]))\n",
      "Best weights:\n",
      "0.5051735938712013\n",
      "(0.5231335444336457, 0.6333333333333332, array([0.55359708, 0.42572046, 0.55692077, 0.62379969, 0.74228902,\n",
      "       0.75003274, 0.72522065, 0.32031986, 0.17980525, 0.1976453 ,\n",
      "       0.83940959, 0.36284212]), array([0.8, 0.7, 0.7, 0.6, 0.4, 0.5, 0.7, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88707058, 0.89098458, 0.85974663, 0.81194879, 0.77336734,\n",
      "       0.81160337, 0.8677406 , 0.94661938, 0.94067774, 0.92311298,\n",
      "       0.77641554, 0.84230973]))\n"
     ]
    }
   ],
   "source": [
    "print_au()\n",
    "print('Best weights:')\n",
    "mlpModel.set_weights(best_model_weights)\n",
    "print_au()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5051735938712013\n",
      "(0.5231335444336457, 0.6333333333333332, array([0.55359708, 0.42572046, 0.55692077, 0.62379969, 0.74228902,\n",
      "       0.75003274, 0.72522065, 0.32031986, 0.17980525, 0.1976453 ,\n",
      "       0.83940959, 0.36284212]), array([0.8, 0.7, 0.7, 0.6, 0.4, 0.5, 0.7, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88707058, 0.89098458, 0.85974663, 0.81194879, 0.77336734,\n",
      "       0.81160337, 0.8677406 , 0.94661938, 0.94067774, 0.92311298,\n",
      "       0.77641554, 0.84230973]))\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    #mlpModel.save_weights('au_enet0_vgaf.h5') #0.49859147455269043   with thresholds 0.5265306930000911\n",
    "    mlpModel.save_weights('au_enet0_mtl.h5') #0.5051735938712013\n",
    "else:\n",
    "    mlpModel.load_weights('au_enet0_mtl.h5') #0.5051735938712013\n",
    "    #mlpModel.load_weights('../au_enet0_vgaf.h5') #0.507568027779308\n",
    "    print_au()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5367145284583944\n"
     ]
    }
   ],
   "source": [
    "#mlpModel.load_weights('au_enet0_mtl.h5') \n",
    "mlpModel.load_weights('../au_enet0_vgaf.h5')\n",
    "y_val_preds=mlpModel.predict(X_val)\n",
    "\n",
    "thresholds=0.5\n",
    "#thresholds=np.array([0.8, 0.7, 0.7, 0.6, 0.4, 0.5, 0.7, 0.8, 0.7, 0.8, 0.3, 0.6]) #mtl 0.5231335444336457\n",
    "thresholds=np.array([0.8, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]) #vgaf 0.5367145284583944\n",
    "\n",
    "new_pred = ((y_val_preds >= thresholds) * 1)\n",
    "print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(y_val_preds.shape[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enet_b0_8_best_vgaf\n",
    "features\n",
    "dense: 0.507568027779308\n",
    "(0.5367145284583944, 0.65, array([0.56438654, 0.47163507, 0.57207889, 0.61677155, 0.74818918,\n",
    "       0.74534595, 0.71942028, 0.35743029, 0.19360184, 0.24140214,\n",
    "       0.83680711, 0.37350551]), array([0.8, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]), array([0.8884859 , 0.90530374, 0.8692748 , 0.79757579, 0.78782557,\n",
    "       0.80682583, 0.8569631 , 0.94949937, 0.94323473, 0.95116814,\n",
    "       0.77594452, 0.85026333]))\n",
    "       \n",
    "       \n",
    " mtl\n",
    " 0.49428877376095776\n",
    "(0.524806956530541, 0.7000000000000001, array([0.54610128, 0.42494575, 0.55170266, 0.62691763, 0.74382282,\n",
    "       0.74725918, 0.7251595 , 0.31431459, 0.21263799, 0.1999356 ,\n",
    "       0.83512272, 0.36976376]), array([0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.9, 0.8, 0.9, 0.3, 0.7]), array([0.87291964, 0.89063243, 0.86118887, 0.81252075, 0.78728725,\n",
    "       0.81416036, 0.86124943, 0.95587391, 0.95360626, 0.94984479,\n",
    "       0.76649485, 0.83221633]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_val_preds_vgaf=y_val_preds\n",
    "y_val_preds_mtl=y_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5051735938712013\n",
      "(0.5231335444336457, 0.6333333333333332, array([0.55359708, 0.42572046, 0.55692077, 0.62379969, 0.74228902,\n",
      "       0.75003274, 0.72522065, 0.32031986, 0.17980525, 0.1976453 ,\n",
      "       0.83940959, 0.36284212]), array([0.8, 0.7, 0.7, 0.6, 0.4, 0.5, 0.7, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88707058, 0.89098458, 0.85974663, 0.81194879, 0.77336734,\n",
      "       0.81160337, 0.8677406 , 0.94661938, 0.94067774, 0.92311298,\n",
      "       0.77641554, 0.84230973]))\n",
      "0.1\n",
      "0.5091455374196453\n",
      "(0.5279939392250242, 0.6166666666666666, array([0.55987886, 0.43465787, 0.56224317, 0.62654832, 0.74539631,\n",
      "       0.75222757, 0.7285629 , 0.33105139, 0.18511054, 0.20258621,\n",
      "       0.8408712 , 0.36679294]), array([0.8, 0.7, 0.7, 0.6, 0.4, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.5]), array([0.89047318, 0.89392512, 0.86332642, 0.81484223, 0.77535237,\n",
      "       0.81338429, 0.86023336, 0.9498089 , 0.94286913, 0.92862846,\n",
      "       0.77820992, 0.8147884 ]))\n",
      "0.2\n",
      "0.5127973921074275\n",
      "(0.533017397148989, 0.6249999999999999, array([0.56484658, 0.44359876, 0.56877713, 0.62935288, 0.74865063,\n",
      "       0.754916  , 0.73146233, 0.34267134, 0.19023254, 0.20882875,\n",
      "       0.84174832, 0.37112349]), array([0.7, 0.7, 0.7, 0.6, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.87937717, 0.89669968, 0.86721575, 0.81786801, 0.79496272,\n",
      "       0.8154097 , 0.86255933, 0.95284365, 0.94462313, 0.93507702,\n",
      "       0.77923721, 0.84530859]))\n",
      "0.30000000000000004\n",
      "0.5161879402744332\n",
      "(0.5375026584034432, 0.6166666666666666, array([0.56976915, 0.45084511, 0.57360552, 0.63160508, 0.75165132,\n",
      "       0.75679927, 0.73335565, 0.35297151, 0.19374649, 0.21774768,\n",
      "       0.84249049, 0.37544463]), array([0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88203286, 0.89877668, 0.87046134, 0.80362286, 0.79684234,\n",
      "       0.81687885, 0.8642281 , 0.95496999, 0.94522874, 0.94091998,\n",
      "       0.78018599, 0.84601288]))\n",
      "0.4\n",
      "0.5187270490065781\n",
      "(0.541014384144264, 0.6166666666666666, array([0.57316591, 0.45698558, 0.57729665, 0.63373932, 0.7542145 ,\n",
      "       0.75784588, 0.73414719, 0.35982333, 0.19863126, 0.2245393 ,\n",
      "       0.84299787, 0.37878582]), array([0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88380481, 0.89999013, 0.87300487, 0.80574471, 0.79829354,\n",
      "       0.81769081, 0.8652352 , 0.95611166, 0.94510762, 0.94478463,\n",
      "       0.78093739, 0.84583345]))\n",
      "0.5\n",
      "0.5199393283667891\n",
      "(0.5430868951332039, 0.6166666666666666, array([0.57564271, 0.46087072, 0.57899923, 0.6347521 , 0.75550435,\n",
      "       0.75756078, 0.73303063, 0.36535557, 0.20331393, 0.22754806,\n",
      "       0.84300553, 0.38145913]), array([0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88474461, 0.90025705, 0.87444935, 0.80709947, 0.79867261,\n",
      "       0.81742614, 0.86495483, 0.95664325, 0.94413641, 0.94737078,\n",
      "       0.78120654, 0.84459757]))\n",
      "0.6000000000000001\n",
      "0.5198255232950532\n",
      "(0.543975201831992, 0.6249999999999999, array([0.57638351, 0.46688322, 0.57987711, 0.6332615 , 0.7558231 ,\n",
      "       0.755736  , 0.73109244, 0.36942135, 0.20410174, 0.23078234,\n",
      "       0.84263162, 0.38170849]), array([0.7, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88472443, 0.91312501, 0.87501458, 0.80686172, 0.7981141 ,\n",
      "       0.81579774, 0.86405764, 0.95661409, 0.94202801, 0.94938722,\n",
      "       0.78110337, 0.84139011]))\n",
      "0.7000000000000001\n",
      "0.5178935122387572\n",
      "(0.5436623812129876, 0.6333333333333332, array([0.57502695, 0.47127263, 0.58108291, 0.62987163, 0.75483367,\n",
      "       0.75371778, 0.72896558, 0.36984061, 0.20351354, 0.23411769,\n",
      "       0.84176021, 0.37994538]), array([0.7, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.6]), array([0.88329341, 0.91254407, 0.8750886 , 0.80534546, 0.79638926,\n",
      "       0.81397195, 0.8629496 , 0.95592774, 0.95789932, 0.95086758,\n",
      "       0.78052692, 0.83702976]))\n",
      "0.8\n",
      "0.5149169725953825\n",
      "(0.5426215845931188, 0.6416666666666666, array([0.57209059, 0.47380567, 0.57948074, 0.6253632 , 0.75328333,\n",
      "       0.75140504, 0.72562433, 0.36879743, 0.20502473, 0.23820447,\n",
      "       0.84024417, 0.37813532]), array([0.7, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]), array([0.88070277, 0.91101212, 0.87379216, 0.80276604, 0.79408347,\n",
      "       0.8119914 , 0.86091298, 0.9546627 , 0.95493186, 0.95158085,\n",
      "       0.77910936, 0.86103186]))\n",
      "0.9\n",
      "0.511355118935657\n",
      "(0.5398550602179175, 0.65, array([0.56802046, 0.47297454, 0.57562929, 0.62092852, 0.7507178 ,\n",
      "       0.74875759, 0.72278971, 0.36296607, 0.20020751, 0.24060946,\n",
      "       0.83867702, 0.37598276]), array([0.8, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]), array([0.89164177, 0.90838559, 0.87161871, 0.8001754 , 0.79085134,\n",
      "       0.80972375, 0.85908496, 0.95232776, 0.94985824, 0.95170646,\n",
      "       0.77771647, 0.85579899]))\n",
      "1.0\n",
      "0.5075692080786435\n",
      "(0.5367145284583944, 0.65, array([0.56438654, 0.47163507, 0.57207889, 0.61677155, 0.74818918,\n",
      "       0.74534595, 0.71942028, 0.35743029, 0.19360184, 0.24140214,\n",
      "       0.83680711, 0.37350551]), array([0.8, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]), array([0.8884859 , 0.90530374, 0.8692748 , 0.79757579, 0.78782557,\n",
      "       0.80682583, 0.8569631 , 0.94949937, 0.94323473, 0.95116814,\n",
      "       0.77594452, 0.85026333]))\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    print(w)\n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_preds_mtl\n",
    "    new_pred = ((y_ensemble >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "    print(f1_score_max(y_val,y_ensemble,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543975201831992\n"
     ]
    }
   ],
   "source": [
    "weight=0.6\n",
    "y_ensemble=weight*y_val_preds+(1-weight)*y_val_preds_mtl\n",
    "thresholds=0.5\n",
    "thresholds=np.array([0.7, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6])\n",
    "new_pred = ((y_ensemble >= thresholds) * 1)\n",
    "print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(new_pred.shape[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirpath=os.path.join(DATA_DIR,'AU_Detection_Challenge/Validation_Set')\n",
    "ind=0\n",
    "test_videos={}\n",
    "for filename in os.listdir(dirpath):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,y_true=[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    splitted_line=line.split(',')\n",
    "                    aus=list(map(int,splitted_line))\n",
    "                    if min(aus)>=0:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            X.append(y_ensemble[ind])\n",
    "                            indices.append(i)\n",
    "                            y_true.append(aus)\n",
    "                            ind+=1\n",
    "        test_videos[fn]=(np.array(X),indices,np.array(y_true))\n",
    "\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.543975201831992 [0.5763835083496809, 0.46688322413698174, 0.5798771063444793, 0.6332614973125378, 0.7558231014220684, 0.7557359983343744, 0.73109243697479, 0.3694213528932355, 0.20410174293280778, 0.23078234191239133, 0.8426316213819238, 0.3817084899886334]\n",
      "3 0.5527115882582081 [0.5863481228668942, 0.4721199707807554, 0.5901815547818772, 0.6429130573166222, 0.7654025210312815, 0.7654152609288636, 0.7417232244455538, 0.3823310271420968, 0.21511930424440645, 0.2346071024489945, 0.8479743813241369, 0.38840353178701353]\n",
      "5 0.5528469599376815 [0.5878298218723751, 0.47152221412964307, 0.591238406897257, 0.646294690429658, 0.7674270435696511, 0.7649485894280461, 0.7451706010622415, 0.3810434910589448, 0.2041967054653832, 0.23787061994609163, 0.8473113423530224, 0.3893099930398634]\n",
      "7 0.5514931236426248 [0.58772722883952, 0.46844986058039856, 0.5917521689181159, 0.6493052551435344, 0.7676100046822086, 0.7633270174241268, 0.7463173635004249, 0.3764385221078134, 0.193131762391481, 0.23859595457500093, 0.8460185828073926, 0.38924376274148137]\n",
      "10 0.5490788247920431 [0.585313966480447, 0.46396639663966394, 0.5908621641737294, 0.6531620081670204, 0.7672097061272921, 0.7613176120976826, 0.7455704072116879, 0.3684767692609292, 0.1798265632131447, 0.23993413572744737, 0.844130066715603, 0.3891761016898697]\n",
      "15 0.5433385627648376 [0.5767132815932055, 0.4553985579351837, 0.5867414782862518, 0.657092264921753, 0.7661134087940793, 0.7572345966096209, 0.744280578855194, 0.35817484286996987, 0.15000745563894827, 0.23775028487709587, 0.8415967415700911, 0.3889592612266579]\n",
      "20 0.5380824835642478 [0.5674562498835194, 0.4473359856463063, 0.584570315696447, 0.6598227435533207, 0.7639202581867065, 0.7540537380726121, 0.7414957461325313, 0.3490597716588314, 0.126479250334672, 0.237909810325336, 0.8395157842147124, 0.38537014906597894]\n",
      "25 0.5329111662587908 [0.5583159886471144, 0.4380913008220572, 0.5794182521127808, 0.66210344466548, 0.7618733904294185, 0.7512326203529314, 0.7370720232983607, 0.34011552720062077, 0.11122448979591837, 0.23681720430107528, 0.8381811133461738, 0.3804886401335574]\n",
      "50 0.5109522680195706 [0.5168802328721903, 0.4027777777777778, 0.5507567558281364, 0.6664528515757148, 0.7509992191262377, 0.7390181500043594, 0.7216663808053666, 0.27588860564667406, 0.06722240746915639, 0.23893429070811092, 0.8333818540546981, 0.3674486903664242]\n"
     ]
    }
   ],
   "source": [
    "deltas=[0,3,5,7,10,15,20,25,50]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_aus,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if min(y_true[i])>=0:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_aus[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_aus[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_aus[cur_ind-1]+(1-w)*y_pred_aus[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            aus=(pred>=thresholds)*1\n",
    "            #aus=(pred>=0.5)*1\n",
    "            cur_preds.append(aus)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if min(y_true[i])>=0:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "    \n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    f1scores=[f1_score(y_true=total_true[:,i],y_pred=preds[:,i]) for i in range(preds.shape[1])]\n",
    "    print(delta,np.mean(f1scores),f1scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = Task(\n",
    "        name = 'multilabel'#,loss='f1',\n",
    "        #metric = lambda y_true, y_pred: f1_score(y_true=y_true,y_pred=np.argmax(y_pred,axis=1), average=\"macro\")\n",
    "    ),\n",
    "    timeout=600 #*6*8 #,cpu_limit=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356694          f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0 -0.740520 -0.044359 -1.846506  1.321128  1.217274  0.086414 -2.281916   \n",
      "1 -0.760110 -0.151064 -1.863520  1.420068  1.229155  0.062401 -2.325460   \n",
      "2 -0.725249 -0.172695 -1.468626  1.499178  0.889816 -0.092044 -2.158123   \n",
      "3 -0.658872 -0.183799 -1.228663  1.180651  0.912762  0.037123 -2.416795   \n",
      "4 -0.474594 -0.389611 -1.076806  1.023775  0.932743  0.383680 -2.453935   \n",
      "\n",
      "         f7  AU_1  AU_2  AU_3  AU_4  AU_5  AU_6  AU_7  AU_8  AU_9  AU_10  \\\n",
      "0  4.121276     0     0     0     0     1     1     1     0     0      0   \n",
      "1  4.212641     0     0     0     0     1     1     1     0     0      0   \n",
      "2  3.987385     0     0     0     0     1     1     1     0     0      0   \n",
      "3  3.962024     0     0     0     0     1     1     1     0     0      0   \n",
      "4  3.765034     0     0     0     0     1     1     1     0     0      0   \n",
      "\n",
      "   AU_11  AU_12  \n",
      "0      1      0  \n",
      "1      1      0  \n",
      "2      1      0  \n",
      "3      1      0  \n",
      "4      1      0  \n",
      "445836          f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0 -1.367348  3.447955 -1.198485 -2.192642  3.894852  1.771455 -1.081753   \n",
      "1 -1.254405  3.550966 -1.179791 -2.200516  3.805342  1.735472 -1.139996   \n",
      "2 -0.728573  2.162614 -0.872399 -0.766737  3.160072  0.980653 -1.365254   \n",
      "3 -0.728573  2.162614 -0.872399 -0.766737  3.160072  0.980653 -1.365254   \n",
      "4 -1.510414  2.111998 -0.488893 -1.078952  3.365052  0.986065 -1.907691   \n",
      "\n",
      "         f7  AU_1  AU_2  AU_3  AU_4  AU_5  AU_6  AU_7  AU_8  AU_9  AU_10  \\\n",
      "0  2.578589     0     0     0     0     1     1     1     0     0      0   \n",
      "1  2.515839     0     0     0     0     1     1     1     0     0      0   \n",
      "2  2.699691     1     1     0     0     0     0     1     0     0      0   \n",
      "3  2.699691     1     1     0     0     0     0     1     0     0      0   \n",
      "4  3.034719     1     1     0     0     0     0     1     0     0      0   \n",
      "\n",
      "   AU_11  AU_12  \n",
      "0      1      0  \n",
      "1      1      0  \n",
      "2      0      0  \n",
      "3      0      0  \n",
      "4      0      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def get_df(X,y):\n",
    "    #xy=np.concatenate((y.reshape((-1,1)),X),axis=1)\n",
    "    df=pd.DataFrame(data=X,columns=['f'+str(i) for i in range(X.shape[1])])\n",
    "    for i in range(y.shape[1]):\n",
    "        df['AU_'+str(i+1)]=y[:,i]\n",
    "    return df\n",
    "\n",
    "if True:\n",
    "    df_train=get_df(X_train,y_train)\n",
    "    print(len(df_train),df_train.head())\n",
    "\n",
    "df_val=get_df(X_val,y_val)\n",
    "print(len(df_val),df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:27] Stdout logging level is INFO.\n",
      "[14:44:27] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[14:44:27] Task: multilabel\n",
      "\n",
      "[14:44:27] Start automl preset with listed constraints:\n",
      "[14:44:27] - time: 600.00 seconds\n",
      "[14:44:27] - CPU: 4 cores\n",
      "[14:44:27] - memory: 16 GB\n",
      "\n",
      "[14:44:27] \u001b[1mTrain data shape: (1356694, 20)\u001b[0m\n",
      "\n",
      "[14:44:32] Layer \u001b[1m1\u001b[0m train process start. Time left 595.17 secs\n",
      "[14:44:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_RFSklearn\u001b[0m ...\n",
      "[15:04:03] Time limit exceeded after calculating fold 0\n",
      "\n",
      "[15:04:04] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_RFSklearn\u001b[0m finished. score = \u001b[1m-4.1065008922970385\u001b[0m\n",
      "[15:04:04] \u001b[1mLvl_0_Pipe_0_Mod_0_RFSklearn\u001b[0m fitting and predicting completed\n",
      "[15:04:04] Time left -577.10 secs\n",
      "\n",
      "[15:04:04] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "[15:04:04] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:04:04] \u001b[1mAutoml preset training completed in 1177.10 seconds\u001b[0m\n",
      "\n",
      "[15:04:04] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_RFSklearn) \n",
      "\n",
      "oof_pred:\n",
      "array([[          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [6.3491523e-01, 4.8485181e-01, 1.0942842e-02, 1.5161571e-01,\n",
      "        4.3640050e-01, 7.1763337e-01, 3.2579169e-01, 5.4490659e-02,\n",
      "        3.1482738e-02, 4.9808429e-04, 8.2856470e-01, 3.4123144e-01],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [5.9290636e-01, 3.7974653e-01, 1.7602852e-02, 1.2693006e-01,\n",
      "        4.3074667e-01, 6.2994671e-01, 1.7355594e-01, 1.2281007e-02,\n",
      "        3.6067873e-02, 1.3907645e-02, 8.0582130e-01, 2.5354394e-01],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan],\n",
      "       [          nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan,\n",
      "                  nan,           nan,           nan,           nan]],\n",
      "      dtype=float32)\n",
      "Shape = (1356694, 12)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(df_train, roles = {'target': ['AU_'+str(i+1) for i in range(y_train.shape[1])]}, verbose = 1) #, valid_data=df_val)\n",
    "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445836, 12)\n",
      "0.3967976517739536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47712935942351486, 0.25000000000000006, array([0.48615976, 0.39929463, 0.51798481, 0.60161062, 0.68653855,\n",
      "       0.71018885, 0.71865606, 0.18148784, 0.06501251, 0.19240359,\n",
      "       0.811192  , 0.35502308]), array([0.2, 0.2, 0.2, 0.3, 0.4, 0.4, 0.4, 0.1, 0.1, 0.1, 0.4, 0.2]), array([0.82858046, 0.90449179, 0.82563768, 0.79050593, 0.73450103,\n",
      "       0.78638782, 0.86375483, 0.92623521, 0.93212975, 0.91281996,\n",
      "       0.72501772, 0.86053392]))\n"
     ]
    }
   ],
   "source": [
    "val_pred = automl.predict(df_val).data #complete lama\n",
    "print(val_pred.shape)\n",
    "\n",
    "new_pred = ((val_pred >= 0.5) * 1)\n",
    "print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "print(f1_score_max(y_val,val_pred,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39161635065008743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47801455675819343, 0.25000000000000006, array([0.48729388, 0.40392079, 0.53907524, 0.60048323, 0.69929169,\n",
      "       0.72261939, 0.72593995, 0.15211746, 0.059756  , 0.18386043,\n",
      "       0.81331989, 0.34849671]), array([0.2, 0.2, 0.2, 0.3, 0.4, 0.4, 0.4, 0.1, 0.1, 0.1, 0.4, 0.2]), array([0.83631874, 0.90561103, 0.83711275, 0.79378964, 0.74755964,\n",
      "       0.79922886, 0.86624454, 0.9216371 , 0.94571995, 0.90808279,\n",
      "       0.72760387, 0.86565912]))\n"
     ]
    }
   ],
   "source": [
    "val_pred = automl.predict(df_val).data #600 s: 0.39161635065008743, (0.47801455675819343, 0.25\n",
    "new_pred = ((val_pred >= 0.5) * 1)\n",
    "print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "print(f1_score_max(y_val,val_pred,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.3967976517739536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47712935942351486, 0.25000000000000006, array([0.48615976, 0.39929463, 0.51798481, 0.60161062, 0.68653855,\n",
      "       0.71018885, 0.71865606, 0.18148784, 0.06501251, 0.19240359,\n",
      "       0.811192  , 0.35502308]), array([0.2, 0.2, 0.2, 0.3, 0.4, 0.4, 0.4, 0.1, 0.1, 0.1, 0.4, 0.2]), array([0.82858046, 0.90449179, 0.82563768, 0.79050593, 0.73450103,\n",
      "       0.78638782, 0.86375483, 0.92623521, 0.93212975, 0.91281996,\n",
      "       0.72501772, 0.86053392]))\n",
      "0.1\n",
      "0.412161016994298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5039515433117274, 0.26666666666666666, array([0.51446046, 0.44160531, 0.53645566, 0.61495244, 0.70221956,\n",
      "       0.72041016, 0.72473944, 0.2508855 , 0.13836355, 0.21719737,\n",
      "       0.81689322, 0.36923585]), array([0.3, 0.2, 0.2, 0.3, 0.4, 0.4, 0.4, 0.1, 0.1, 0.2, 0.4, 0.2]), array([0.86680977, 0.89588997, 0.82169228, 0.79370441, 0.74593124,\n",
      "       0.79181582, 0.86511408, 0.87903399, 0.86194251, 0.94331548,\n",
      "       0.73438888, 0.83705443]))\n",
      "0.2\n",
      "0.43008000305533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5263361953207768, 0.3083333333333334, array([0.53891288, 0.44917796, 0.55782671, 0.62452623, 0.71781616,\n",
      "       0.72956851, 0.72961114, 0.3332561 , 0.19157184, 0.24114475,\n",
      "       0.82268266, 0.37993941]), array([0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.4, 0.3]), array([0.86251447, 0.91102558, 0.85696086, 0.79402067, 0.75661678,\n",
      "       0.79622103, 0.86537202, 0.9354516 , 0.94199661, 0.92993836,\n",
      "       0.74431854, 0.87329422]))\n",
      "0.30000000000000004\n",
      "0.45242858432824645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.536179212780311, 0.35000000000000003, array([0.54886708, 0.46748638, 0.56821065, 0.6304995 , 0.73074094,\n",
      "       0.73699005, 0.73184365, 0.35637481, 0.19879013, 0.25396349,\n",
      "       0.82815662, 0.38222726]), array([0.4, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.3, 0.3, 0.3, 0.4, 0.3]), array([0.88214725, 0.89567016, 0.84882782, 0.82155097, 0.76513785,\n",
      "       0.79894401, 0.86355745, 0.95300963, 0.96138042, 0.94427099,\n",
      "       0.75426839, 0.84597251]))\n",
      "0.4\n",
      "0.4815151275537799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5396252279672301, 0.40000000000000013, array([0.5637537 , 0.47794323, 0.57948681, 0.6373418 , 0.73975404,\n",
      "       0.74224612, 0.73584192, 0.34912945, 0.18174282, 0.25149827,\n",
      "       0.83251636, 0.38424821]), array([0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.5, 0.4, 0.3, 0.4, 0.4, 0.4]), array([0.87385496, 0.90767906, 0.86950807, 0.81894015, 0.77046268,\n",
      "       0.79989727, 0.87466243, 0.96142976, 0.91143604, 0.95237711,\n",
      "       0.76303843, 0.86921648]))\n",
      "0.5\n",
      "0.5330206309128257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5415474938273397, 0.4500000000000001, array([0.56704785, 0.4791801 , 0.57647411, 0.63721316, 0.74443683,\n",
      "       0.74743735, 0.7361386 , 0.35047214, 0.19804193, 0.24378612,\n",
      "       0.83522394, 0.3831178 ]), array([0.5, 0.5, 0.5, 0.4, 0.4, 0.5, 0.5, 0.4, 0.4, 0.5, 0.4, 0.4]), array([0.8861218 , 0.91485434, 0.87955661, 0.81252075, 0.77259351,\n",
      "       0.82039135, 0.87141909, 0.93828672, 0.93238769, 0.95803165,\n",
      "       0.77007465, 0.84335944]))\n",
      "0.6000000000000001\n",
      "0.5416010326422609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5426797952756166, 0.4916666666666667, array([0.56766117, 0.47527219, 0.58069546, 0.6319157 , 0.74789084,\n",
      "       0.74977854, 0.7328288 , 0.36167423, 0.20147168, 0.24571675,\n",
      "       0.83708673, 0.38016545]), array([0.5, 0.6, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5]), array([0.87512449, 0.91968123, 0.8709346 , 0.80412528, 0.79557057,\n",
      "       0.81879884, 0.86602248, 0.94759508, 0.94425977, 0.9450964 ,\n",
      "       0.77619797, 0.86085018]))\n",
      "0.7000000000000001\n",
      "0.5330069982904867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5427279745528589, 0.5416666666666666, array([0.57031407, 0.47620718, 0.5777379 , 0.62912817, 0.74983669,\n",
      "       0.74953848, 0.73052723, 0.36558017, 0.20239204, 0.24525344,\n",
      "       0.83738303, 0.3788373 ]), array([0.6, 0.6, 0.6, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.3, 0.5]), array([0.88486349, 0.90623009, 0.87862129, 0.81813941, 0.79471151,\n",
      "       0.81589419, 0.87242843, 0.95368028, 0.95198459, 0.9514059 ,\n",
      "       0.76710046, 0.83983572]))\n",
      "0.8\n",
      "0.5233746153162943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5418482761273528, 0.5833333333333334, array([0.56660896, 0.47785687, 0.57756748, 0.62563396, 0.75022258,\n",
      "       0.74875582, 0.72816836, 0.36333946, 0.19684505, 0.25098745,\n",
      "       0.83837813, 0.37781519]), array([0.6, 0.7, 0.6, 0.5, 0.5, 0.5, 0.6, 0.7, 0.7, 0.7, 0.3, 0.6]), array([0.87477682, 0.91164688, 0.87043891, 0.81108973, 0.79297544,\n",
      "       0.81305009, 0.86768453, 0.95802492, 0.95751801, 0.95704026,\n",
      "       0.77221893, 0.85493993]))\n",
      "0.9\n",
      "0.5151790025942177\n",
      "(0.5389088935584706, 0.6166666666666666, array([0.56699325, 0.47582438, 0.57242174, 0.62108665, 0.74923953,\n",
      "       0.74737354, 0.72397726, 0.35490109, 0.19370557, 0.24806202,\n",
      "       0.83811841, 0.3752033 ]), array([0.7, 0.8, 0.6, 0.5, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.3, 0.6]), array([0.88262949, 0.9158906 , 0.86177428, 0.80407818, 0.790322  ,\n",
      "       0.81009385, 0.862344  , 0.96108883, 0.93690505, 0.96105519,\n",
      "       0.77500022, 0.83714415]))\n",
      "1.0\n",
      "0.5075692080786435\n",
      "(0.5367145284583944, 0.65, array([0.56438654, 0.47163507, 0.57207889, 0.61677155, 0.74818918,\n",
      "       0.74534595, 0.71942028, 0.35743029, 0.19360184, 0.24140214,\n",
      "       0.83680711, 0.37350551]), array([0.8, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.8, 0.8, 0.8, 0.3, 0.7]), array([0.8884859 , 0.90530374, 0.8692748 , 0.79757579, 0.78782557,\n",
      "       0.80682583, 0.8569631 , 0.94949937, 0.94323473, 0.95116814,\n",
      "       0.77594452, 0.85026333]))\n"
     ]
    }
   ],
   "source": [
    "#Lama\n",
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_val_preds+(1-w)*val_pred\n",
    "    print(w)\n",
    "    new_pred = ((y_ensemble >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "    print(f1_score_max(y_val,y_ensemble,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.4580072685224435\n",
      "(0.49359570246201073, 0.6249999999999999, array([0.52567855, 0.43852914, 0.54602399, 0.59209251, 0.69997531,\n",
      "       0.72424481, 0.72971041, 0.17204494, 0.08372545, 0.22091029,\n",
      "       0.81851463, 0.37169841]), array([0.7, 0.8, 0.6, 0.5, 0.5, 0.6, 0.7, 0.7, 0.6, 0.8, 0.3, 0.7]), array([0.86222064, 0.9114338 , 0.84654447, 0.77814936, 0.75199625,\n",
      "       0.8100288 , 0.87108264, 0.89652697, 0.80563929, 0.92156084,\n",
      "       0.74013987, 0.84585588]))\n",
      "0.1\n",
      "0.4686004562840463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5077485438891499, 0.6249999999999999, array([0.53876687, 0.44769293, 0.55349253, 0.6046315 , 0.71357628,\n",
      "       0.73048127, 0.73376549, 0.2110483 , 0.11884438, 0.23701055,\n",
      "       0.82371557, 0.37995686]), array([0.7, 0.8, 0.6, 0.5, 0.5, 0.6, 0.7, 0.7, 0.6, 0.8, 0.3, 0.7]), array([0.86811742, 0.91440799, 0.85107304, 0.78811716, 0.76209413,\n",
      "       0.81453494, 0.87434842, 0.91328426, 0.87474094, 0.93396002,\n",
      "       0.74661535, 0.85298181]))\n",
      "0.2\n",
      "0.47911647975123506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5208088603704856, 0.6083333333333333, array([0.54764374, 0.45347116, 0.55988382, 0.61586546, 0.72683025,\n",
      "       0.73533016, 0.73805155, 0.25154886, 0.16777879, 0.24061164,\n",
      "       0.82804723, 0.38464367]), array([0.7, 0.7, 0.6, 0.5, 0.5, 0.6, 0.6, 0.7, 0.6, 0.8, 0.3, 0.7]), array([0.87182955, 0.89564324, 0.85453844, 0.79655524, 0.77139352,\n",
      "       0.81785679, 0.86648229, 0.92440045, 0.91831525, 0.94185306,\n",
      "       0.75202541, 0.85734216]))\n",
      "0.30000000000000004\n",
      "0.4898939990798123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.529193228141319, 0.6166666666666667, array([0.55399821, 0.45701692, 0.56404024, 0.62566893, 0.73816914,\n",
      "       0.74031251, 0.74113622, 0.27613616, 0.19835587, 0.23745275,\n",
      "       0.83195788, 0.38607392]), array([0.7, 0.8, 0.6, 0.5, 0.5, 0.5, 0.6, 0.7, 0.6, 0.8, 0.4, 0.7]), array([0.87388412, 0.91600275, 0.85596497, 0.80309576, 0.7786316 ,\n",
      "       0.80101203, 0.86916938, 0.9276909 , 0.9321948 , 0.94434949,\n",
      "       0.77177931, 0.85860047]))\n",
      "0.4\n",
      "0.49800040213247393\n",
      "(0.5337851886083411, 0.6166666666666667, array([0.55652982, 0.45884744, 0.56532689, 0.63315776, 0.74524761,\n",
      "       0.74576952, 0.74175066, 0.29235051, 0.2097307 , 0.23649808,\n",
      "       0.83628029, 0.38393299]), array([0.7, 0.8, 0.6, 0.5, 0.5, 0.5, 0.6, 0.7, 0.6, 0.8, 0.4, 0.7]), array([0.87374057, 0.915202  , 0.8548233 , 0.80722508, 0.78201401,\n",
      "       0.80397949, 0.87029087, 0.92756305, 0.93292825, 0.9451121 ,\n",
      "       0.77713554, 0.8574745 ]))\n",
      "0.5\n",
      "0.5016388822928762\n",
      "(0.53572301396097, 0.6333333333333334, array([0.55651741, 0.45837313, 0.56519989, 0.63756528, 0.74879143,\n",
      "       0.74944277, 0.74054456, 0.30150796, 0.21689457, 0.23384711,\n",
      "       0.83856363, 0.38142842]), array([0.7, 0.8, 0.7, 0.5, 0.5, 0.5, 0.6, 0.7, 0.7, 0.8, 0.4, 0.7]), array([0.87210768, 0.91349734, 0.87156488, 0.80885348, 0.78262635,\n",
      "       0.80560341, 0.8701361 , 0.92602661, 0.96094977, 0.94481155,\n",
      "       0.78021515, 0.85482778]))\n",
      "0.6000000000000001\n",
      "0.5019551098097399\n",
      "(0.536135316544336, 0.65, array([0.55558351, 0.45712721, 0.56788435, 0.63771128, 0.74883982,\n",
      "       0.75050487, 0.73818981, 0.30517518, 0.22270194, 0.2304381 ,\n",
      "       0.83909962, 0.3803681 ]), array([0.7, 0.8, 0.7, 0.5, 0.5, 0.6, 0.6, 0.8, 0.7, 0.8, 0.4, 0.7]), array([0.86927256, 0.91107492, 0.8681892 , 0.807649  , 0.78040131,\n",
      "       0.82292816, 0.86900564, 0.9515158 , 0.95558008, 0.94346127,\n",
      "       0.78116393, 0.85161584]))\n",
      "0.7000000000000001\n",
      "0.5005593874755307\n",
      "(0.5353146512475647, 0.6583333333333334, array([0.5575532 , 0.45298477, 0.56470156, 0.63525305, 0.74762337,\n",
      "       0.7513855 , 0.7352616 , 0.32201361, 0.2184456 , 0.22200653,\n",
      "       0.8384799 , 0.37806714]), array([0.8, 0.8, 0.7, 0.5, 0.5, 0.6, 0.6, 0.8, 0.7, 0.8, 0.4, 0.7]), array([0.88750572, 0.90744803, 0.86190886, 0.80498659, 0.77747647,\n",
      "       0.82160032, 0.86735706, 0.94792031, 0.9492504 , 0.94067101,\n",
      "       0.78068841, 0.8471254 ]))\n",
      "0.8\n",
      "0.4987307823740115\n",
      "(0.5321629552433124, 0.6833333333333335, array([0.55559449, 0.44401702, 0.56085834, 0.63264881, 0.74641925,\n",
      "       0.75047294, 0.73193113, 0.3227909 , 0.21370088, 0.21404858,\n",
      "       0.83719945, 0.37627369]), array([0.8, 0.8, 0.8, 0.5, 0.6, 0.6, 0.6, 0.8, 0.7, 0.9, 0.4, 0.7]), array([0.88335845, 0.90209853, 0.87523888, 0.80235333, 0.79402067,\n",
      "       0.81923174, 0.86541239, 0.94313604, 0.94421043, 0.95964435,\n",
      "       0.77923721, 0.84251833]))\n",
      "0.9\n",
      "0.49665616669472407\n",
      "(0.5285669812053401, 0.6833333333333332, array([0.55081517, 0.43389042, 0.55646503, 0.62976533, 0.74556575,\n",
      "       0.74915488, 0.72870028, 0.31869886, 0.21183827, 0.2080038 ,\n",
      "       0.83608681, 0.37381916]), array([0.8, 0.8, 0.8, 0.5, 0.6, 0.6, 0.6, 0.8, 0.8, 0.9, 0.3, 0.7]), array([0.878074  , 0.89629146, 0.8678864 , 0.79963933, 0.79089396,\n",
      "       0.816751  , 0.86351708, 0.93873981, 0.95815726, 0.95507765,\n",
      "       0.7670242 , 0.83764434]))\n",
      "1.0\n",
      "0.49428877376095776\n",
      "(0.524806956530541, 0.7000000000000001, array([0.54610128, 0.42494575, 0.55170266, 0.62691763, 0.74382282,\n",
      "       0.74725918, 0.7251595 , 0.31431459, 0.21263799, 0.1999356 ,\n",
      "       0.83512272, 0.36976376]), array([0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.9, 0.8, 0.9, 0.3, 0.7]), array([0.87291964, 0.89063243, 0.86118887, 0.81252075, 0.78728725,\n",
      "       0.81416036, 0.86124943, 0.95587391, 0.95360626, 0.94984479,\n",
      "       0.76649485, 0.83221633]))\n"
     ]
    }
   ],
   "source": [
    "#Scores\n",
    "for w in np.linspace(0,1,11):\n",
    "    print(w)\n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_scores\n",
    "    new_pred = ((y_ensemble >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "    print(f1_score_max(y_val,y_ensemble,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.5416010326422609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5426797952756166, 0.4916666666666667, array([0.56766117, 0.47527219, 0.58069546, 0.6319157 , 0.74789084,\n",
      "       0.74977854, 0.7328288 , 0.36167423, 0.20147168, 0.24571675,\n",
      "       0.83708673, 0.38016545]), array([0.5, 0.6, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5]), array([0.87512449, 0.91968123, 0.8709346 , 0.80412528, 0.79557057,\n",
      "       0.81879884, 0.86602248, 0.94759508, 0.94425977, 0.9450964 ,\n",
      "       0.77619797, 0.86085018]))\n"
     ]
    }
   ],
   "source": [
    "if True: #lama, full: 0.5291060382620348, short 0.5289615773736197 (0.5328972153003431,\n",
    "    w=0.6\n",
    "    y_ensemble=w*y_val_preds+(1-w)*val_pred\n",
    "else: #scores 0.5019551098097399\n",
    "    w=0.6 \n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_scores\n",
    "print(w)\n",
    "new_pred = ((y_ensemble >= 0.5) * 1)\n",
    "print(np.mean([f1_score(y_true=y_val[:,i],y_pred=new_pred[:,i]) for i in range(val_pred.shape[1])]))\n",
    "print(f1_score_max(y_val,y_ensemble,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds=np.array([0.6, 0.6, 0.6, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.4, 0.5]) #lama\n",
    "#thresholds=np.array([0.7, 0.8, 0.7, 0.5, 0.5, 0.6, 0.6, 0.8, 0.7, 0.8, 0.4, 0.7]) #scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 52.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirpath=os.path.join(DATA_DIR,'AU_Detection_Challenge/Validation_Set')\n",
    "ind=0\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,y_true=[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    splitted_line=line.split(',')\n",
    "                    aus=list(map(int,splitted_line))\n",
    "                    if min(aus)>=0:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            #X.append(y_val_preds[ind])\n",
    "                            X.append(y_ensemble[ind])\n",
    "                            indices.append(i)\n",
    "                            y_true.append(aus)\n",
    "                            ind+=1\n",
    "        test_videos[fn]=(np.array(X),indices,np.array(y_true))\n",
    "\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5416010326422609 [0.5676611738394397, 0.4719440992332404, 0.5806954646146671, 0.6309714712797007, 0.7478908380772189, 0.7497785404109547, 0.7328287978816668, 0.36167422545216105, 0.2014716750747084, 0.2457167508936275, 0.8284139005496169, 0.38016545440012783]\n",
      "3 0.5528112024399152 [0.579910441029606, 0.4827713694173321, 0.5948808207535107, 0.6405822164577029, 0.7580980856922936, 0.7599123206914424, 0.7460848493616405, 0.3835401855645259, 0.2075584405240731, 0.25345560871876666, 0.8383582181511984, 0.38858187291689067]\n",
      "5 0.5539261586365561 [0.5837142179668527, 0.4875051826165618, 0.5975835304105269, 0.6427864539332352, 0.7599265830529214, 0.7606266638337228, 0.7492707799365819, 0.3877104061072523, 0.19459881903438694, 0.25562372188139065, 0.8390952599935277, 0.3886722848717128]\n",
      "7 0.5535949604016204 [0.5849253385425288, 0.4882283846585976, 0.598285905999329, 0.6448600846562897, 0.7599842032661417, 0.7595888976089901, 0.7511314687032346, 0.38849568910050186, 0.18566489974648534, 0.25570935462501304, 0.8389007706147945, 0.38736452729753806]\n",
      "10 0.5520381951293492 [0.5858861132138953, 0.4892454940310541, 0.5994257991218105, 0.6482460916232402, 0.759585155205435, 0.756372892380047, 0.7512664871525717, 0.387801305100546, 0.16670789018055898, 0.25566701174454715, 0.8376924899312959, 0.38656161186718735]\n",
      "15 0.5485896969154594 [0.5841417558077643, 0.490353719184566, 0.5999332873067466, 0.6527151309237889, 0.7573808299873571, 0.7520911929027697, 0.7506394213580484, 0.3881010990534965, 0.13347055955798712, 0.2544073172530796, 0.8361106284048367, 0.38373142124507337]\n",
      "20 0.544495477255726 [0.5795117698343506, 0.48976701752474844, 0.5981893442045713, 0.6541919758011229, 0.7557591899601319, 0.749670466606761, 0.7492850597049978, 0.381527683454266, 0.10712428497139885, 0.25398981324278436, 0.8346107776372104, 0.3803183441263693]\n",
      "25 0.5397615003471172 [0.5744880108847383, 0.4898665964785903, 0.5965498227648681, 0.6533694734154343, 0.753253541293076, 0.7465471559839899, 0.7468233946013879, 0.3701172233858817, 0.08538945331398162, 0.25419145484045425, 0.8330960567314925, 0.3734458204715113]\n",
      "50 0.5235874148818092 [0.5477516616538561, 0.4722528969182973, 0.5837329908471656, 0.6478288219024891, 0.7410296021042962, 0.7346796810127376, 0.7345966239432269, 0.3321682535856334, 0.049862666384956685, 0.2529989094874591, 0.8276227775044217, 0.3585240932371694]\n"
     ]
    }
   ],
   "source": [
    "deltas=[0,3,5,7,10,15,20,25,50]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_aus,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if min(y_true[i])>=0:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_aus[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_aus[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_aus[cur_ind-1]+(1-w)*y_pred_aus[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            #aus=(pred>=thresholds)*1\n",
    "            aus=(pred>=0.5)*1\n",
    "            cur_preds.append(aus)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if min(y_true[i])>=0:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "    \n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    f1scores=[f1_score(y_true=total_true[:,i],y_pred=preds[:,i]) for i in range(preds.shape[1])]\n",
    "    print(delta,np.mean(f1scores),f1scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble\n",
    "lama\n",
    "full\n",
    "0.5: 7 0.5427202485732338 [0.5622850736998378, 0.45635588056063375, 0.5834574644157564, 0.6499061984267667, 0.7627329722580009, 0.7617615138869782, 0.7543433571649475, 0.3409326700540023, 0.18967013888888887, 0.21496013713912548, 0.8455688622754491, 0.39066871410841625]\n",
    "thresholds: 5 0.5432475964435367 [0.5642816654171771, 0.4488306111494517, 0.5772163887845584, 0.6476236040168667, 0.7623334408840132, 0.7630356063335431, 0.7523382714481408, 0.33635214283871306, 0.20305710342007058, 0.2317432941496846, 0.8427327858772562, 0.3894262430029634]\n",
    "\n",
    "\n",
    "short:\n",
    "0.5:7 0.5427907663334933 [0.5630333621329938, 0.4562853520577336, 0.5832971546312185, 0.6500648776726781, 0.762558855052603, 0.7617918112209808, 0.7543074431890543, 0.3407990636803745, 0.19031610909288077, 0.21513900955690704, 0.845619942504259, 0.3902762152102369]\n",
    "thresholds:5 0.5431849232592929 [0.5644161684857127, 0.4485259171815352, 0.577370220195312, 0.647618422163638, 0.7621896595853596, 0.7629270079677626, 0.7524146096929171, 0.33580819798917244, 0.20416304403416355, 0.23122118774292688, 0.8427077480177311, 0.38885689605528356]\n",
    "\n",
    "scores:\n",
    "0.5:15 0.517485099031021 [0.5110772245768854, 0.3995639808872825, 0.5626289591177739, 0.6629337763450671, 0.7581380057840585, 0.7529381632332309, 0.7477873881122398, 0.24575849893564136, 0.18515073358420361, 0.19044676876002176, 0.836244169874346, 0.35715351916150173]\n",
    "thresholds:5 0.544937801517075 [0.5689467619638525, 0.46471474766984183, 0.5794526569042496, 0.6510396393236463, 0.7598485881695998, 0.7577554053313476, 0.752400073006023, 0.31074004906807284, 0.22262266385213406, 0.23435941759191542, 0.8465570983281383, 0.3908165169960802]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:25<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'faces')\n",
    "dirpath=os.path.join(DATA_DIR,'AU_Detection_Challenge/Validation_Set')\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,y_true=[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    if imagename in filename2featuresAll:\n",
    "                        X.append(filename2featuresAll[imagename][0])\n",
    "                        indices.append(i)\n",
    "                        splitted_line=line.split(',')\n",
    "                        aus=list(map(int,splitted_line))\n",
    "                        y_true.append(aus)\n",
    "        test_videos[fn]=(mlpModel.predict(np.array(X)),indices,np.array(y_true))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.9, 0.8, 0.9, 0.3, 0.7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0 0.524806956530541\n",
      "mean 2 0.5318321046837913\n",
      "median 2 0.5307851342641186\n",
      "mean 7 0.5309452680793919\n",
      "median 7 0.5353606647251313\n"
     ]
    }
   ],
   "source": [
    "hyperparams=[(isMean,delta) for delta in [0,2,7]  for isMean in [1,0] if not (isMean==0 and delta==0)]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(hyperparams))]\n",
    "for videoname,(y_pred_aus,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if min(y_true[i])>=0:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_aus[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_aus[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_aus[cur_ind-1]+(1-w)*y_pred_aus[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            if isMean:\n",
    "                pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            else:\n",
    "                pred=np.median(preds[i1:i+delta+1],axis=0)\n",
    "            aus=(pred>=thresholds)*1\n",
    "            cur_preds.append(aus)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if min(y_true[i])>=0:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print('mean' if isMean else 'median',delta,np.mean([f1_score(y_true=total_true[:,i],y_pred=preds[:,i]) for i in range(preds.shape[1])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5367145284583944 [0.5643865382761913, 0.47163506664163696, 0.5720788851524985, 0.6167715525660951, 0.7481891822104622, 0.7453459491425192, 0.7194202822032445, 0.35743029196038706, 0.1936018353301045, 0.24140213944736752, 0.8368071098332, 0.37350550873702587]\n",
      "3 0.5456568248392965 [0.5674285557114173, 0.47954985800355654, 0.5847582276153704, 0.6280900760667186, 0.7568499180944555, 0.7563628582636914, 0.730513605990577, 0.3764893278114049, 0.19621683784748384, 0.24640049809323683, 0.8441518388609688, 0.38107029571267775]\n",
      "5 0.5453739302190261 [0.5657975774994868, 0.48083283630645773, 0.585573303174431, 0.6316280153828225, 0.758441128845092, 0.7566440885600956, 0.7331032058619416, 0.37811175847457634, 0.18319553266092375, 0.24745175456266874, 0.8443020458426168, 0.37940591545719965]\n",
      "7 0.5445119128957571 [0.5608856788087317, 0.48035608472170543, 0.5852735306768857, 0.6356666291677845, 0.7593075924360897, 0.7553905469084677, 0.7336282104100361, 0.37789685654800503, 0.17457900807381777, 0.24949983327775926, 0.8436271056879239, 0.37803187803187804]\n",
      "10 0.5416391816305005 [0.5536061247571267, 0.4781175144427223, 0.5844450595073346, 0.6388744228031802, 0.7587162219759611, 0.7537906868042716, 0.7336720512177897, 0.37462364067868653, 0.15719228868017796, 0.2502683900888908, 0.8422396572735154, 0.37412412133634854]\n",
      "15 0.5349712162447015 [0.5369723204003019, 0.47098611091037845, 0.5814611255745187, 0.642444354441846, 0.757447193836107, 0.7510888410917606, 0.731626208575431, 0.36889102967875803, 0.12419215855234814, 0.24533786503286972, 0.8399887018169164, 0.36921868502518135]\n",
      "20 0.5294193258656613 [0.5239654176337635, 0.4650310375406444, 0.5781963516780491, 0.6447642367976535, 0.7556429175599402, 0.7482370458606314, 0.7284599045798875, 0.36176087123245654, 0.09939101459266919, 0.24514585442164352, 0.8384024305571737, 0.3640348279334242]\n",
      "25 0.5234582906500872 [0.5102743965339386, 0.4577631956939173, 0.57358185966444, 0.6468365722681874, 0.7538473814400085, 0.7453365822852683, 0.7260954507396036, 0.3503164556962025, 0.08060331825037707, 0.24310068757652822, 0.8371963493067922, 0.35654723834578306]\n",
      "50 0.5008177570051234 [0.4520388434836101, 0.42419829789988023, 0.5473778205172236, 0.6483403773718368, 0.744024364964202, 0.7334021245757707, 0.7102284880432354, 0.30636065573770493, 0.042986425339366516, 0.23424820385589495, 0.8325120818000162, 0.33409540047274]\n"
     ]
    }
   ],
   "source": [
    "deltas=[0,3,5,7,10,15,20,25,50]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_aus,indices,y_true) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if min(y_true[i])>=0:\n",
    "            total_true.append(y_true[i])\n",
    "    cur_ind=0\n",
    "    preds=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds.append(y_pred_aus[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds.append(y_pred_aus[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_aus[cur_ind-1]+(1-w)*y_pred_aus[cur_ind]\n",
    "                preds.append(pred)\n",
    "    \n",
    "    preds=np.array(preds)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        cur_preds=[]\n",
    "        for i in range(len(preds)):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            aus=(pred>=thresholds)*1\n",
    "            #aus=(pred>=0.5)*1\n",
    "            cur_preds.append(aus)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if min(y_true[i])>=0:\n",
    "                total_preds[hInd].append(cur_preds[ind-1])\n",
    "    \n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    f1scores=[f1_score(y_true=total_true[:,i],y_pred=preds[:,i]) for i in range(preds.shape[1])]\n",
    "    print(delta,np.mean(f1scores),f1scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729737 ['image_location,AU1,AU2,AU4,AU6,AU7,AU10,AU12,AU15,AU23,AU24,AU25,AU26', '2-30-640x360/00001.jpg,', '2-30-640x360/00002.jpg,', '2-30-640x360/00003.jpg,', '2-30-640x360/00004.jpg,']\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_DIR,'test_set','CVPR_5th_ABAW_AU_test_set_sample.txt'),'r') as f:\n",
    "    test_set_sample=f.read().splitlines()\n",
    "print(len(test_set_sample),test_set_sample[:5])\n",
    "\n",
    "test_set_videos={}\n",
    "for s in test_set_sample[1:]:\n",
    "    videoname,img_name=s[:-1].split('/')\n",
    "    if videoname not in test_set_videos:\n",
    "        test_set_videos[videoname]=[]\n",
    "    test_set_videos[videoname].append(img_name)\n",
    "    \n",
    "print(len(test_set_videos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:34<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames=[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][0])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    X=np.array(X)\n",
    "    test_videos[videoname]=(mlpModel.predict(X),indices,filenames)\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2-30-640x360': (19347, 6), '3-25-1920x1080': (6189, 0), '6-30-1920x1080_left': (7672, 314), '6-30-1920x1080_right': (7984, 2), '11-24-1920x1080': (5302, 88), '14-30-1920x1080': (5311, 0), '27-60-1280x720': (2933, 0), '32-60-1920x1080': (4460, 0), '36-24-1280x720': (5124, 137), '38-30-1920x1080': (2401, 31), '40-30-1280x720': (8767, 893), '42-30-480x480': (1395, 0), '55-25-1280x720': (1476, 30), '56-30-1080x1920': (4168, 133), '58-30-640x480': (2843, 34), '62-30-654x480': (12034, 0), '70-30-720x1280': (2781, 3), '74-25-1920x1080': (5042, 0), '80-30-320x240': (5674, 0), '88-30-360x480': (3658, 65), '91-30-1920x1080': (10779, 143), '102-30-640x360': (2979, 5), '102': (4508, 270), '103-30-384x480': (772, 0), '103': (26551, 67), '105-30-1280x720': (1479, 23), '108-15-640x480': (466, 13), '109-30-1280x720': (1046, 0), '119': (4578, 0), '128-24-1920x1080': (3794, 19), '130-25-1280x720_left': (8086, 376), '130-25-1280x720_right': (8462, 0), '130': (4002, 0), '133-30-1280x720': (2401, 3), '134-30-1280x720': (3681, 194), '137-30-1920x1080': (8503, 50), '139': (7100, 1066), '147': (19406, 289), '159': (3366, 93), '164': (7044, 0), '165': (4350, 218), '171': (3931, 46), '194': (4537, 0), '197': (1784, 86), '199': (2850, 68), '204': (5879, 46), '209': (2455, 401), '212': (4140, 422), '219': (3576, 315), '234': (2905, 14), '239': (1964, 0), '241': (3512, 0), '244': (2286, 35), '265': (6691, 28), '266': (2465, 0), '267': (3841, 0), '268': (4364, 2), '270': (3935, 2), '274': (3526, 0), '281': (7011, 0), '284': (4054, 0), '286': (2678, 0), '289': (4203, 0), '303': (3897, 53), '304': (2694, 0), '307': (3311, 0), '311': (1930, 0), '313': (3140, 0), '322': (2429, 0), '336': (4344, 0), '344': (4263, 0), '349': (4054, 0), '353': (2775, 81), '357': (1373, 0), '358': (324, 0), '365': (1067, 0), '367': (4169, 0), '370': (1939, 0), '375': (2947, 10), '380': (2288, 87), '381': (1265, 0), '382': (2713, 0), '408': (2978, 0), '416': (6509, 3), '434': (5233, 0), '439': (2308, 0), '450': (9820, 87), 'video2': (1778, 287), 'video2_left': (144, 1921), 'video3': (7802, 0), 'video4': (1072, 479), 'video6': (4620, 705), 'video7': (3027, 351), 'video8': (5256, 112), 'video9': (3773, 22), 'video11': (4132, 248), 'video12': (5580, 0), 'video13': (10551, 16), 'video14': (7583, 3), 'video15': (4288, 0), 'video16': (12486, 1), 'video17': (21938, 0), 'video18': (3784, 0), 'video19': (775, 10), 'video20': (11272, 0), 'video21': (6787, 22), 'video22': (10458, 12), 'video23': (8783, 7), 'video24': (5202, 3), 'video25': (3641, 4), 'video26': (11021, 0), 'video27': (16410, 9), 'video28': (8728, 0), 'video30': (8209, 5), 'video32': (2751, 25), 'video33': (7538, 16), 'video34': (10262, 20), 'video35': (3568, 0), 'video36': (2386, 39), 'video37': (8820, 367), 'video38': (2936, 9), 'video39': (10671, 8), 'video40': (5877, 0), 'video41': (3466, 29), 'video42': (9217, 10), 'video44': (7778, 8), 'video45_1': (805, 8), 'video45_2': (1096, 0), 'video45_3': (295, 0), 'video45_4': (1039, 0), 'video45_5': (415, 0), 'video45_6': (309, 0), 'video45_7': (180, 0), 'video46': (3167, 6), 'video47': (812, 9), 'video48': (2532, 11), 'video49_left': (6109, 13), 'video49_right': (6071, 51), 'video51': (4406, 2), 'video52': (10671, 9), 'video53': (7967, 13)}\n"
     ]
    }
   ],
   "source": [
    "print(test_videos_num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=5\n",
    "resdir=os.path.join(DATA_DIR,'test_set/test_results/AU')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_au_results(res_filename):\n",
    "    with open(os.path.join(resdir,res_filename), 'w') as f:\n",
    "        f.write(test_set_sample[0]+'\\n')\n",
    "        for videoname,(y_pred_au,indices,filenames) in test_videos.items():\n",
    "            cur_ind=0\n",
    "            preds=[]\n",
    "            for i in range(indices[-1]):\n",
    "                if indices[cur_ind]-1==i:\n",
    "                    preds.append(y_pred_au[cur_ind])\n",
    "                    cur_ind+=1\n",
    "                else:\n",
    "                    if cur_ind==0:\n",
    "                        preds.append(y_pred_au[cur_ind])\n",
    "                    else:\n",
    "                        w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                        pred=w*y_pred_au[cur_ind-1]+(1-w)*y_pred_au[cur_ind]\n",
    "                        preds.append(pred)\n",
    "\n",
    "            pred=y_pred_au[cur_ind-1]\n",
    "            for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "                preds.append(pred)\n",
    "\n",
    "            preds=np.array(preds)\n",
    "            for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "                i1=max(i-delta,0)\n",
    "                pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "                aus=(pred>=thresholds)*1\n",
    "                f.write(videoname+'/'+img_name+','+','.join(map(str,aus))+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_filename='predictions_1_mt_mlp.txt'\n",
    "#res_filename='predictions_2_vgaf_mlp.txt'\n",
    "res_filename='predictions_5_vgaf_mlp_train_val.txt'\n",
    "write_au_results(res_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos_mt=test_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 [0.7 0.8 0.7 0.5 0.5 0.5 0.6 0.8 0.7 0.8 0.3 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(weight,thresholds)\n",
    "with open(os.path.join(resdir,'predictions_3_mt_vgaf.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_au,indices,filenames) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        preds=[]\n",
    "        y_pred_au_mtl,_,_=test_videos_mt[videoname]\n",
    "        y_ensemble=weight*y_pred_au+(1-weight)*y_pred_au_mtl\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds.append(y_ensemble[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds.append(pred)\n",
    "\n",
    "        pred=y_ensemble[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds=np.array(preds)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            aus=(pred>=thresholds)*1\n",
    "            f.write(videoname+'/'+img_name+','+','.join(map(str,aus))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [01:33<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_videos_lama={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames=[],[],[]\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][1])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "    X=np.array(X)\n",
    "    df_test=pd.DataFrame(data=X,columns=['f'+str(i) for i in range(X.shape[1])])\n",
    "    test_videos_lama[videoname]=automl.predict(df_test).data\n",
    "\n",
    "print(len(test_videos_lama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.6\n",
    "\n",
    "with open(os.path.join(resdir,'predictions_4_vgaf_lama.txt'), 'w') as f:\n",
    "    f.write(test_set_sample[0]+'\\n')\n",
    "    for videoname,(y_pred_au,indices,filenames) in test_videos.items():\n",
    "        cur_ind=0\n",
    "        preds=[]\n",
    "        y_pred_au_lama=test_videos_lama[videoname]\n",
    "        y_ensemble=weight*y_pred_au+(1-weight)*y_pred_au_lama\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds.append(y_ensemble[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds.append(pred)\n",
    "\n",
    "        pred=y_ensemble[cur_ind-1]\n",
    "        for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "            preds.append(pred)\n",
    "\n",
    "        preds=np.array(preds)\n",
    "        for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "            i1=max(i-delta,0)\n",
    "            pred=np.mean(preds[i1:i+delta+1],axis=0)\n",
    "            aus=(pred>=0.5)*1\n",
    "            f.write(videoname+'/'+img_name+','+','.join(map(str,aus))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
