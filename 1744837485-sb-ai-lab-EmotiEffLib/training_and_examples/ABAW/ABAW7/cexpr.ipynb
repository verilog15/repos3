{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/HDD6TB/datasets/emotions/ABAW/ABAW_7/CE/'\n",
    "VIDEO_DIR=DATA_DIR+'videos/'\n",
    "FRAMES_DIR=DATA_DIR+'frames/'\n",
    "FACES_DIR=DATA_DIR+'faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,roc_auc_score,average_precision_score\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(id):\n",
    "    name = \"\"\n",
    "    if id>=0 and id<10:\n",
    "        name = \"0000\" + str(id)\n",
    "    elif id>=10 and id<100:\n",
    "        name = \"000\" + str(id)\n",
    "    elif id>=100 and id<1000:\n",
    "        name = \"00\" + str(id)\n",
    "    elif id>=1000 and id<10000:\n",
    "        name = \"0\" + str(id)\n",
    "    else:\n",
    "        name = str(id)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_filenames=lambda x: int(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [01:47<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(os.listdir(VIDEO_DIR)):\n",
    "    frames_dir=FRAMES_DIR + str(os.path.splitext(filename)[0])\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.mkdir(frames_dir)\n",
    "    command = \"ffmpeg -r 1 -i \" + VIDEO_DIR + str(filename) + \" -r 1 '\" + frames_dir + \"/%04d.png'\"\n",
    "    #print(command)\n",
    "    os.system(command=command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 659 0659.png\n",
      "02 278 0278.png\n",
      "03 302 0302.png\n",
      "04 1204 1204.png\n",
      "05 188 0188.png\n",
      "06 61 0061.png\n",
      "07 128 0128.png\n",
      "08 302 0302.png\n",
      "09 91 0087.png\n",
      "10 36 0035.png\n",
      "11 228 0228.png\n",
      "12 444 0444.png\n",
      "13 69 0069.png\n",
      "14 5459 5459.png\n",
      "15 786 0786.png\n",
      "16 265 0265.png\n",
      "17 67 0067.png\n",
      "18 282 0282.png\n",
      "19 255 0255.png\n",
      "20 205 0205.png\n",
      "21 377 0377.png\n",
      "22 69 0068.png\n",
      "23 66 0066.png\n",
      "24 660 0626.png\n",
      "25 266 0266.png\n",
      "26 2438 2438.png\n",
      "27 56 0056.png\n",
      "28 329 0329.png\n",
      "29 91 0091.png\n",
      "30 72 0072.png\n",
      "31 773 0773.png\n",
      "32 412 0412.png\n",
      "33 192 0192.png\n",
      "34 56 0056.png\n",
      "35 196 0196.png\n",
      "36 577 0577.png\n",
      "37 154 0154.png\n",
      "38 703 0703.png\n",
      "39 495 0495.png\n",
      "40 768 0768.png\n",
      "41 319 0319.png\n",
      "42 563 0563.png\n",
      "43 75 0075.png\n",
      "44 386 0386.png\n",
      "45 62 0061.png\n",
      "46 352 0352.png\n",
      "47 180 0180.png\n",
      "48 104 0104.png\n",
      "49 597 0597.png\n",
      "50 273 0273.png\n",
      "51 482 0482.png\n",
      "52 76 0076.png\n",
      "53 442 0442.png\n",
      "54 478 0478.png\n",
      "55 1465 1465.png\n",
      "56 266 0266.png\n"
     ]
    }
   ],
   "source": [
    "video2len={}\n",
    "for filename in sorted(os.listdir(VIDEO_DIR)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    vid=os.path.join(VIDEO_DIR,filename)\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video2len[fn]=total_frames #+1 #FIX ME!!! NEED TO ADD 1 to teh number of frames for consistency with challeng's organizer\n",
    "    \n",
    "    dn=os.path.join(FRAMES_DIR,fn)\n",
    "    last_img=''\n",
    "    if os.path.exists(dn):\n",
    "        images=[img_name for img_name in os.listdir(dn) if img_name.lower().endswith('.png')]\n",
    "        last_img=sorted(images, key=compare_filenames)[-1]\n",
    "    if True or str(total_frames) not in last_img:\n",
    "        print(fn,total_frames,last_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh=mp_face_mesh.FaceMesh(max_num_faces=1,refine_landmarks=True,min_detection_confidence=0.5,min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface.pre_trained_models import get_model\n",
    "model = get_model(\"resnet50_2020-07-20\", max_size=1024,device='cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from skimage import transform as trans\n",
    "def preprocess(img, bbox=None, landmark=None, **kwargs):\n",
    "    M = None\n",
    "    image_size = [224,224]\n",
    "    src = np.array([\n",
    "      [30.2946, 51.6963],\n",
    "      [65.5318, 51.5014],\n",
    "      [48.0252, 71.7366],\n",
    "      [33.5493, 92.3655],\n",
    "      [62.7299, 92.2041] ], dtype=np.float32 )\n",
    "    if image_size[1]==224:\n",
    "        src[:,0] += 8.0\n",
    "    src*=2\n",
    "    if landmark is not None:\n",
    "        dst = landmark.astype(np.float32)\n",
    "\n",
    "        tform = trans.SimilarityTransform()\n",
    "        #dst=dst[:3]\n",
    "        #src=src[:3]\n",
    "        #print(dst.shape,src.shape,dst,src)\n",
    "        tform.estimate(dst, src)\n",
    "        M = tform.params[0:2,:]\n",
    "        #M = cv2.estimateRigidTransform( dst.reshape(1,5,2), src.reshape(1,5,2), False)\n",
    "        #print(M)\n",
    "\n",
    "    if M is None:\n",
    "        if bbox is None: #use center crop\n",
    "            det = np.zeros(4, dtype=np.int32)\n",
    "            det[0] = int(img.shape[1]*0.0625)\n",
    "            det[1] = int(img.shape[0]*0.0625)\n",
    "            det[2] = img.shape[1] - det[0]\n",
    "            det[3] = img.shape[0] - det[1]\n",
    "        else:\n",
    "              det = bbox\n",
    "        margin = kwargs.get('margin', 44)\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin//2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin//2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin//2, img.shape[1])\n",
    "        bb[3] = np.minimum(det[3]+margin//2, img.shape[0])\n",
    "        ret = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "        if len(image_size)>0:\n",
    "              ret = cv2.resize(ret, (image_size[1], image_size[0]))\n",
    "        return ret \n",
    "    else: #do align using landmark\n",
    "        assert len(image_size)==2\n",
    "        warped = cv2.warpAffine(img,M,(image_size[1],image_size[0]), borderValue = 0.0)\n",
    "        return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [33:27<00:00, 35.85s/it] \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(FACES_DIR):\n",
    "    os.mkdir(FACES_DIR)\n",
    "for folder in tqdm(os.listdir(FRAMES_DIR)):\n",
    "    folder_full_path=os.path.join(FACES_DIR, folder)\n",
    "    if not os.path.exists(folder_full_path):\n",
    "        os.mkdir(folder_full_path)\n",
    "\n",
    "        for image_file in os.listdir(os.path.join(FRAMES_DIR, folder)):\n",
    "            filename = os.path.join(FRAMES_DIR, folder, image_file)\n",
    "            image = cv2.imread(filename)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            annotations = model.predict_jsons(image_rgb)\n",
    "            if len(annotations)==0 or not annotations[0][\"bbox\"]:\n",
    "                pass #print('No faces')\n",
    "            else:\n",
    "                root,ext=os.path.splitext(image_file)\n",
    "                faces_folder=os.path.join(folder_full_path, root) \n",
    "                if not os.path.exists(faces_folder):\n",
    "                    os.mkdir(faces_folder)\n",
    "                for i,annotation in enumerate(annotations):\n",
    "                    outfile=os.path.join(faces_folder, str(i)+ext)\n",
    "                    if not os.path.exists(outfile):\n",
    "                        box = np.array(annotation['bbox']).astype(int)\n",
    "                        x1,y1,x2,y2=box[0:4]    \n",
    "                        x1=max(x1,0)\n",
    "                        y1=max(y1,0)\n",
    "                        face_img=image[y1:y2,x1:x2,:]\n",
    "                        if np.prod(face_img.shape)==0:\n",
    "                            print('Empty face ', x1,x2,y1,y2,folder,image_file)\n",
    "                            continue\n",
    "                        cv2.imwrite(outfile, face_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FACES_DIR):\n",
    "    os.mkdir(FACES_DIR)\n",
    "for folder in tqdm(os.listdir(FRAMES_DIR)):\n",
    "    folder_full_path=os.path.join(FACES_DIR, folder)\n",
    "    if not os.path.exists(folder_full_path):\n",
    "        os.mkdir(folder_full_path)\n",
    "\n",
    "        for image_file in os.listdir(os.path.join(FRAMES_DIR, folder)):\n",
    "            filename = os.path.join(FRAMES_DIR, folder, image_file)\n",
    "            image = cv2.imread(filename)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            results = face_mesh.process(image_rgb)\n",
    "            if results.multi_face_landmarks:\n",
    "                height,width,_=image.shape\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    x1 = y1 = 1\n",
    "                    x2 = y2 = 0\n",
    "                    for id, lm in enumerate(face_landmarks.landmark):\n",
    "                        cx, cy = lm.x, lm.y\n",
    "                        if cx<x1:\n",
    "                            x1=cx\n",
    "                        if cy<y1:\n",
    "                            y1=cy\n",
    "                        if cx>x2:\n",
    "                            x2=cx\n",
    "                        if cy>y2:\n",
    "                            y2=cy\n",
    "                    if x1<0:\n",
    "                        x1=0\n",
    "                    if y1<0:\n",
    "                        y1=0\n",
    "                    x1,x2=int(x1*width),int(x2*width)\n",
    "                    y1,y2=int(y1*height),int(y2*height)\n",
    "                    face_img=image_rgb[y1:y2,x1:x2,:]\n",
    "                    if np.prod(face_img.shape)==0:\n",
    "                        print('Empty face ', x1,x2,y1,y2,folder,image_file)\n",
    "                        continue\n",
    "                    cv2.imwrite(os.path.join(folder_full_path, image_file), face_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 644 659\n",
      "02 157 278\n",
      "03 302 302\n",
      "04 1094 1204\n",
      "05 188 188\n",
      "06 48 61\n",
      "07 128 128\n",
      "08 302 302\n",
      "09 35 87\n",
      "10 33 35\n",
      "11 215 228\n",
      "12 431 444\n",
      "13 69 69\n",
      "14 5315 5459\n",
      "15 476 786\n",
      "16 265 265\n",
      "17 61 67\n",
      "18 175 282\n",
      "19 99 255\n",
      "20 205 205\n",
      "21 312 377\n",
      "22 56 68\n",
      "23 66 66\n",
      "24 421 626\n",
      "25 266 266\n",
      "26 1989 2438\n",
      "27 56 56\n",
      "28 234 329\n",
      "29 91 91\n",
      "30 70 72\n",
      "31 770 773\n",
      "32 412 412\n",
      "33 192 192\n",
      "34 56 56\n",
      "35 196 196\n",
      "36 577 577\n",
      "37 144 154\n",
      "38 669 703\n",
      "39 384 495\n",
      "40 432 768\n",
      "41 203 319\n",
      "42 434 563\n",
      "43 63 75\n",
      "44 378 386\n",
      "45 61 61\n",
      "46 352 352\n",
      "47 38 180\n",
      "48 102 104\n",
      "49 592 597\n",
      "50 234 273\n",
      "51 482 482\n",
      "52 75 76\n",
      "53 334 442\n",
      "54 344 478\n",
      "55 1097 1465\n",
      "56 217 266\n"
     ]
    }
   ],
   "source": [
    "for folder in sorted(os.listdir(FACES_DIR)):\n",
    "    print(folder, len(os.listdir(os.path.join(FACES_DIR, folder))), len(os.listdir(os.path.join(FRAMES_DIR, folder))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.0.1+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes=7\n",
    "if True:\n",
    "    #PATH='affectnet_vggface2_enet2_gmp_smooth.pt'\n",
    "    PATH='enet_b2_8_best.pt'\n",
    "    #PATH='enet_b2_7.pt'\n",
    "    IMG_SIZE=260 #224 #\n",
    "else:\n",
    "    #PATH='affectnet_vggface2_enet0.pt'\n",
    "    #PATH='affectnet_vggface2_enet0_new.pt'\n",
    "    #PATH='enet_b0_7.pt'\n",
    "    #PATH='enet_b0_8_best_afew.pt'\n",
    "    PATH='enet_b0_8_best_vgaf.pt'\n",
    "    #PATH='enet_b0_8_va_mtl.pt'\n",
    "    #PATH='affectnet_vggface2_mobilevit_mtl_new.pt'\n",
    "    \n",
    "    IMG_SIZE=224\n",
    "    \n",
    "#IMG_SIZE=112\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "np_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(None),\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    PATH='affectnet_vggface2_mbf_va.pt'\n",
    "    \n",
    "    IMG_SIZE=112\n",
    "    \n",
    "    test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((112,112)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    import sys\n",
    "    import os\n",
    "    FILE_DIR = pathlib.Path(__file__).parent.resolve()\n",
    "    path_to_backbones = os.path.join(FILE_DIR, \"..\", \"..\", \"..\", \"emotiefflib\", \"backbones\")\n",
    "    if path_to_backbones not in sys.path:\n",
    "        sys.path.append(path_to_backbones)\n",
    "    import mobilefacenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b2_8_best.pt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)\n",
    "feature_extractor_model = torch.load('/home/avsavchenko/src/face-emotion-recognition/models/affectnet_emotions/'+PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    IMG_SIZE=112\n",
    "    \n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])  \n",
    "    \n",
    "    import sys\n",
    "    DDAMNFN_PATH='/home/avsavchenko/src/distr/DDAMFN'\n",
    "    sys.path.append(DDAMNFN_PATH)\n",
    "    from networks.DDAM import DDAMNet\n",
    "\n",
    "    if True:\n",
    "        feature_extractor_model = DDAMNet(num_class=8, num_head=2)\n",
    "        model_name='affectnet8_epoch4_acc0.6462'\n",
    "    else:\n",
    "        feature_extractor_model = DDAMNet(num_class=10, num_head=2)\n",
    "        model_name='affectnet8_epoch9_acc0.642_mtl_2'\n",
    "    feature_extractor_model.load_state_dict(torch.load(DDAMNFN_PATH+'/checkpoints/'+model_name+'.pth')['model_state_dict'])\n",
    "    feature_extractor_model.bn=torch.nn.Identity()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 512) [[-0.02266632  0.03422606  0.04598025 ... -0.03784892 -0.02933266\n",
      "  -0.02419638]\n",
      " [-0.06048942 -0.01143544  0.04876871 ... -0.00673319 -0.03489853\n",
      "  -0.04350665]\n",
      " [ 0.00924769  0.01705422 -0.02023846 ... -0.04731875 -0.04449094\n",
      "   0.01527624]\n",
      " ...\n",
      " [ 0.02578277  0.02344748  0.02957167 ...  0.03510113  0.03270051\n",
      "  -0.02460761]\n",
      " [ 0.02018657 -0.03497695  0.01600289 ...  0.04777396  0.01695777\n",
      "  -0.00137146]\n",
      " [ 0.01643609  0.00521718 -0.01940052 ...  0.0298525  -0.028677\n",
      "   0.04591733]]\n",
      "(8,) [ 0.0492584  -0.05201729 -0.02789966 -0.06214872 -0.05696991  0.05707647\n",
      " -0.00724991 -0.0286497 ]\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    classifier_weights=feature_extractor_model.classifier[0].weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier[0].bias.cpu().data.numpy()\n",
    "elif False:\n",
    "    classifier_weights=feature_extractor_model.classifier.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier.bias.cpu().data.numpy()\n",
    "elif False:\n",
    "    classifier_weights=feature_extractor_model.head.fc.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.head.fc.bias.cpu().data.numpy()\n",
    "else:\n",
    "    classifier_weights=feature_extractor_model.fc.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.fc.bias.cpu().data.numpy()\n",
    "print(classifier_weights.shape,classifier_weights)\n",
    "print(classifier_bias.shape,classifier_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDAMNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv_block(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (1): Conv_block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (2): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=32, bias=False)\n",
       "          (2): Conv2d(32, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=32, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=64, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (9): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (10): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (11): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (12): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (13): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (14): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (15): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1024)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256, bias=False)\n",
       "          (2): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=256, bias=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=256, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1024)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Conv_block(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "  )\n",
       "  (cat_head0): CoordAttHead(\n",
       "    (CoordAtt): CoordAtt(\n",
       "      (Linear_h): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Linear_w): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): h_swish(\n",
       "        (sigmoid): h_sigmoid(\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Linear): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (flatten): Flatten()\n",
       "    )\n",
       "  )\n",
       "  (cat_head1): CoordAttHead(\n",
       "    (CoordAtt): CoordAtt(\n",
       "      (Linear_h): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Linear_w): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): h_swish(\n",
       "        (sigmoid): h_sigmoid(\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Linear): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (flatten): Flatten()\n",
       "    )\n",
       "  )\n",
       "  (Linear): Linear_block(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (flatten): Flatten()\n",
       "  (fc): Identity()\n",
       "  (bn): Identity()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    feature_extractor_model.classifier=torch.nn.Identity()\n",
    "elif False:\n",
    "    feature_extractor_model.head.fc=torch.nn.Identity()\n",
    "else:\n",
    "    feature_extractor_model.fc=torch.nn.Identity()\n",
    "feature_extractor_model=feature_extractor_model.to(device)\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probab(features):\n",
    "    x=np.dot(features,np.transpose(classifier_weights))+classifier_bias\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(112, 112), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_6/CE/faces/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbde79ec2f0481aa761407efcf7986a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "data_dir=FACES_DIR\n",
    "print(data_dir)\n",
    "\n",
    "videoname2featuresAll={}\n",
    "for videoname in tqdm(os.listdir(data_dir)):\n",
    "    frames_dir=os.path.join(data_dir,videoname)\n",
    "    X_global_features,X_global_scores,img_names=[],[],[]\n",
    "    for filename in sorted(os.listdir(frames_dir)):\n",
    "        faces_dir=os.path.join(frames_dir,filename)\n",
    "        imgs=[]\n",
    "        global_features=[]\n",
    "        for img_name in sorted(os.listdir(faces_dir)):\n",
    "            img = Image.open(os.path.join(faces_dir,img_name))\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                imgs.append(img_tensor)\n",
    "\n",
    "\n",
    "        if len(imgs)>0:        \n",
    "            if False:\n",
    "                features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "            else: #DDAMNet\n",
    "                features,_,_ = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "            features=features.data.cpu().numpy()\n",
    "\n",
    "            scores=get_probab(features)\n",
    "            #print(features.shape,scores.shape)\n",
    "\n",
    "            #print(videoname,filename,features.shape)\n",
    "            X_global_features.append(features)\n",
    "            X_global_scores.append(scores)\n",
    "            img_names.append(videoname+'/'+filename+'/'+img_name)\n",
    "\n",
    "    #print(videoname,len(X_global_features))\n",
    "    videoname2featuresAll[videoname]=(X_global_features,X_global_scores,img_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained on AffWild "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential, load_model,model_from_json\n",
    "from tensorflow.keras.applications import mobilenet,mobilenet_v2,densenet,inception_resnet_v2,inception_v3,vgg16,resnet_v2,resnet\n",
    "#from tensorflow.keras.applications import efficientnet as enet\n",
    "import efficientnet.tfkeras as enet\n",
    "#from tensorflow.keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,GlobalAveragePooling2D,Activation, Conv2D, Reshape,DepthwiseConv2D,Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Neutral', 1: 'Angry', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Sad', 6: 'Surprised', 7: 'Other'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_class_2={0: 'Neutral', 1:'Angry', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprised', 7:'Other'} #ABAW\n",
    "print(idx_to_class_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABAW (Expr) Pretraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../abaw5/enet_b0_8_best_vgaf_cropped.pickle 2942996\n"
     ]
    }
   ],
   "source": [
    "model_name='enet_b0_8_best_vgaf'\n",
    "#model_name='mobilevit_mtl'\n",
    "#model_name='mbf_va'\n",
    "\n",
    "#model_name='ddamfnet_8' #affectnet8_epoch4_acc0.6462\n",
    "#model_name='ddamfnet_8_mtl' #affectnet8_epoch6_acc0\n",
    "\n",
    "#model_name='enet_b0_8_va_mtl'\n",
    "#filename=model_name+'_aligned_112.pickle'\n",
    "filename=model_name+'_cropped.pickle' \n",
    "with open(filename, 'rb') as handle:\n",
    "    filename2featuresAll=pickle.load(handle)\n",
    "print(filename,len(filename2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242253, 1280) (242253,) 4994\n",
      "(91830, 1280) (91830,) 965\n"
     ]
    }
   ],
   "source": [
    "def get_image2Expr(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'../../ABAW_5/VA_AU_FER/EXPR_Classification_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        expression=int(line)-1\n",
    "                        if expression>=0 and expression<=5: #w/o neutral/ & other\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if imagename in filename2featuresAll:\n",
    "                                X.append(filename2featuresAll[imagename][0])\n",
    "                                #X.append(filename2featuresAll[imagename][1])\n",
    "                                y.append(expression)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2Expr('Train_Set')\n",
    "X_val,y_val=get_image2Expr('Validation_Set')\n",
    "TRAIN_VAL=False\n",
    "batch_size=256 #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334083, 1280) (334083,)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_train=np.concatenate((y_train,y_val))\n",
    "    print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expr(X=X_val,y=y_val):\n",
    "    y_val_preds=mlpModel.predict(X,verbose=0)\n",
    "    y_pred=np.argmax(y_val_preds,axis=1)\n",
    "    print('Acc:',(y_pred==y).mean(), 'F1:',f1_score(y_true=y,y_pred=y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22699  16067  17488 129974 103908  43947] {0: 5.725979118022821, 1: 8.089500217837806, 2: 7.432182067703569, 3: 1.0, 4: 1.2508565269276668, 5: 2.9575170091246274} 6 [0 1 2 3 4 5]\n",
      "(array([0, 1, 2, 3, 4, 5]), array([ 6126,  5296,  8408, 34511, 25157, 12332]))\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)\n",
    "print(np.unique(y_val, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-class classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpModel=Sequential()\n",
    "if False:\n",
    "    mlpModel.add(Dense(num_classes, input_shape=X_val.shape[1:],activation='softmax',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_val.shape[1:],activation='relu')) #256\n",
    "    mlpModel.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164742 (643.52 KB)\n",
      "Trainable params: 164742 (643.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "653/653 [==============================] - 5s 7ms/step - loss: 0.9591 - accuracy: 0.8532 - val_loss: 0.2639 - val_accuracy: 0.9038\n",
      "0.9038223028182983\n"
     ]
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlpModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_accuracy',True)\n",
    "mlpModel.fit(X_train,y_train, batch_size=batch_size, epochs=1 if TRAIN_VAL else 10, verbose=1, shuffle=True,\n",
    "             callbacks=[save_best_model], validation_data=(X_val,y_val),class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5852880322334749 F1: 0.455170840873927\n",
      "Best weights:\n",
      "Acc: 0.5858434062942394 F1: 0.46569501512453515\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print_expr()\n",
    "    print('Best weights:')\n",
    "    mlpModel.set_weights(best_model_weights)\n",
    "print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5858434062942394 F1: 0.46569501512453515\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    mlpModel.save_weights('abaw_expr_enet0_multiclass.h5')\n",
    "else:\n",
    "    mlpModel.load_weights('abaw_expr_enet0_multiclass.h5') #0.46569501512453515\n",
    "    print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    mlpModel.save_weights('abaw_expr_enet0_multiclass_train_val.h5')\n",
    "else:\n",
    "    mlpModel.load_weights('abaw_expr_enet0_multiclass_train_val.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242253, 6) [[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train_ohe = tf.keras.utils.to_categorical(y_train, num_classes = num_classes)\n",
    "y_val_ohe = tf.keras.utils.to_categorical(y_val, num_classes = num_classes)\n",
    "print(y_train_ohe.shape,y_train_ohe[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53671792  7.3086647 ]\n",
      " [ 0.52326531 11.24561322]\n",
      " [ 0.51947052 13.33992291]\n",
      " [ 0.82516861  1.2688319 ]\n",
      " [ 0.7408258   1.53809475]\n",
      " [ 0.57504581  3.83129843]]\n"
     ]
    }
   ],
   "source": [
    "num_labels=num_classes\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = np.empty([num_labels, 2])\n",
    "for i in range(num_labels):\n",
    "    neg, pos = np.bincount(y_train_ohe[:, i].astype('int64'))\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    class_weights[i][0]=weight_for_0\n",
    "    class_weights[i][1]=weight_for_1\n",
    "    #class_weights[i] = compute_class_weight('balanced', [0,1], y_train[:, i])\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    loss='binary_crossentropy'\n",
    "    #loss='hinge'\n",
    "else:\n",
    "    import tensorflow.keras.backend as K\n",
    "    def get_weighted_loss(weights):\n",
    "        def weighted_loss(y_true, y_pred):\n",
    "            y_true=tf.cast(y_true, tf.float32)\n",
    "            ce=K.binary_crossentropy(y_true, y_pred)\n",
    "            return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*ce, axis=-1)\n",
    "        return weighted_loss\n",
    "    loss=get_weighted_loss(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512 #256 #128\n",
    "mlpModel=Sequential()\n",
    "if False:\n",
    "    mlpModel.add(Dense(y_train_ohe.shape[1], input_shape=X_train.shape[1:],activation='sigmoid',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_val.shape[1:],activation='relu')) #256\n",
    "    mlpModel.add(Dense(y_val_ohe.shape[1],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164742 (643.52 KB)\n",
      "Trainable params: 164742 (643.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "474/474 [==============================] - 5s 9ms/step - loss: 0.1904 - auc: 0.8692 - binary_accuracy: 0.9037 - recall_6: 0.8211 - precision_6: 0.6731 - val_loss: 1.4112 - val_auc: 0.8028 - val_binary_accuracy: 0.8447 - val_recall_6: 0.6005 - val_precision_6: 0.5302\n",
      "Epoch 2/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0979 - auc: 0.9931 - binary_accuracy: 0.9589 - recall_6: 0.9648 - precision_6: 0.8204 - val_loss: 1.7648 - val_auc: 0.8017 - val_binary_accuracy: 0.8556 - val_recall_6: 0.5999 - val_precision_6: 0.5627\n",
      "Epoch 3/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0737 - auc: 0.9957 - binary_accuracy: 0.9692 - recall_6: 0.9747 - precision_6: 0.8594 - val_loss: 1.9625 - val_auc: 0.7995 - val_binary_accuracy: 0.8578 - val_recall_6: 0.5885 - val_precision_6: 0.5714\n",
      "Epoch 4/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0600 - auc: 0.9970 - binary_accuracy: 0.9751 - recall_6: 0.9794 - precision_6: 0.8838 - val_loss: 2.2132 - val_auc: 0.7959 - val_binary_accuracy: 0.8618 - val_recall_6: 0.5694 - val_precision_6: 0.5881\n",
      "Epoch 5/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0517 - auc: 0.9976 - binary_accuracy: 0.9788 - recall_6: 0.9829 - precision_6: 0.8990 - val_loss: 2.1722 - val_auc: 0.7950 - val_binary_accuracy: 0.8610 - val_recall_6: 0.5731 - val_precision_6: 0.5848\n",
      "Epoch 6/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0436 - auc: 0.9983 - binary_accuracy: 0.9820 - recall_6: 0.9857 - precision_6: 0.9131 - val_loss: 2.5080 - val_auc: 0.7851 - val_binary_accuracy: 0.8596 - val_recall_6: 0.5586 - val_precision_6: 0.5822\n",
      "Epoch 7/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0392 - auc: 0.9986 - binary_accuracy: 0.9839 - recall_6: 0.9874 - precision_6: 0.9214 - val_loss: 2.5214 - val_auc: 0.7890 - val_binary_accuracy: 0.8620 - val_recall_6: 0.5573 - val_precision_6: 0.5911\n",
      "Epoch 8/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0344 - auc: 0.9989 - binary_accuracy: 0.9859 - recall_6: 0.9893 - precision_6: 0.9305 - val_loss: 2.7970 - val_auc: 0.7839 - val_binary_accuracy: 0.8657 - val_recall_6: 0.5663 - val_precision_6: 0.6036\n",
      "Epoch 9/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0316 - auc: 0.9990 - binary_accuracy: 0.9872 - recall_6: 0.9904 - precision_6: 0.9366 - val_loss: 2.7466 - val_auc: 0.7826 - val_binary_accuracy: 0.8630 - val_recall_6: 0.5482 - val_precision_6: 0.5968\n",
      "Epoch 10/10\n",
      "474/474 [==============================] - 4s 8ms/step - loss: 0.0288 - auc: 0.9991 - binary_accuracy: 0.9883 - recall_6: 0.9912 - precision_6: 0.9416 - val_loss: 3.0126 - val_auc: 0.7796 - val_binary_accuracy: 0.8655 - val_recall_6: 0.5484 - val_precision_6: 0.6067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6c1d84eb20>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(learning_rate=1e-3), loss=loss, metrics=metrics)\n",
    "mlpModel.summary()\n",
    "\n",
    "mlpModel.fit(X_train,y_train_ohe, batch_size=batch_size, epochs=10, verbose=1, validation_data=(X_val,y_val_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5903844059675487 F1: 0.4695959401981484\n"
     ]
    }
   ],
   "source": [
    "print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5903844059675487 F1: 0.4695959401981484\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    mlpModel.save_weights('abaw_expr_enet0_multilabel.h5')\n",
    "else:\n",
    "    mlpModel.load_weights('abaw_expr_enet0_multilabel.h5') #0.4695959401981484\n",
    "    print_expr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enet_b0_8_best_vgaf\n",
    "multi-class Acc: 0.5851682456713493 F1: 0.4560254761987716\n",
    "Acc: 0.5858434062942394 F1: 0.46569501512453515\n",
    "\n",
    "multilabel Acc: 0.5894152237830774 F1: 0.46974224583460283\n",
    "\n",
    "enet_b0_8_va_mtl\n",
    "multi-class Acc: 0.487411521289339 F1: 0.4111396717716926\n",
    "Best weights:\n",
    "Acc: 0.47348361102036374 F1: 0.3982023451444861\n",
    "\n",
    "multilabel Acc: 0.49060219971686814 F1: 0.3890066877800855\n",
    "\n",
    "\n",
    "mbf_va\n",
    "multi-class Acc: 0.5362299901992813 F1: 0.3968220476090418\n",
    "multilabel Acc: 0.5545573342045084 F1: 0.42504772768905436\n",
    "\n",
    "ddamfnet_8_mtl\n",
    "multi-class Acc: 0.5549820320156812 F1: 0.3933065366566983\n",
    "multilabel Acc: 0.5486333442230208 F1: 0.4211318191092324\n",
    "\n",
    "\n",
    "ddamfnet_8\n",
    "multi-class Acc: 0.5349776761406948 F1: 0.39622075130922846\n",
    "multilabel Acc: 0.5080910377872155 F1: 0.3586924049357983\n",
    "\n",
    "mobilevit_mtl\n",
    "multi-class Acc: 0.5735162800827617 F1: 0.4346964998861715\n",
    "multilabel Acc: 0.571588805401285 F1: 0.4210486097188926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To C-EXPR (expr classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "MODEL2FEATURES='cexpr_enet_b0_8_best_vgaf.pickle'\n",
    "with open(MODEL2FEATURES, 'rb') as handle:\n",
    "    videoname2featuresAll=pickle.load(handle)\n",
    "print(len(videoname2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Angry 0\n",
      "2 Disgust 2\n",
      "3 Fear 3\n",
      "4 Happy 4\n",
      "5 Sad 6\n",
      "6 Surprised 7\n"
     ]
    }
   ],
   "source": [
    "idx_to_class_2={1:'Angry', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprised'} #ABAW\n",
    "idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprised'} #AffectNet\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n",
    "for idx,cls in idx_to_class_2.items():\n",
    "    print(idx,cls,class_to_idx[cls] if cls in class_to_idx else 'None')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5}\n"
     ]
    }
   ],
   "source": [
    "AFFWILD2AFFECTNET=np.array([0,2,3,4,6,7])\n",
    "AFFECTNET2AFFWILD={affwild:affectnet for affectnet,affwild in enumerate(AFFWILD2AFFECTNET)}\n",
    "#AFFECTNET2AFFWILD=np.array([AFFECTNET2AFFWILD[i] for i in range(len(AFFWILD2AFFECTNET))])\n",
    "print(AFFECTNET2AFFWILD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [16:54<00:00, 18.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for videoname in tqdm(videoname2featuresAll):\n",
    "    X_global_features,_,img_names=videoname2featuresAll[videoname]\n",
    "    X_global_scores=[]\n",
    "    for frame_number in range(len(img_names)):\n",
    "        features=X_global_features[frame_number]\n",
    "        scores=mlpModel.predict(features,verbose=0)\n",
    "        new_scores=np.zeros((len(scores),8))\n",
    "        new_scores[:,AFFWILD2AFFECTNET]=scores\n",
    "\n",
    "        #print(new_scores)\n",
    "        X_global_scores.append(new_scores)\n",
    "    videoname2featuresAll[videoname]=(X_global_features,X_global_scores,img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01401836 0.00000339 0.         0.8913945  0.00007616 0.09450755]] [[0.01401836 0.         0.00000339 0.         0.8913945  0.\n",
      "  0.00007616 0.09450755]]\n"
     ]
    }
   ],
   "source": [
    "new_scores=np.zeros((len(scores),8))\n",
    "for i in range(len(scores)):\n",
    "    for affwild,affectnet in enumerate(AFFWILD2AFFECTNET):\n",
    "        new_scores[i,affectnet]=scores[i,affwild]\n",
    "    \n",
    "print(scores,new_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01401836 0.00000339 0.         0.8913945  0.00007616 0.09450755]] [[0.01401836 0.         0.00000339 0.         0.8913945  0.\n",
      "  0.00007616 0.09450755]]\n"
     ]
    }
   ],
   "source": [
    "new_scores=np.zeros((len(scores),8))\n",
    "new_scores[:,AFFWILD2AFFECTNET]=scores\n",
    "print(scores,new_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To C-EXPR (all classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    MODEL2FEATURES='cexpr_enet_b0_8_best_vgaf.pickle'\n",
    "    MLP_MODEL='../ABAW5/expr_enet0_vgaf.h5'\n",
    "else:\n",
    "    MODEL2FEATURES='cexpr_enet_b0_8_va_mtl.pickle'\n",
    "    MLP_MODEL='../ABAW4/expr_enet0_mtl_va.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexpr_mbf_va.pickle\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(MODEL2FEATURES)\n",
    "with open(MODEL2FEATURES, 'rb') as handle:\n",
    "    videoname2featuresAll=pickle.load(handle)\n",
    "print(len(videoname2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpModel=Sequential()\n",
    "if False:\n",
    "    mlpModel.add(Dense(128, input_shape=(1280,),activation='relu')) #256\n",
    "    mlpModel.add(Dense(8,activation='softmax'))\n",
    "else:\n",
    "    mlpModel.add(Dense(8, input_shape=(1280,),activation='softmax'))\n",
    "mlpModel.load_weights(MLP_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 2 3 4 0 5 6]\n"
     ]
    }
   ],
   "source": [
    "AFFWILD2AFFECTNET=np.array([5,0,2,3,4,6,7,1])\n",
    "AFFECTNET2AFFWILD={affwild:affectnet for affectnet,affwild in enumerate(AFFWILD2AFFECTNET)}\n",
    "AFFECTNET2AFFWILD=np.array([AFFECTNET2AFFWILD[i] for i in range(len(AFFWILD2AFFECTNET))])\n",
    "print(AFFECTNET2AFFWILD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Neutral 5 1\n",
      "1 Angry 0 7\n",
      "2 Disgust 2 2\n",
      "3 Fear 3 3\n",
      "4 Happy 4 4\n",
      "5 Sad 6 0\n",
      "6 Surprised 7 5\n",
      "7 Other None 6\n"
     ]
    }
   ],
   "source": [
    "idx_to_class_2={0: 'Neutral', 1:'Angry', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprised', 7:'Other'} #ABAW\n",
    "idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprised'} #AffectNet\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n",
    "for idx,cls in idx_to_class_2.items():\n",
    "    print(idx,cls,class_to_idx[cls] if cls in class_to_idx else 'None',AFFWILD2AFFECTNET[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [16:35<00:00, 17.77s/it]\n"
     ]
    }
   ],
   "source": [
    "for videoname in tqdm(videoname2featuresAll):\n",
    "    X_global_features,_,img_names=videoname2featuresAll[videoname]\n",
    "    X_global_scores=[]\n",
    "    for frame_number in range(len(img_names)):\n",
    "        features=X_global_features[frame_number]\n",
    "        scores=mlpModel.predict(features,verbose=0)\n",
    "        new_scores=scores[:,AFFECTNET2AFFWILD]\n",
    "        X_global_scores.append(new_scores)\n",
    "        #print(features.shape)\n",
    "    videoname2featuresAll[videoname]=(X_global_features,X_global_scores,img_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexpr_mbf_va.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "num_classes=8\n",
    "if False:\n",
    "    #model_name='enet_b2_8_best'\n",
    "    #model_name='enet_b0_8_best_vgaf'\n",
    "    #model_name='enet_b0_8_vgaf_abaw'\n",
    "    #model_name='cexpr_enet_b0_8_mtl_abaw'\n",
    "    #model_name='ddamfnet_8'\n",
    "    \n",
    "    #model_name='abaw_expr_enet0_multilabel'\n",
    "    #model_name='abaw_expr_enet0_multiclass'\n",
    "    model_name='abaw_expr_enet0_multiclass_train_val'\n",
    "    has_va=False\n",
    "else:\n",
    "    #model_name='enet_b0_8_va_mtl'\n",
    "    #model_name='mobilevit_mtl'\n",
    "    model_name='mbf_va'\n",
    "    #model_name='ddamfnet_mtl'\n",
    "    has_va=True\n",
    "\n",
    "MODEL2FEATURES='cexpr_'+model_name+'.pickle' \n",
    "\n",
    "print(MODEL2FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(MODEL2FEATURES, 'wb') as handle:\n",
    "        pickle.dump(videoname2featuresAll, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "filename=MODEL2FEATURES\n",
    "with open(filename, 'rb') as handle:\n",
    "    videoname2featuresAll=pickle.load(handle)\n",
    "print(len(videoname2featuresAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data expoloration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores2probabs(x):\n",
    "    e_x = np.exp(x - np.max(x))#[np.newaxis])\n",
    "    e_x = e_x / e_x.sum(axis=1)[:,None]\n",
    "    return e_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information from original paper (https://openaccess.thecvf.com/content/CVPR2023/papers/Kollias_Multi-Label_Compound_Expression_Recognition_C-EXPR_Database__Network_CVPR_2023_paper.pdf)\n",
    "\n",
    "Fearfully Surprised (14445 frames): V < 0, A > 0\n",
    "Happily Surprised (24915 frames): V > 0, A > 0\n",
    "Sadly Surprised (10780 frames): V < 0, A > 0\n",
    "Disgustedly Surprised (10637 frames): V < 0, A > 0\n",
    "Angrily Surprised (10535 frames): V < 0, A > 0\n",
    "Sadly Fearful (10112 frames): V < 0, A > 0\n",
    "Sadly Angry (8878 frames): V < 0, A > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454]\n"
     ]
    }
   ],
   "source": [
    "freqs=np.array([14445, 24915, 10780, 10637, 10535, 10112, 8878])\n",
    "probabs_orig=freqs/freqs.sum()\n",
    "print(probabs_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffectNet: {0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprise'} {'Angry': 0, 'Contempt': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Sad': 6, 'Surprise': 7}\n"
     ]
    }
   ],
   "source": [
    "idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprise'}\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n",
    "print('AffectNet:',idx_to_class,class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 7]\n",
      " [4 7]\n",
      " [6 7]\n",
      " [2 7]\n",
      " [0 7]\n",
      " [6 3]\n",
      " [6 0]]\n"
     ]
    }
   ],
   "source": [
    "compound_classes=['Fear Surprise', 'Happy Surprise', 'Sad Surprise', 'Disgust Surprise', 'Angry Surprise', 'Sad Fear', 'Sad Angry']\n",
    "compound_fer_indices=np.array([[class_to_idx[c] for c in cc.split(' ')] for cc in compound_classes])\n",
    "print(compound_fer_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 644 659\n",
      "02 157 278\n",
      "03 302 302\n",
      "04 1094 1204\n",
      "05 188 188\n",
      "06 48 61\n",
      "07 128 128\n",
      "08 302 302\n",
      "09 35 87\n",
      "10 33 35\n",
      "11 215 228\n",
      "12 431 444\n",
      "13 69 69\n",
      "14 5315 5459\n",
      "15 476 786\n",
      "16 265 265\n",
      "17 61 67\n",
      "18 175 282\n",
      "19 99 255\n",
      "20 205 205\n",
      "21 312 377\n",
      "22 56 68\n",
      "23 66 66\n",
      "24 421 626\n",
      "25 266 266\n",
      "26 1989 2438\n",
      "27 56 56\n",
      "28 234 329\n",
      "29 91 91\n",
      "30 70 72\n",
      "31 770 773\n",
      "32 412 412\n",
      "33 192 192\n",
      "34 56 56\n",
      "35 196 196\n",
      "36 577 577\n",
      "37 144 154\n",
      "38 669 703\n",
      "39 384 495\n",
      "40 432 768\n",
      "41 203 319\n",
      "42 434 563\n",
      "43 63 75\n",
      "44 378 386\n",
      "45 61 61\n",
      "46 352 352\n",
      "47 38 180\n",
      "48 102 104\n",
      "49 592 597\n",
      "50 234 273\n",
      "51 482 482\n",
      "52 75 76\n",
      "53 334 442\n",
      "54 344 478\n",
      "55 1097 1465\n",
      "56 217 266\n",
      "22641 26138\n"
     ]
    }
   ],
   "source": [
    "total_frames=total_facial_frames=0\n",
    "for videoname in sorted(videoname2featuresAll):\n",
    "    frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "    total_frames+=frames_count\n",
    "    facial_frames_count=len(videoname2featuresAll[videoname][0])\n",
    "    total_facial_frames+=facial_frames_count\n",
    "    print(videoname, facial_frames_count,frames_count)\n",
    "\n",
    "print(total_facial_frames,total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import gmean,hmean\n",
    "ARITHMETIC_MEAN,GEOMETRIC_MEAN,HARMONIC_MEAN=0,1,2\n",
    "mean_functions=[np.mean,gmean,hmean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videoname2compound_scores(videoname2featuresAll, mean_function=ARITHMETIC_MEAN):\n",
    "    videoname2compound_scores={}\n",
    "    for videoname in sorted(videoname2featuresAll):\n",
    "        X_global_features,X_global_scores,img_names=videoname2featuresAll[videoname]\n",
    "        compound_scores={}\n",
    "        for img_name,scores in zip(img_names,X_global_scores):\n",
    "            frame_number=int(img_name.split('/')[1])\n",
    "\n",
    "            if False:\n",
    "                if has_va:\n",
    "                    fer_scores=scores[:,:-2]\n",
    "                    valences=scores[:,-2]\n",
    "                    arousals=scores[:,-1]\n",
    "                else:\n",
    "                    fer_scores=scores\n",
    "                    valences,arousals=None,None\n",
    "            else:\n",
    "                fer_scores=scores[:,:num_classes]\n",
    "            fer_probabs=scores2probabs(fer_scores)\n",
    "            compound_probabs=np.array([[[probabs[c] for c in cc] for cc in compound_fer_indices] for probabs in fer_probabs])\n",
    "            max_faces_scores=mean_functions[mean_function](compound_probabs,axis=2).max(axis=0)\n",
    "            compound_scores[frame_number]=max_faces_scores\n",
    "        videoname2compound_scores[videoname]=compound_scores\n",
    "    return videoname2compound_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compound_scores(videoname,videoname2compound_scores):\n",
    "    frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "    all_compound_scores=np.zeros((frames_count,len(compound_classes)))\n",
    "    compound_scores=videoname2compound_scores[videoname]\n",
    "    frame_numbers=sorted(compound_scores.keys())\n",
    "    cur_ind=0\n",
    "    for i in range(1,frames_count+1):\n",
    "        if cur_ind>=len(frame_numbers):\n",
    "            all_compound_scores[i-1]=compound_scores[cur_frame_number]\n",
    "            continue\n",
    "        cur_frame_number=frame_numbers[cur_ind]\n",
    "        if i==cur_frame_number:\n",
    "            all_compound_scores[i-1]=compound_scores[cur_frame_number]\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                all_compound_scores[i-1]=compound_scores[cur_frame_number]\n",
    "            else:\n",
    "                w=1-(i-frame_numbers[cur_ind-1])/(cur_frame_number-frame_numbers[cur_ind-1])\n",
    "                avg_scores=w*compound_scores[frame_numbers[cur_ind-1]]+(1-w)*compound_scores[cur_frame_number]\n",
    "                all_compound_scores[i-1]=avg_scores\n",
    "    return all_compound_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454]\n",
      "enet_b0_8_best_vgaf <function mean at 0x7f71f00d74c0> [0.17706022 0.23942153 0.0988599  0.06098401 0.04131915 0.2137501\n",
      " 0.1686051 ] KL: 0.11862078496424168\n",
      "enet_b0_8_best_vgaf <function gmean at 0x7f71185c4040> [0.19676333 0.17805494 0.11320683 0.03079807 0.04522152 0.22381207\n",
      " 0.21214324] KL: 0.20948032904417707\n",
      "enet_b0_8_best_vgaf <function hmean at 0x7f71185c4310> [0.20418548 0.15483205 0.11481368 0.0221134  0.04541281 0.22530415\n",
      " 0.23333843] KL: 0.26885570257042635\n",
      "\n",
      "mbf_va <function mean at 0x7f71f00d74c0> [0.13019359 0.32860204 0.05872676 0.12273319 0.06645497 0.15268957\n",
      " 0.14059989] KL: 0.060323047351097385\n",
      "mbf_va <function gmean at 0x7f71185c4040> [0.1392991  0.30071161 0.07521616 0.0462545  0.0747188  0.17365521\n",
      " 0.19014462] KL: 0.10162860767594191\n",
      "mbf_va <function hmean at 0x7f71185c4310> [0.14331624 0.28406917 0.07590481 0.03776111 0.07647869 0.17648634\n",
      " 0.20598363] KL: 0.12320593291510143\n",
      "\n",
      "enet_b0_8_mtl_abaw <function mean at 0x7f71f00d74c0> [0.08194965 0.46197108 0.02727829 0.0512281  0.12223583 0.12690336\n",
      " 0.1284337 ] KL: 0.1933555393166923\n",
      "enet_b0_8_mtl_abaw <function gmean at 0x7f71185c4040> [0.08221746 0.45990512 0.02785217 0.05046293 0.12185324 0.12789808\n",
      " 0.129811  ] KL: 0.1918002842044568\n",
      "enet_b0_8_mtl_abaw <function hmean at 0x7f71185c4310> [0.08344173 0.45661489 0.02854082 0.04939169 0.12131762 0.12942842\n",
      " 0.13126483] KL: 0.18911566479901326\n",
      "\n",
      "abaw_expr_enet0_multilabel <function mean at 0x7f71f00d74c0> [0.01729283 0.67002066 0.09296809 0.04066876 0.01932053 0.11010789\n",
      " 0.04962124] KL: 0.5450719728228879\n",
      "abaw_expr_enet0_multilabel <function gmean at 0x7f71185c4040> [0.01744586 0.662522   0.09392455 0.03998011 0.01947356 0.11840998\n",
      " 0.04824394] KL: 0.5412646351669035\n",
      "abaw_expr_enet0_multilabel <function hmean at 0x7f71185c4310> [0.01813452 0.65158007 0.09132298 0.04353814 0.02176907 0.12307751\n",
      " 0.0505777 ] KL: 0.5110033431099567\n",
      "\n",
      "abaw_expr_enet0_multiclass <function mean at 0x7f71f00d74c0> [0.0144617  0.56683755 0.11114087 0.03286403 0.05700513 0.1239192\n",
      " 0.09377152] KL: 0.4215674095706967\n",
      "abaw_expr_enet0_multiclass <function gmean at 0x7f71185c4040> [0.01323743 0.56607239 0.11102609 0.03248144 0.05398271 0.12709465\n",
      " 0.09610529] KL: 0.43869772503738436\n",
      "abaw_expr_enet0_multiclass <function hmean at 0x7f71185c4310> [0.01373479 0.54250516 0.11186778 0.03313184 0.05937715 0.13708011\n",
      " 0.10230316] KL: 0.41556810223074275\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val <function mean at 0x7f71f00d74c0> [0.03795241 0.42283266 0.14962889 0.05298799 0.03986533 0.18566838\n",
      " 0.11106435] KL: 0.23613772570912675\n",
      "abaw_expr_enet0_multiclass_train_val <function gmean at 0x7f71185c4040> [0.03695769 0.43121126 0.14924631 0.05210804 0.0406305  0.18387023\n",
      " 0.10597597] KL: 0.2407331200807978\n",
      "abaw_expr_enet0_multiclass_train_val <function hmean at 0x7f71185c4310> [0.03856454 0.40259392 0.15490856 0.06255261 0.04537455 0.1855536\n",
      " 0.11045222] KL: 0.20893547816316363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta=0\n",
    "print('freqs from paper:',freqs/freqs.sum())\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    for mean_function in [ARITHMETIC_MEAN,GEOMETRIC_MEAN,HARMONIC_MEAN]:\n",
    "        videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll,mean_function)\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            for i in range(len(compound_scores)):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(model_name,mean_functions[mean_function],compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf 0 [0.16562094 0.22040707 0.10873058 0.06515418 0.04189303 0.21482133\n",
      " 0.18337287] KL: 0.12255947279994284\n",
      "enet_b0_8_best_vgaf 1 [0.16688346 0.19944143 0.10819497 0.03359094 0.04189303 0.21998623\n",
      " 0.23000995] KL: 0.20261237746264424\n",
      "enet_b0_8_best_vgaf 2 [0.16822251 0.17794016 0.10853929 0.02383503 0.04177825 0.2241564\n",
      " 0.25552835] KL: 0.26071677514908587\n",
      "\n",
      "mbf_va 0 [0.11971077 0.30970235 0.06867396 0.12093504 0.07299717 0.16145076\n",
      " 0.14652996] KL: 0.05189005225243018\n",
      "mbf_va 1 [0.12005509 0.30185936 0.06878874 0.05780855 0.07165812 0.17258398\n",
      " 0.20724616] KL: 0.10586313783332726\n",
      "mbf_va 2 [0.12051419 0.28058765 0.06901829 0.04273472 0.07146683 0.17859056\n",
      " 0.23708776] KL: 0.14386049877738005\n",
      "\n",
      "enet_b0_8_mtl_abaw 0 [0.08558421 0.44341572 0.03087459 0.05157242 0.13199174 0.12254189\n",
      " 0.13401944] KL: 0.17292399535289993\n",
      "enet_b0_8_mtl_abaw 1 [0.08546943 0.44219145 0.03091285 0.05088377 0.1318387  0.12273319\n",
      " 0.13597062] KL: 0.17387680590276355\n",
      "enet_b0_8_mtl_abaw 2 [0.08543117 0.44108195 0.03095111 0.04992731 0.13176219 0.12311577\n",
      " 0.13773051] KL: 0.17518403044738276\n",
      "\n",
      "abaw_expr_enet0_multilabel 0 [0.01886143 0.66669217 0.08684674 0.04759354 0.02310812 0.10746805\n",
      " 0.04942995] KL: 0.5043787955491499\n",
      "abaw_expr_enet0_multilabel 1 [0.01878491 0.66653914 0.08665544 0.0476318  0.02310812 0.10758283\n",
      " 0.04969776] KL: 0.504610220874063\n",
      "abaw_expr_enet0_multilabel 2 [0.01878491 0.66596526 0.08646415 0.04774658 0.02314638 0.10781238\n",
      " 0.05008034] KL: 0.5036425721380831\n",
      "\n",
      "abaw_expr_enet0_multiclass 0 [0.01541817 0.56278216 0.10107889 0.03699594 0.06301171 0.12629122\n",
      " 0.09442191] KL: 0.39619224423093585\n",
      "abaw_expr_enet0_multiclass 1 [0.01499732 0.56151963 0.10119366 0.03688117 0.06289693 0.12705639\n",
      " 0.09545489] KL: 0.3999359332327305\n",
      "abaw_expr_enet0_multiclass 2 [0.01457648 0.55995103 0.10119366 0.03668988 0.06270564 0.12816589\n",
      " 0.09671742] KL: 0.4039631889119719\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0 [0.03309358 0.40932742 0.15640064 0.06947739 0.05195501 0.17002066\n",
      " 0.1097253 ] KL: 0.2099599573714777\n",
      "abaw_expr_enet0_multiclass_train_val 1 [0.03324661 0.40875354 0.15594154 0.06924784 0.05199327 0.17032673\n",
      " 0.11049047] KL: 0.20937931302732352\n",
      "abaw_expr_enet0_multiclass_train_val 2 [0.03294055 0.40806489 0.1555207  0.06898003 0.05191675 0.17097712\n",
      " 0.11159997] KL: 0.2108657524111189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_videoname2compound_scores_first(videoname2featuresAll, mean_function=ARITHMETIC_MEAN):\n",
    "    videoname2compound_scores={}\n",
    "    for videoname in sorted(videoname2featuresAll):\n",
    "        X_global_features,X_global_scores,img_names=videoname2featuresAll[videoname]\n",
    "        compound_scores={}\n",
    "        for img_name,scores in zip(img_names,X_global_scores):\n",
    "            frame_number=int(img_name.split('/')[1])\n",
    "            fer_scores=scores[:1,:num_classes] #first faces only\n",
    "            fer_probabs=scores2probabs(fer_scores)\n",
    "            compound_probabs=np.array([[[probabs[c] for c in cc] for cc in compound_fer_indices] for probabs in fer_probabs])\n",
    "            max_faces_scores=mean_functions[mean_function](compound_probabs,axis=2).max(axis=0)\n",
    "            compound_scores[frame_number]=max_faces_scores\n",
    "        videoname2compound_scores[videoname]=compound_scores\n",
    "    return videoname2compound_scores\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "\n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    for mean_function in [ARITHMETIC_MEAN,GEOMETRIC_MEAN,HARMONIC_MEAN]:\n",
    "        videoname2compound_scores=get_videoname2compound_scores_first(videoname2featuresAll,mean_function)\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            for i in range(len(compound_scores)):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(model_name,mean_function,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454] \n",
      "\n",
      "enet_b0_8_best_vgaf 0 [0.17706022 0.23942153 0.0988599  0.06098401 0.04131915 0.2137501\n",
      " 0.1686051 ] KL: 0.11862078496424168\n",
      "enet_b0_8_best_vgaf 1 [0.17797842 0.24007193 0.09985462 0.05834417 0.04020966 0.21463004\n",
      " 0.16891116] KL: 0.12359948162867672\n",
      "enet_b0_8_best_vgaf 5 [0.17331089 0.24527508 0.10104063 0.0557426  0.0372255  0.22140179\n",
      " 0.16600352] KL: 0.1331232255080153\n",
      "enet_b0_8_best_vgaf 10 [0.16871987 0.24975132 0.10215013 0.05643125 0.0336292  0.22576326\n",
      " 0.16355498] KL: 0.140807320398386\n",
      "enet_b0_8_best_vgaf 50 [0.14836636 0.27404545 0.11022266 0.05222282 0.021463   0.2397276\n",
      " 0.1539521 ] KL: 0.18742691743015727\n",
      "enet_b0_8_best_vgaf 100 [0.1309205  0.29217997 0.10823322 0.05115158 0.01423215 0.24401255\n",
      " 0.15927003] KL: 0.23698030893590658\n",
      "\n",
      "mbf_va 0 [0.13019359 0.32860204 0.05872676 0.12273319 0.06645497 0.15268957\n",
      " 0.14059989] KL: 0.060323047351097385\n",
      "mbf_va 1 [0.12755375 0.33292524 0.05918586 0.12254189 0.06492463 0.15280435\n",
      " 0.14006427] KL: 0.0622567732609975\n",
      "mbf_va 5 [0.12476088 0.34115081 0.05918586 0.11906037 0.06136659 0.15724233\n",
      " 0.13723315] KL: 0.06783627097210918\n",
      "mbf_va 10 [0.12020813 0.34784605 0.05895631 0.11324508 0.05723468 0.1638993\n",
      " 0.13861045] KL: 0.0772902294323603\n",
      "mbf_va 50 [0.09790344 0.37466524 0.06565154 0.10058153 0.05138113 0.17468819\n",
      " 0.13512893] KL: 0.09870594734119009\n",
      "mbf_va 100 [0.08325044 0.39559262 0.06832964 0.10716199 0.05448007 0.17480297\n",
      " 0.11638228] KL: 0.10518377961815074\n",
      "\n",
      "enet_b0_8_mtl_abaw 0 [0.08194965 0.46197108 0.02727829 0.0512281  0.12223583 0.12690336\n",
      " 0.1284337 ] KL: 0.1933555393166923\n",
      "enet_b0_8_mtl_abaw 1 [0.07965414 0.46705945 0.02689571 0.04969776 0.1198638  0.12663555\n",
      " 0.13019359] KL: 0.2013212130527674\n",
      "enet_b0_8_mtl_abaw 5 [0.08156707 0.47436682 0.0259775  0.04721096 0.11374244 0.12495218\n",
      " 0.13218303] KL: 0.20955826782031084\n",
      "enet_b0_8_mtl_abaw 10 [0.08198791 0.47979953 0.02528885 0.04575714 0.11228862 0.12372791\n",
      " 0.13115005] KL: 0.21585958120028786\n",
      "enet_b0_8_mtl_abaw 50 [0.08435994 0.49774275 0.02234295 0.04793787 0.10452215 0.12323055\n",
      " 0.1198638 ] KL: 0.22812802219066555\n",
      "enet_b0_8_mtl_abaw 100 [0.07839161 0.48898156 0.02065958 0.05245237 0.10570816 0.14090596\n",
      " 0.11290076] KL: 0.2330729908227114\n",
      "\n",
      "abaw_expr_enet0_multilabel 0 [0.01729283 0.67002066 0.09296809 0.04066876 0.01932053 0.11010789\n",
      " 0.04962124] KL: 0.5450719728228879\n",
      "abaw_expr_enet0_multilabel 1 [0.0151121  0.67430561 0.09208815 0.04112786 0.01702502 0.11278598\n",
      " 0.04755528] KL: 0.5809346164632374\n",
      "abaw_expr_enet0_multilabel 5 [0.01369653 0.68302854 0.08971612 0.04070702 0.01411738 0.1144311\n",
      " 0.04430331] KL: 0.6246388977848297\n",
      "abaw_expr_enet0_multilabel 10 [0.01201316 0.68750478 0.08925702 0.03994185 0.01189839 0.11906037\n",
      " 0.04032443] KL: 0.6714226104545613\n",
      "abaw_expr_enet0_multilabel 50 [0.00799602 0.71413268 0.07793251 0.04074528 0.0119749  0.12074374\n",
      " 0.02647486] KL: 0.7789503665029482\n",
      "abaw_expr_enet0_multilabel 100 [0.00822557 0.73712602 0.06469508 0.03871758 0.00906726 0.12460785\n",
      " 0.01756064] KL: 0.8631986644899444\n",
      "\n",
      "abaw_expr_enet0_multiclass 0 [0.0144617  0.56683755 0.11114087 0.03286403 0.05700513 0.1239192\n",
      " 0.09377152] KL: 0.4215674095706967\n",
      "abaw_expr_enet0_multiclass 1 [0.01419389 0.56760272 0.10941924 0.03179279 0.05402097 0.12560257\n",
      " 0.09736782] KL: 0.43101447861386694\n",
      "abaw_expr_enet0_multiclass 5 [0.01323743 0.5690948  0.10643508 0.03156324 0.0510368  0.12965797\n",
      " 0.09897467] KL: 0.44706605605802363\n",
      "abaw_expr_enet0_multiclass 10 [0.01124799 0.57303543 0.10551687 0.03213712 0.04855    0.13202999\n",
      " 0.09748259] KL: 0.47541647283591487\n",
      "abaw_expr_enet0_multiclass 50 [0.01052108 0.58416864 0.11247991 0.02574795 0.04372944 0.12916061\n",
      " 0.09419236] KL: 0.5173113814171874\n",
      "abaw_expr_enet0_multiclass 100 [0.00803428 0.59476624 0.11871605 0.02127171 0.04177825 0.13225955\n",
      " 0.08317392] KL: 0.5864425161970617\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0 [0.03795241 0.42283266 0.14962889 0.05298799 0.03986533 0.18566838\n",
      " 0.11106435] KL: 0.23613772570912675\n",
      "abaw_expr_enet0_multiclass_train_val 1 [0.03695769 0.42608463 0.14886372 0.05187849 0.03668988 0.18700742\n",
      " 0.11251817] KL: 0.24897758424999009\n",
      "abaw_expr_enet0_multiclass_train_val 5 [0.03355268 0.4282271  0.15364603 0.050769   0.03339965 0.1864718\n",
      " 0.11393374] KL: 0.27188031138288693\n",
      "abaw_expr_enet0_multiclass_train_val 10 [0.03056852 0.42964267 0.15536766 0.04950647 0.03033897 0.18872905\n",
      " 0.11584666] KL: 0.2957343476105086\n",
      "abaw_expr_enet0_multiclass_train_val 50 [0.02020047 0.44200015 0.16615655 0.04694315 0.02559492 0.19029765\n",
      " 0.1088071 ] KL: 0.3774998485066427\n",
      "abaw_expr_enet0_multiclass_train_val 100 [0.01113322 0.44969011 0.17269875 0.04751703 0.02153952 0.18375545\n",
      " 0.11366593] KL: 0.48174866450997317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('probabs from paper:',probabs_orig,'\\n')\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "    for delta in [0,1,5,10, 50, 100]:\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            for i in range(len(compound_scores)):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(model_name,delta, compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454] \n",
      "\n",
      "enet_b0_8_best_vgaf 0 [0.16562094 0.22040707 0.10873058 0.06515418 0.04189303 0.21482133\n",
      " 0.18337287] KL: 0.12255947279994284\n",
      "enet_b0_8_best_vgaf 1 [0.16619481 0.22117224 0.11098783 0.06213176 0.04174    0.21596909\n",
      " 0.18180427] KL: 0.12486703678019509\n",
      "enet_b0_8_best_vgaf 5 [0.16271329 0.22614584 0.11247991 0.06014232 0.03833499 0.22235825\n",
      " 0.17782539] KL: 0.13319570521009422\n",
      "enet_b0_8_best_vgaf 10 [0.16026475 0.2311577  0.11205907 0.06098401 0.03435611 0.22828832\n",
      " 0.17289005] KL: 0.14098801226441693\n",
      "enet_b0_8_best_vgaf 50 [0.13539674 0.26061673 0.11955773 0.05203152 0.02440891 0.24519856\n",
      " 0.16278981] KL: 0.18362973670424235\n",
      "enet_b0_8_best_vgaf 100 [0.12059071 0.2814676  0.12020813 0.05126636 0.01434693 0.25407453\n",
      " 0.15804576] KL: 0.24293892263347636\n",
      "\n",
      "mbf_va 0 [0.11971077 0.30970235 0.06867396 0.12093504 0.07299717 0.16145076\n",
      " 0.14652996] KL: 0.05189005225243018\n",
      "mbf_va 1 [0.11810391 0.31421685 0.06894177 0.11963425 0.07204071 0.16183335\n",
      " 0.14522917] KL: 0.05301847794935083\n",
      "mbf_va 5 [0.11542582 0.32056776 0.06878874 0.11504323 0.06787053 0.16818425\n",
      " 0.14411967] KL: 0.059441342406216104\n",
      "mbf_va 10 [0.11171474 0.32603872 0.06955391 0.10896013 0.06270564 0.17591246\n",
      " 0.14511439] KL: 0.06860542685574944\n",
      "mbf_va 50 [0.0898309  0.35293442 0.07896549 0.09671742 0.05520698 0.18899686\n",
      " 0.13734792] KL: 0.0927325701917856\n",
      "mbf_va 100 [0.07594307 0.37455046 0.07636391 0.09702349 0.05314102 0.1936644\n",
      " 0.12931364] KL: 0.11446726716058497\n",
      "\n",
      "enet_b0_8_mtl_abaw 0 [0.08558421 0.44341572 0.03087459 0.05157242 0.13199174 0.12254189\n",
      " 0.13401944] KL: 0.17292399535289993\n",
      "enet_b0_8_mtl_abaw 1 [0.08409213 0.44903971 0.03053026 0.04992731 0.12973449 0.12192976\n",
      " 0.13474635] KL: 0.1794588970001186\n",
      "enet_b0_8_mtl_abaw 5 [0.086885   0.45470197 0.02972683 0.04755528 0.12491392 0.11967251\n",
      " 0.13654449] KL: 0.18489904347451083\n",
      "enet_b0_8_mtl_abaw 10 [0.08753539 0.45875736 0.02877037 0.04621624 0.1223506  0.11982554\n",
      " 0.13654449] KL: 0.1908005394564225\n",
      "enet_b0_8_mtl_abaw 50 [0.08887444 0.48335756 0.02207514 0.04789961 0.11335986 0.12062897\n",
      " 0.12380442] KL: 0.21915362721967874\n",
      "enet_b0_8_mtl_abaw 100 [0.08271482 0.47654756 0.0210039  0.05241411 0.11313031 0.13665927\n",
      " 0.11753003] KL: 0.22126466371955558\n",
      "\n",
      "abaw_expr_enet0_multilabel 0 [0.01886143 0.66669217 0.08684674 0.04759354 0.02310812 0.10746805\n",
      " 0.04942995] KL: 0.5043787955491499\n",
      "abaw_expr_enet0_multilabel 1 [0.01660418 0.67170403 0.0866937  0.04721096 0.02058306 0.10930446\n",
      " 0.04789961] KL: 0.5385577635611205\n",
      "abaw_expr_enet0_multilabel 5 [0.01526513 0.68191905 0.08501033 0.04613972 0.01622159 0.10968705\n",
      " 0.04575714] KL: 0.5847762638995128\n",
      "abaw_expr_enet0_multilabel 10 [0.01319917 0.68773433 0.08462775 0.04483893 0.01293136 0.11412503\n",
      " 0.04254342] KL: 0.6387660903379659\n",
      "abaw_expr_enet0_multilabel 50 [0.00822557 0.71405616 0.07280588 0.04319382 0.01633637 0.11687964\n",
      " 0.02850256] KL: 0.735854598140623\n",
      "abaw_expr_enet0_multilabel 100 [0.00822557 0.74466294 0.05945367 0.03871758 0.01132451 0.11798913\n",
      " 0.0196266 ] KL: 0.8397201372872182\n",
      "\n",
      "abaw_expr_enet0_multiclass 0 [0.01541817 0.56278216 0.10107889 0.03699594 0.06301171 0.12629122\n",
      " 0.09442191] KL: 0.39619224423093585\n",
      "abaw_expr_enet0_multiclass 1 [0.01515036 0.56450379 0.10111715 0.03554212 0.06044839 0.12728594\n",
      " 0.09595225] KL: 0.40521549943338553\n",
      "abaw_expr_enet0_multiclass 5 [0.01476777 0.56802357 0.09824776 0.03427959 0.05792333 0.13042314\n",
      " 0.09633484] KL: 0.41714911532123367\n",
      "abaw_expr_enet0_multiclass 10 [0.01254878 0.57383886 0.09759737 0.03458566 0.05612518 0.13191522\n",
      " 0.09338894] KL: 0.4455890900723122\n",
      "abaw_expr_enet0_multiclass 50 [0.0104063  0.58707629 0.09828602 0.03121891 0.04694315 0.13202999\n",
      " 0.09403933] KL: 0.5005301395070707\n",
      "abaw_expr_enet0_multiclass 100 [0.00803428 0.59817124 0.09805647 0.02345244 0.04992731 0.13371337\n",
      " 0.08864488] KL: 0.5679191545947165\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0 [0.03309358 0.40932742 0.15640064 0.06947739 0.05195501 0.17002066\n",
      " 0.1097253 ] KL: 0.2099599573714777\n",
      "abaw_expr_enet0_multiclass_train_val 1 [0.03236667 0.41280894 0.15773969 0.06649323 0.04889433 0.1706328\n",
      " 0.11106435] KL: 0.2208180182468055\n",
      "abaw_expr_enet0_multiclass_train_val 5 [0.02965032 0.41464534 0.16497054 0.06465682 0.04395899 0.16791644\n",
      " 0.11420155] KL: 0.24303553462965136\n",
      "abaw_expr_enet0_multiclass_train_val 10 [0.02712526 0.4162522  0.16967633 0.06262912 0.04158696 0.16829903\n",
      " 0.1144311 ] KL: 0.2626211620149233\n",
      "abaw_expr_enet0_multiclass_train_val 50 [0.01870839 0.43247379 0.18934119 0.0530645  0.03542735 0.16695998\n",
      " 0.10402479] KL: 0.34689843249525404\n",
      "abaw_expr_enet0_multiclass_train_val 100 [0.01553294 0.43909251 0.19538603 0.04824394 0.0345474  0.1600352\n",
      " 0.10716199] KL: 0.38468596474020694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('probabs from paper:',probabs_orig,'\\n')\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores_first(videoname2featuresAll)\n",
    "    for delta in [0,1,5,10, 50, 100]:\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            for i in range(len(compound_scores)):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(model_name,delta, compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf 0.1 1 [0.17709848 0.23965108 0.09882164 0.06102227 0.04112786 0.21363532\n",
      " 0.16864335] KL: 0.11887335552660516\n",
      "enet_b0_8_best_vgaf 0.1 5 [0.18448236 0.23846507 0.09752085 0.06102227 0.04074528 0.21000077\n",
      " 0.16776341] KL: 0.11881596338438918\n",
      "enet_b0_8_best_vgaf 0.1 10 [0.19228709 0.23701125 0.09625832 0.06102227 0.04043921 0.20640447\n",
      " 0.1665774 ] KL: 0.118942050098508\n",
      "enet_b0_8_best_vgaf 0.1 50 [0.19228709 0.23701125 0.09625832 0.06102227 0.04043921 0.20640447\n",
      " 0.1665774 ] KL: 0.118942050098508\n",
      "enet_b0_8_best_vgaf 0.1 100 [0.19228709 0.23701125 0.09625832 0.06102227 0.04043921 0.20640447\n",
      " 0.1665774 ] KL: 0.118942050098508\n",
      "enet_b0_8_best_vgaf 1 1 [0.17771061 0.24030148 0.09962507 0.05930064 0.04032443 0.21474482\n",
      " 0.16799296] KL: 0.12207953133166059\n",
      "enet_b0_8_best_vgaf 1 5 [0.17748106 0.24079884 0.10008417 0.05922412 0.04020966 0.21413268\n",
      " 0.16806948] KL: 0.1219264761681508\n",
      "enet_b0_8_best_vgaf 1 10 [0.17782539 0.24091361 0.10065805 0.05922412 0.0401714  0.21336751\n",
      " 0.16783993] KL: 0.1214486959834009\n",
      "enet_b0_8_best_vgaf 1 50 [0.19634249 0.23754687 0.09966333 0.05922412 0.03925319 0.20311424\n",
      " 0.16485577] KL: 0.1206475625851328\n",
      "enet_b0_8_best_vgaf 1 100 [0.19634249 0.23754687 0.09966333 0.05922412 0.03925319 0.20311424\n",
      " 0.16485577] KL: 0.1206475625851328\n",
      "enet_b0_8_best_vgaf 10 1 [0.17790191 0.24026322 0.09985462 0.05845895 0.03998011 0.21470656\n",
      " 0.16883465] KL: 0.12388956988005993\n",
      "enet_b0_8_best_vgaf 10 5 [0.17510904 0.24297957 0.10123192 0.05677558 0.03894713 0.21746117\n",
      " 0.1674956 ] KL: 0.12753457536085633\n",
      "enet_b0_8_best_vgaf 10 10 [0.17487949 0.2431326  0.10161451 0.05669906 0.03864106 0.2171551\n",
      " 0.16787819] KL: 0.1281330797705786\n",
      "enet_b0_8_best_vgaf 10 50 [0.18421455 0.24076058 0.10192058 0.05669906 0.03783763 0.21183717\n",
      " 0.16673043] KL: 0.12806245993651375\n",
      "enet_b0_8_best_vgaf 10 100 [0.19190451 0.23938327 0.10054327 0.05669906 0.03783763 0.2090443\n",
      " 0.16458796] KL: 0.12748527320786204\n",
      "enet_b0_8_best_vgaf 50 1 [0.17790191 0.24041625 0.10004591 0.05845895 0.03994185 0.21432397\n",
      " 0.16891116] KL: 0.12375227674532314\n",
      "enet_b0_8_best_vgaf 50 5 [0.17250746 0.24619328 0.10123192 0.05585737 0.03783763 0.21899151\n",
      " 0.16738082] KL: 0.1308780606744543\n",
      "enet_b0_8_best_vgaf 50 10 [0.16818425 0.25021042 0.10264749 0.05578086 0.03558038 0.22029229\n",
      " 0.16730431] KL: 0.13553382332920225\n",
      "enet_b0_8_best_vgaf 50 50 [0.16803122 0.24971306 0.10375698 0.05566608 0.0345474  0.21891499\n",
      " 0.16937027] KL: 0.13812052494409874\n",
      "enet_b0_8_best_vgaf 50 100 [0.17235443 0.24860357 0.10264749 0.05566608 0.03458566 0.21719336\n",
      " 0.16894942] KL: 0.1375685604621601\n",
      "enet_b0_8_best_vgaf 100 1 [0.17790191 0.24049277 0.09996939 0.05845895 0.03990359 0.21436223\n",
      " 0.16891116] KL: 0.12384762810971624\n",
      "enet_b0_8_best_vgaf 100 5 [0.17212488 0.24649935 0.10100237 0.05578086 0.03760808 0.21952713\n",
      " 0.16745734] KL: 0.13171434076709215\n",
      "enet_b0_8_best_vgaf 100 10 [0.16726605 0.25063126 0.10314485 0.05570434 0.03496825 0.22178438\n",
      " 0.16650088] KL: 0.13727248129257058\n",
      "enet_b0_8_best_vgaf 100 50 [0.16386105 0.25074604 0.10635856 0.05589563 0.03156324 0.22071314\n",
      " 0.17086235] KL: 0.14632149201915173\n",
      "enet_b0_8_best_vgaf 100 100 [0.16382279 0.25074604 0.10635856 0.05589563 0.03156324 0.21922106\n",
      " 0.17239268] KL: 0.14624178874677168\n",
      "enet_b0_8_best_vgaf 500 1 [0.17794016 0.24056929 0.09989288 0.05845895 0.03986533 0.21432397\n",
      " 0.16894942] KL: 0.12392649674826169\n",
      "enet_b0_8_best_vgaf 500 5 [0.17185707 0.2467289  0.10077282 0.05578086 0.03745505 0.22021578\n",
      " 0.16718953] KL: 0.1322605484612288\n",
      "enet_b0_8_best_vgaf 500 10 [0.16550616 0.25093733 0.10387176 0.05643125 0.03374397 0.22239651\n",
      " 0.16711302] KL: 0.13975046851817632\n",
      "enet_b0_8_best_vgaf 500 50 [0.14568827 0.26696763 0.10781238 0.0555513  0.02857908 0.22748489\n",
      " 0.16791644] KL: 0.1568491978573876\n",
      "enet_b0_8_best_vgaf 500 100 [0.14392838 0.26708241 0.10739154 0.05547479 0.02861734 0.22840309\n",
      " 0.16910246] KL: 0.1580048439756772\n",
      "enet_b0_8_best_vgaf 1000 1 [0.17794016 0.24053103 0.09985462 0.05849721 0.03990359 0.21432397\n",
      " 0.16894942] KL: 0.1238271354337346\n",
      "enet_b0_8_best_vgaf 1000 5 [0.17174229 0.24680542 0.10081108 0.0557426  0.03741679 0.22025404\n",
      " 0.16722779] KL: 0.13239464912424315\n",
      "enet_b0_8_best_vgaf 1000 10 [0.16573571 0.25135818 0.10341266 0.05635473 0.03351442 0.22297039\n",
      " 0.16665391] KL: 0.14053328699470558\n",
      "enet_b0_8_best_vgaf 1000 50 [0.14006427 0.27458107 0.10823322 0.05490091 0.02643661 0.2302395\n",
      " 0.16554442] KL: 0.16545249167580472\n",
      "enet_b0_8_best_vgaf 1000 100 [0.13620017 0.27614967 0.10800367 0.05478614 0.02624531 0.23299411\n",
      " 0.16562094] KL: 0.1683258887625966\n",
      "enet_b0_8_best_vgaf 10000 1 [0.17794016 0.24053103 0.09985462 0.05849721 0.03990359 0.21432397\n",
      " 0.16894942] KL: 0.1238271354337346\n",
      "enet_b0_8_best_vgaf 10000 5 [0.17181881 0.2467289  0.10077282 0.0557426  0.03730201 0.22033055\n",
      " 0.16730431] KL: 0.1327288070376668\n",
      "enet_b0_8_best_vgaf 10000 10 [0.16554442 0.25131992 0.10303007 0.05646951 0.03374397 0.22327646\n",
      " 0.16661566] KL: 0.140035446228241\n",
      "enet_b0_8_best_vgaf 10000 50 [0.13688882 0.28295968 0.11171474 0.05210804 0.02138649 0.23242023\n",
      " 0.162522  ] KL: 0.18868578532940902\n",
      "enet_b0_8_best_vgaf 10000 100 [0.12770679 0.29393986 0.10609075 0.05195501 0.01625985 0.2361313\n",
      " 0.16791644] KL: 0.22278995831957082\n",
      "enet_b0_8_best_vgaf 100000 1 [0.17794016 0.24053103 0.09985462 0.05845895 0.03990359 0.21432397\n",
      " 0.16898768] KL: 0.1238819395511926\n",
      "enet_b0_8_best_vgaf 100000 5 [0.17185707 0.2467289  0.10077282 0.0557426  0.03726375 0.22029229\n",
      " 0.16734257] KL: 0.13280987565172087\n",
      "enet_b0_8_best_vgaf 100000 10 [0.16554442 0.25131992 0.10299181 0.05646951 0.03366746 0.22331471\n",
      " 0.16669217] KL: 0.14028030201105463\n",
      "enet_b0_8_best_vgaf 100000 50 [0.13608539 0.28334226 0.11148519 0.05229933 0.02130997 0.23287933\n",
      " 0.16259852] KL: 0.1892194191208753\n",
      "enet_b0_8_best_vgaf 100000 100 [0.12200627 0.30224195 0.10444563 0.05115158 0.01660418 0.23540439\n",
      " 0.16814599] KL: 0.2238774624282206\n",
      "\n",
      "mbf_va 0.1 1 [0.13015533 0.32883159 0.05865024 0.12273319 0.06622542 0.15276609\n",
      " 0.14063815] KL: 0.06065386131302601\n",
      "mbf_va 0.1 5 [0.13987298 0.32370495 0.05830591 0.12265667 0.06415946 0.15142704\n",
      " 0.13987298] KL: 0.05946694102554627\n",
      "mbf_va 0.1 10 [0.15039406 0.31811921 0.05773204 0.12254189 0.06232305 0.14985844\n",
      " 0.1390313 ] KL: 0.0591066839072463\n",
      "mbf_va 0.1 50 [0.15039406 0.31811921 0.05773204 0.12254189 0.06232305 0.14985844\n",
      " 0.1390313 ] KL: 0.0591066839072463\n",
      "mbf_va 0.1 100 [0.15039406 0.31811921 0.05773204 0.12254189 0.06232305 0.14985844\n",
      " 0.1390313 ] KL: 0.0591066839072463\n",
      "mbf_va 1 1 [0.12801285 0.33269569 0.05945367 0.12231234 0.06473334 0.15295738\n",
      " 0.13983472] KL: 0.06194768183908228\n",
      "mbf_va 1 5 [0.12759201 0.3329635  0.059798   0.1223506  0.06435075 0.1530339\n",
      " 0.13991124] KL: 0.06210796563918103\n",
      "mbf_va 1 10 [0.12873977 0.33196878 0.05964496 0.1223506  0.0641212  0.15326345\n",
      " 0.13991124] KL: 0.062055911790016696\n",
      "mbf_va 1 50 [0.15161833 0.32217461 0.05792333 0.1223506  0.05975974 0.14913153\n",
      " 0.13704185] KL: 0.06096514167130687\n",
      "mbf_va 1 100 [0.15161833 0.32217461 0.05792333 0.1223506  0.05975974 0.14913153\n",
      " 0.13704185] KL: 0.06096514167130687\n",
      "mbf_va 10 1 [0.1277833  0.33284873 0.05926238 0.12254189 0.06446553 0.15311041\n",
      " 0.13998776] KL: 0.06253589103294813\n",
      "mbf_va 10 5 [0.1268651  0.33816665 0.05842069 0.12009335 0.06186395 0.15594154\n",
      " 0.13864871] KL: 0.06710028888472563\n",
      "mbf_va 10 10 [0.12675033 0.33801362 0.05834417 0.12005509 0.06159614 0.1564389\n",
      " 0.13880174] KL: 0.06760505110793809\n",
      "mbf_va 10 50 [0.13895478 0.32925243 0.05765552 0.12005509 0.06002755 0.15663019\n",
      " 0.13742444] KL: 0.06541591619657344\n",
      "mbf_va 10 100 [0.14825159 0.32297804 0.05627822 0.12005509 0.05838243 0.15663019\n",
      " 0.13742444] KL: 0.06649319583630928\n",
      "mbf_va 50 1 [0.12770679 0.33311654 0.05933889 0.12246538 0.06419772 0.15291912\n",
      " 0.14025557] KL: 0.0627670954124943\n",
      "mbf_va 50 5 [0.12598516 0.33973525 0.05903283 0.11932818 0.06086923 0.15693626\n",
      " 0.13811309] KL: 0.06800502172563011\n",
      "mbf_va 50 10 [0.12238886 0.34298722 0.0591476  0.11707093 0.05895631 0.16110644\n",
      " 0.13834264] KL: 0.07265215007691063\n",
      "mbf_va 50 50 [0.12085852 0.34543576 0.05964496 0.1162675  0.05765552 0.162522\n",
      " 0.13761573] KL: 0.07465499074828473\n",
      "mbf_va 50 100 [0.1257556  0.34222205 0.05853547 0.1162675  0.05708164 0.162522\n",
      " 0.13761573] KL: 0.07428873589194722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va 100 1 [0.12766853 0.33307828 0.05930064 0.12242712 0.0643125  0.15291912\n",
      " 0.14029383] KL: 0.06272530670322751\n",
      "mbf_va 100 5 [0.12556431 0.33965873 0.0591476  0.11921341 0.06098401 0.15743362\n",
      " 0.13799832] KL: 0.06799152394800378\n",
      "mbf_va 100 10 [0.12093504 0.34528273 0.05903283 0.11550233 0.05681383 0.16301936\n",
      " 0.13941388] KL: 0.07678249294643566\n",
      "mbf_va 100 50 [0.11810391 0.35044762 0.06186395 0.11179126 0.05176372 0.16585049\n",
      " 0.14017905] KL: 0.08312409561902645\n",
      "mbf_va 100 100 [0.11814217 0.35040937 0.06186395 0.11179126 0.05176372 0.16585049\n",
      " 0.14017905] KL: 0.08310240821560408\n",
      "mbf_va 500 1 [0.12766853 0.33311654 0.05930064 0.12254189 0.0643125  0.15280435\n",
      " 0.14025557] KL: 0.06269413080154353\n",
      "mbf_va 500 5 [0.1252965  0.33981177 0.05922412 0.11925166 0.06109878 0.15743362\n",
      " 0.13788354] KL: 0.06787909359774408\n",
      "mbf_va 500 10 [0.120782   0.34608616 0.05941541 0.11404851 0.05601041 0.16470273\n",
      " 0.13895478] KL: 0.07790015225965168\n",
      "mbf_va 500 50 [0.1097253  0.36487107 0.06297345 0.10394827 0.04349989 0.17805494\n",
      " 0.13692708] KL: 0.10486113601929696\n",
      "mbf_va 500 100 [0.10838626 0.36552146 0.06316474 0.10387176 0.04139567 0.17954702\n",
      " 0.13811309] KL: 0.1100606390974769\n",
      "mbf_va 1000 1 [0.12770679 0.33315479 0.05926238 0.12254189 0.0643125  0.15276609\n",
      " 0.14025557] KL: 0.06271959847119814\n",
      "mbf_va 1000 5 [0.1252965  0.33969699 0.05930064 0.11936644 0.06090749 0.15751014\n",
      " 0.1379218 ] KL: 0.06798899384825319\n",
      "mbf_va 1000 10 [0.12051419 0.34646874 0.05918586 0.11385722 0.05616344 0.16497054\n",
      " 0.13884   ] KL: 0.07819122870592116\n",
      "mbf_va 1000 50 [0.10276226 0.37183411 0.06427424 0.10222664 0.04239039 0.18153646\n",
      " 0.1349759 ] KL: 0.11191628597951948\n",
      "mbf_va 1000 100 [0.09905119 0.37049506 0.06503941 0.10295355 0.04193129 0.18475017\n",
      " 0.13577933] KL: 0.11526985443359479\n",
      "mbf_va 10000 1 [0.12766853 0.33315479 0.05926238 0.12254189 0.06435075 0.15276609\n",
      " 0.14025557] KL: 0.0626981465694214\n",
      "mbf_va 10000 5 [0.1252965  0.33973525 0.05922412 0.11932818 0.06086923 0.15762491\n",
      " 0.1379218 ] KL: 0.06814155250626405\n",
      "mbf_va 10000 10 [0.12043768 0.34635397 0.05918586 0.11370419 0.05654602 0.16508532\n",
      " 0.13868697] KL: 0.0777811961536326\n",
      "mbf_va 10000 50 [0.09970158 0.37826153 0.06389165 0.10260923 0.03910016 0.18513276\n",
      " 0.13130308] KL: 0.12223871641570443\n",
      "mbf_va 10000 100 [0.08799449 0.37829979 0.06790879 0.10517255 0.04384421 0.19431479\n",
      " 0.12246538] KL: 0.1200757696867555\n",
      "mbf_va 100000 1 [0.12766853 0.33315479 0.05926238 0.12254189 0.06435075 0.15276609\n",
      " 0.14025557] KL: 0.0626981465694214\n",
      "mbf_va 100000 5 [0.1252965  0.33981177 0.05922412 0.11932818 0.06083097 0.15758666\n",
      " 0.1379218 ] KL: 0.06817995160749693\n",
      "mbf_va 100000 10 [0.12036116 0.34643048 0.05918586 0.11381896 0.05643125 0.16508532\n",
      " 0.13868697] KL: 0.07794010832036741\n",
      "mbf_va 100000 50 [0.09736782 0.37841457 0.06438901 0.10325962 0.03967404 0.18547708\n",
      " 0.13141786] KL: 0.12225218132847925\n",
      "mbf_va 100000 100 [0.08409213 0.38445941 0.06806183 0.10773586 0.04269646 0.19259316\n",
      " 0.12036116] KL: 0.12556566353160942\n",
      "\n",
      "enet_b0_8_mtl_abaw 0.1 1 [0.08175836 0.46223889 0.02731655 0.05118984 0.12215931 0.12701813\n",
      " 0.12831892] KL: 0.19354988300714612\n",
      "enet_b0_8_mtl_abaw 0.1 5 [0.09109343 0.45856607 0.02720178 0.05088377 0.12120285 0.1252965\n",
      " 0.1257556 ] KL: 0.18409416802219322\n",
      "enet_b0_8_mtl_abaw 0.1 10 [0.10092586 0.45447242 0.02720178 0.05069248 0.12013161 0.1228097\n",
      " 0.12376616] KL: 0.17546395186342734\n",
      "enet_b0_8_mtl_abaw 0.1 50 [0.10092586 0.45447242 0.02720178 0.05069248 0.12013161 0.1228097\n",
      " 0.12376616] KL: 0.17546395186342734\n",
      "enet_b0_8_mtl_abaw 0.1 100 [0.10092586 0.45447242 0.02720178 0.05069248 0.12013161 0.1228097\n",
      " 0.12376616] KL: 0.17546395186342734\n",
      "enet_b0_8_mtl_abaw 1 1 [0.0801515  0.46529956 0.02724003 0.05019512 0.12005509 0.12663555\n",
      " 0.13042314] KL: 0.19831628623897338\n",
      "enet_b0_8_mtl_abaw 1 5 [0.07976892 0.46556737 0.02727829 0.04996557 0.1203229  0.12751549\n",
      " 0.12958145] KL: 0.19889644245996185\n",
      "enet_b0_8_mtl_abaw 1 10 [0.08133752 0.46503175 0.02762262 0.04996557 0.12001683 0.12675033\n",
      " 0.12927538] KL: 0.1958051808396659\n",
      "enet_b0_8_mtl_abaw 1 50 [0.10456041 0.45588798 0.02762262 0.04931517 0.11840998 0.11879256\n",
      " 0.12541128] KL: 0.17446851130993335\n",
      "enet_b0_8_mtl_abaw 1 100 [0.10456041 0.45588798 0.02762262 0.04931517 0.11840998 0.11879256\n",
      " 0.12541128] KL: 0.17446851130993335\n",
      "enet_b0_8_mtl_abaw 10 1 [0.07961588 0.46732726 0.02701048 0.04981253 0.11944296 0.12709465\n",
      " 0.12969623] KL: 0.20084121924434017\n",
      "enet_b0_8_mtl_abaw 10 5 [0.08038105 0.47210957 0.02636009 0.04812916 0.11638228 0.12629122\n",
      " 0.13034662] KL: 0.20670811590967592\n",
      "enet_b0_8_mtl_abaw 10 10 [0.08061061 0.47218609 0.02655138 0.04805264 0.11615273 0.12587038\n",
      " 0.13057617] KL: 0.2059625959648575\n",
      "enet_b0_8_mtl_abaw 10 50 [0.09331242 0.46782462 0.02655138 0.04732573 0.11416329 0.11856301\n",
      " 0.13225955] KL: 0.19436560327933167\n",
      "enet_b0_8_mtl_abaw 10 100 [0.0997781  0.46541434 0.02655138 0.04594843 0.11416329 0.11588492\n",
      " 0.13225955] KL: 0.19111134107697925\n",
      "enet_b0_8_mtl_abaw 50 1 [0.07953937 0.46740378 0.02697222 0.04973602 0.11967251 0.1268651\n",
      " 0.129811  ] KL: 0.20119162315908132\n",
      "enet_b0_8_mtl_abaw 50 5 [0.07999847 0.4749407  0.02658964 0.04728747 0.11450761 0.12571735\n",
      " 0.13095876] KL: 0.20880871474277582\n",
      "enet_b0_8_mtl_abaw 50 10 [0.08160533 0.47888132 0.02563318 0.04613972 0.11182952 0.12445482\n",
      " 0.13145612] KL: 0.21413387847952514\n",
      "enet_b0_8_mtl_abaw 50 50 [0.08566072 0.47907261 0.02544189 0.04613972 0.11079654 0.11928992\n",
      " 0.13359859] KL: 0.2113992930779171\n",
      "enet_b0_8_mtl_abaw 50 100 [0.08891269 0.47872829 0.02544189 0.04499197 0.11079654 0.11745352\n",
      " 0.13367511] KL: 0.21028559491154447\n",
      "enet_b0_8_mtl_abaw 100 1 [0.07957763 0.46744204 0.02697222 0.04973602 0.11963425 0.12675033\n",
      " 0.12988752] KL: 0.2011728391106153\n",
      "enet_b0_8_mtl_abaw 100 5 [0.08018976 0.47543806 0.02620705 0.04724922 0.11408677 0.12552605\n",
      " 0.13130308] KL: 0.21030528331938086\n",
      "enet_b0_8_mtl_abaw 100 10 [0.08133752 0.48029689 0.02578621 0.0460632  0.11114087 0.12307751\n",
      " 0.1322978 ] KL: 0.2146695766776445\n",
      "enet_b0_8_mtl_abaw 100 50 [0.08554595 0.48324279 0.02628357 0.04602494 0.11018441 0.11772133\n",
      " 0.13099702] KL: 0.20969241276070372\n",
      "enet_b0_8_mtl_abaw 100 100 [0.08558421 0.48450532 0.02628357 0.04594843 0.11018441 0.1164588\n",
      " 0.13103527] KL: 0.2102757140806282\n",
      "enet_b0_8_mtl_abaw 500 1 [0.07957763 0.46740378 0.02697222 0.0496595  0.11971077 0.12671207\n",
      " 0.12996404] KL: 0.20127809420624454\n",
      "enet_b0_8_mtl_abaw 500 5 [0.08038105 0.47543806 0.02624531 0.0471727  0.11370419 0.12556431\n",
      " 0.13149438] KL: 0.21015554599253616\n",
      "enet_b0_8_mtl_abaw 500 10 [0.08187313 0.48090902 0.02639835 0.04610146 0.11171474 0.12231234\n",
      " 0.13069095] KL: 0.21166858694530521\n",
      "enet_b0_8_mtl_abaw 500 50 [0.07808555 0.49770449 0.02804346 0.04503022 0.10486648 0.11741526\n",
      " 0.12885454] KL: 0.2186736530149951\n",
      "enet_b0_8_mtl_abaw 500 100 [0.07724386 0.49915831 0.0280052  0.04503022 0.10471344 0.11753003\n",
      " 0.12831892] KL: 0.22023595657506864\n",
      "enet_b0_8_mtl_abaw 1000 1 [0.07957763 0.46740378 0.02697222 0.0496595  0.11971077 0.12671207\n",
      " 0.12996404] KL: 0.20127809420624454\n",
      "enet_b0_8_mtl_abaw 1000 5 [0.08030454 0.47547632 0.02624531 0.0471727  0.11381896 0.12560257\n",
      " 0.1313796 ] KL: 0.2102197243212507\n",
      "enet_b0_8_mtl_abaw 1000 10 [0.08191139 0.48113857 0.02636009 0.04610146 0.11179126 0.12204453\n",
      " 0.13065269] KL: 0.2118296842399873\n",
      "enet_b0_8_mtl_abaw 1000 50 [0.07885072 0.50187467 0.02525059 0.04587191 0.10211187 0.11775958\n",
      " 0.12828066] KL: 0.2283699896452122\n",
      "enet_b0_8_mtl_abaw 1000 100 [0.07724386 0.50547096 0.02509756 0.0467136  0.10050501 0.11726222\n",
      " 0.12770679] KL: 0.2310425860266449\n",
      "enet_b0_8_mtl_abaw 10000 1 [0.07957763 0.46740378 0.02697222 0.0496595  0.11971077 0.12671207\n",
      " 0.12996404] KL: 0.20127809420624454\n",
      "enet_b0_8_mtl_abaw 10000 5 [0.08022802 0.47547632 0.02628357 0.04721096 0.11389548 0.12556431\n",
      " 0.13134134] KL: 0.21008717233600227\n",
      "enet_b0_8_mtl_abaw 10000 10 [0.08168184 0.48113857 0.02636009 0.04610146 0.11205907 0.12208279\n",
      " 0.13057617] KL: 0.21202194766603089\n",
      "enet_b0_8_mtl_abaw 10000 50 [0.07961588 0.49701584 0.02655138 0.04820568 0.10115541 0.12170021\n",
      " 0.1257556 ] KL: 0.21703396477630316\n",
      "enet_b0_8_mtl_abaw 10000 100 [0.07754993 0.48748948 0.02238121 0.05210804 0.10241794 0.13876349\n",
      " 0.11928992] KL: 0.22685621750016655\n",
      "enet_b0_8_mtl_abaw 100000 1 [0.07957763 0.46740378 0.02697222 0.0496595  0.11971077 0.12671207\n",
      " 0.12996404] KL: 0.20127809420624454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_mtl_abaw 100000 5 [0.08018976 0.47555283 0.02628357 0.0471727  0.11389548 0.12552605\n",
      " 0.1313796 ] KL: 0.21022006120332884\n",
      "enet_b0_8_mtl_abaw 100000 10 [0.0817201  0.48113857 0.02636009 0.04602494 0.11205907 0.12208279\n",
      " 0.13061443] KL: 0.21211390981231448\n",
      "enet_b0_8_mtl_abaw 100000 50 [0.07980718 0.49598286 0.02632183 0.04832045 0.10127018 0.12192976\n",
      " 0.12636774] KL: 0.2171598398043258\n",
      "enet_b0_8_mtl_abaw 100000 100 [0.07395363 0.48703038 0.02176907 0.05329405 0.10666463 0.14033208\n",
      " 0.11695616] KL: 0.23131526182517637\n",
      "\n",
      "abaw_expr_enet0_multilabel 0.1 1 [0.01725457 0.66971459 0.09327416 0.04066876 0.01924401 0.11003137\n",
      " 0.04981253] KL: 0.5453224836544938\n",
      "abaw_expr_enet0_multilabel 0.1 5 [0.01710154 0.66887291 0.09400107 0.04070702 0.01905272 0.11022266\n",
      " 0.05004208] KL: 0.5465759890654756\n",
      "abaw_expr_enet0_multilabel 0.1 10 [0.01698676 0.66826077 0.09438366 0.04082179 0.01905272 0.11033744\n",
      " 0.05015686] KL: 0.5467474903119365\n",
      "abaw_expr_enet0_multilabel 0.1 50 [0.01698676 0.66826077 0.09438366 0.04082179 0.01905272 0.11033744\n",
      " 0.05015686] KL: 0.5467474903119365\n",
      "abaw_expr_enet0_multilabel 0.1 100 [0.01698676 0.66826077 0.09438366 0.04082179 0.01905272 0.11033744\n",
      " 0.05015686] KL: 0.5467474903119365\n",
      "abaw_expr_enet0_multilabel 1 1 [0.01515036 0.67304308 0.09204989 0.04112786 0.01725457 0.11301553\n",
      " 0.04835871] KL: 0.577659562920094\n",
      "abaw_expr_enet0_multilabel 1 5 [0.01484429 0.67277527 0.09258551 0.0410896  0.01683373 0.1133216\n",
      " 0.04855   ] KL: 0.5826408016811331\n",
      "abaw_expr_enet0_multilabel 1 10 [0.014653   0.67197184 0.09319764 0.04120438 0.01683373 0.11347463\n",
      " 0.04866478] KL: 0.5835467519484174\n",
      "abaw_expr_enet0_multilabel 1 50 [0.0140026  0.67093886 0.09461321 0.04120438 0.01683373 0.11362767\n",
      " 0.04877955] KL: 0.589051723453405\n",
      "abaw_expr_enet0_multilabel 1 100 [0.0140026  0.67093886 0.09461321 0.04120438 0.01683373 0.11362767\n",
      " 0.04877955] KL: 0.589051723453405\n",
      "abaw_expr_enet0_multilabel 10 1 [0.01499732 0.67388477 0.09243247 0.04128089 0.01675721 0.11293902\n",
      " 0.04770832] KL: 0.5828254419802646\n",
      "abaw_expr_enet0_multilabel 10 5 [0.01430867 0.67797842 0.09155253 0.04097483 0.01442344 0.11469891\n",
      " 0.0460632 ] KL: 0.6099072458079029\n",
      "abaw_expr_enet0_multilabel 10 10 [0.01373479 0.67767235 0.09220292 0.04105134 0.01449996 0.11496672\n",
      " 0.04587191] KL: 0.6150455480864928\n",
      "abaw_expr_enet0_multilabel 10 50 [0.01293136 0.67667763 0.093695   0.04105134 0.01449996 0.1148902\n",
      " 0.0462545 ] KL: 0.6224344760877508\n",
      "abaw_expr_enet0_multilabel 10 100 [0.01293136 0.67667763 0.093695   0.04105134 0.01449996 0.1148902\n",
      " 0.0462545 ] KL: 0.6224344760877508\n",
      "abaw_expr_enet0_multilabel 50 1 [0.01503558 0.67384651 0.09243247 0.04124264 0.01687199 0.11293902\n",
      " 0.0476318 ] KL: 0.581904239877414\n",
      "abaw_expr_enet0_multilabel 50 5 [0.01384957 0.68015916 0.09132298 0.04093657 0.01381131 0.11515801\n",
      " 0.04476241] KL: 0.6220759434797243\n",
      "abaw_expr_enet0_multilabel 50 10 [0.012434   0.68360242 0.09113169 0.04020966 0.01270181 0.11883082\n",
      " 0.0410896 ] KL: 0.6549617568530791\n",
      "abaw_expr_enet0_multilabel 50 50 [0.0110567  0.68409978 0.09063433 0.03998011 0.01254878 0.12177672\n",
      " 0.03990359] KL: 0.6764196597174887\n",
      "abaw_expr_enet0_multilabel 50 100 [0.0110567  0.68409978 0.09009871 0.03998011 0.01254878 0.12231234\n",
      " 0.03990359] KL: 0.6766357837975592\n",
      "abaw_expr_enet0_multilabel 100 1 [0.01499732 0.67392302 0.09239422 0.04120438 0.01691025 0.11290076\n",
      " 0.04767006] KL: 0.5821339633275766\n",
      "abaw_expr_enet0_multilabel 100 5 [0.01381131 0.68069477 0.09151427 0.04097483 0.01346698 0.1153493\n",
      " 0.04418854] KL: 0.6259695483409563\n",
      "abaw_expr_enet0_multilabel 100 10 [0.01231923 0.6846354  0.09178208 0.04013314 0.01220445 0.11928992\n",
      " 0.03963578] KL: 0.663173795734149\n",
      "abaw_expr_enet0_multilabel 100 50 [0.01036805 0.68608922 0.09247073 0.03887061 0.01186013 0.12399572\n",
      " 0.03634555] KL: 0.7005704711621733\n",
      "abaw_expr_enet0_multilabel 100 100 [0.01036805 0.68608922 0.09128472 0.03887061 0.01186013 0.12518173\n",
      " 0.03634555] KL: 0.7010454938430422\n",
      "abaw_expr_enet0_multilabel 500 1 [0.01499732 0.67388477 0.09239422 0.04116612 0.01691025 0.11290076\n",
      " 0.04774658] KL: 0.5821013680356137\n",
      "abaw_expr_enet0_multilabel 500 5 [0.0140026  0.68111562 0.09132298 0.04082179 0.0135435  0.11523452\n",
      " 0.04395899] KL: 0.6242517695113678\n",
      "abaw_expr_enet0_multilabel 500 10 [0.01231923 0.68448236 0.09250899 0.04020966 0.01170709 0.11955773\n",
      " 0.03921494] KL: 0.6677216386944507\n",
      "abaw_expr_enet0_multilabel 500 50 [0.00711608 0.69481215 0.09468972 0.04074528 0.01163058 0.1234601\n",
      " 0.0275461 ] KL: 0.7789300917250026\n",
      "abaw_expr_enet0_multilabel 500 100 [0.00711608 0.69603642 0.09358023 0.04074528 0.01178361 0.12342184\n",
      " 0.02731655] KL: 0.7791837727075901\n",
      "abaw_expr_enet0_multilabel 1000 1 [0.01499732 0.67392302 0.09235596 0.04116612 0.01691025 0.11290076\n",
      " 0.04774658] KL: 0.5821351461675295\n",
      "abaw_expr_enet0_multilabel 1000 5 [0.0140026  0.68107736 0.09136124 0.04078353 0.0135435  0.11531104\n",
      " 0.04392073] KL: 0.6243389870910925\n",
      "abaw_expr_enet0_multilabel 1000 10 [0.01216619 0.6844441  0.09285332 0.04020966 0.01174535 0.11951947\n",
      " 0.0390619 ] KL: 0.6693327428317756\n",
      "abaw_expr_enet0_multilabel 1000 50 [0.00784299 0.69630423 0.09511057 0.04174    0.01071237 0.1203229\n",
      " 0.02796694] KL: 0.7703949263633487\n",
      "abaw_expr_enet0_multilabel 1000 100 [0.00772821 0.70024485 0.09289158 0.04162522 0.01128625 0.12089678\n",
      " 0.02532711] KL: 0.777465262862455\n",
      "abaw_expr_enet0_multilabel 10000 1 [0.01499732 0.67392302 0.09235596 0.04116612 0.01691025 0.11290076\n",
      " 0.04774658] KL: 0.5821351461675295\n",
      "abaw_expr_enet0_multilabel 10000 5 [0.0140026  0.68111562 0.09132298 0.04082179 0.0135435  0.11523452\n",
      " 0.04395899] KL: 0.6242517695113678\n",
      "abaw_expr_enet0_multilabel 10000 10 [0.01208968 0.68440585 0.09285332 0.0401714  0.01170709 0.11951947\n",
      " 0.03925319] KL: 0.6703698784389743\n",
      "abaw_expr_enet0_multilabel 10000 50 [0.00803428 0.69607468 0.09461321 0.04135741 0.0099472  0.12288622\n",
      " 0.027087  ] KL: 0.7777700048968584\n",
      "abaw_expr_enet0_multilabel 10000 100 [0.00665697 0.70697835 0.09587574 0.03929145 0.00642742 0.12510521\n",
      " 0.01966486] KL: 0.8884444520136183\n",
      "abaw_expr_enet0_multilabel 100000 1 [0.01499732 0.67392302 0.09235596 0.04116612 0.01691025 0.11290076\n",
      " 0.04774658] KL: 0.5821351461675295\n",
      "abaw_expr_enet0_multilabel 100000 5 [0.0140026  0.68107736 0.09136124 0.04082179 0.0135435  0.11519627\n",
      " 0.04399725] KL: 0.6241689227959906\n",
      "abaw_expr_enet0_multilabel 100000 10 [0.01205142 0.68452062 0.09285332 0.04013314 0.01166883 0.11951947\n",
      " 0.03925319] KL: 0.6713247451923618\n",
      "abaw_expr_enet0_multilabel 100000 50 [0.00803428 0.69580687 0.0952636  0.04097483 0.01002372 0.12284796\n",
      " 0.02704874] KL: 0.7774329496315646\n",
      "abaw_expr_enet0_multilabel 100000 100 [0.00570051 0.71631341 0.09067258 0.03883235 0.00520315 0.12839544\n",
      " 0.01488255] KL: 0.966822320571596\n",
      "\n",
      "abaw_expr_enet0_multiclass 0.1 1 [0.01453822 0.56668452 0.1112939  0.03286403 0.0571199  0.12388094\n",
      " 0.09361849] KL: 0.420594010656754\n",
      "abaw_expr_enet0_multiclass 0.1 5 [0.01469125 0.5656898  0.11205907 0.03294055 0.05696687 0.12395746\n",
      " 0.093695  ] KL: 0.41847536403690216\n",
      "abaw_expr_enet0_multiclass 0.1 10 [0.01480603 0.5647716  0.11270947 0.0329788  0.05685209 0.12422527\n",
      " 0.09365674] KL: 0.4168848874142391\n",
      "abaw_expr_enet0_multiclass 0.1 50 [0.01480603 0.5647716  0.11270947 0.0329788  0.05685209 0.12422527\n",
      " 0.09365674] KL: 0.4168848874142391\n",
      "abaw_expr_enet0_multiclass 0.1 100 [0.01480603 0.5647716  0.11270947 0.0329788  0.05685209 0.12422527\n",
      " 0.09365674] KL: 0.4168848874142391\n",
      "abaw_expr_enet0_multiclass 1 1 [0.0140026  0.56779402 0.10984008 0.03229015 0.05486265 0.12472263\n",
      " 0.09648787] KL: 0.4306813793506586\n",
      "abaw_expr_enet0_multiclass 1 5 [0.0140026  0.5667993  0.11018441 0.03236667 0.05428877 0.1252965\n",
      " 0.09706175] KL: 0.43064241785635987\n",
      "abaw_expr_enet0_multiclass 1 10 [0.01404086 0.56526896 0.11121738 0.03240493 0.05428877 0.12571735\n",
      " 0.09706175] KL: 0.4293233176477009\n",
      "abaw_expr_enet0_multiclass 1 50 [0.01300788 0.56385339 0.11305379 0.03240493 0.05440355 0.12652077\n",
      " 0.09675568] KL: 0.43963462720788765\n",
      "abaw_expr_enet0_multiclass 1 100 [0.01300788 0.56385339 0.11305379 0.03240493 0.05440355 0.12652077\n",
      " 0.09675568] KL: 0.43963462720788765\n",
      "abaw_expr_enet0_multiclass 10 1 [0.01423215 0.56733491 0.10968705 0.03183105 0.05425052 0.12552605\n",
      " 0.09713827] KL: 0.4300862185641297\n",
      "abaw_expr_enet0_multiclass 10 5 [0.01304614 0.56741143 0.10796541 0.03244319 0.05161068 0.12785982\n",
      " 0.09966333] KL: 0.4448463312647443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaw_expr_enet0_multiclass 10 10 [0.01289311 0.56591935 0.10918969 0.03240493 0.05161068 0.12847196\n",
      " 0.09951029] KL: 0.4458694955299605\n",
      "abaw_expr_enet0_multiclass 10 50 [0.01155406 0.56488637 0.11140868 0.03240493 0.0510368  0.1293519\n",
      " 0.09935726] KL: 0.4622042194821378\n",
      "abaw_expr_enet0_multiclass 10 100 [0.01155406 0.5661489  0.11140868 0.03240493 0.0510368  0.1293519\n",
      " 0.09809473] KL: 0.46284553518059507\n",
      "abaw_expr_enet0_multiclass 50 1 [0.01427041 0.5672584  0.10964879 0.03183105 0.05421226 0.12552605\n",
      " 0.09725304] KL: 0.42970185283541784\n",
      "abaw_expr_enet0_multiclass 50 5 [0.01304614 0.56760272 0.10777412 0.0320606  0.05118984 0.12877802\n",
      " 0.09954855] KL: 0.4466295581312332\n",
      "abaw_expr_enet0_multiclass 50 10 [0.0119749  0.56901829 0.10865407 0.03186931 0.04912388 0.13160915\n",
      " 0.0977504 ] KL: 0.4635450665420588\n",
      "abaw_expr_enet0_multiclass 50 50 [0.01094192 0.56898003 0.10953401 0.03209886 0.04640753 0.13333078\n",
      " 0.09870686] KL: 0.48040942687551014\n",
      "abaw_expr_enet0_multiclass 50 100 [0.01094192 0.57024256 0.10953401 0.03209886 0.04610146 0.13333078\n",
      " 0.0977504 ] KL: 0.4815271638444945\n",
      "abaw_expr_enet0_multiclass 100 1 [0.01427041 0.56729666 0.10964879 0.03186931 0.05421226 0.12544954\n",
      " 0.09725304] KL: 0.4296100315182004\n",
      "abaw_expr_enet0_multiclass 100 5 [0.01300788 0.56760272 0.10804193 0.03202234 0.0510368  0.1288928\n",
      " 0.09939552] KL: 0.44734451062159675\n",
      "abaw_expr_enet0_multiclass 100 10 [0.01163058 0.56913306 0.10896013 0.03236667 0.04900911 0.13115005\n",
      " 0.0977504 ] KL: 0.46666071388677555\n",
      "abaw_expr_enet0_multiclass 100 50 [0.01036805 0.57108425 0.10873058 0.03148672 0.04602494 0.13444028\n",
      " 0.09786518] KL: 0.49203528442571925\n",
      "abaw_expr_enet0_multiclass 100 100 [0.01036805 0.57230852 0.10873058 0.03148672 0.04571888 0.13444028\n",
      " 0.09694697] KL: 0.49314962237831067\n",
      "abaw_expr_enet0_multiclass 500 1 [0.01427041 0.56744969 0.10957227 0.03183105 0.05421226 0.12544954\n",
      " 0.09721478] KL: 0.42979912517359137\n",
      "abaw_expr_enet0_multiclass 500 5 [0.01300788 0.56787053 0.10804193 0.03190757 0.05073074 0.12919887\n",
      " 0.09924248] KL: 0.44822495507639526\n",
      "abaw_expr_enet0_multiclass 500 10 [0.01140103 0.57005127 0.1097253  0.03225189 0.04877955 0.13076746\n",
      " 0.09702349] KL: 0.47059643680599295\n",
      "abaw_expr_enet0_multiclass 500 50 [0.00853164 0.57173464 0.11791262 0.0281965  0.04571888 0.13371337\n",
      " 0.09419236] KL: 0.5313745079455557\n",
      "abaw_expr_enet0_multiclass 500 100 [0.0085699  0.57154335 0.11791262 0.02815824 0.04541281 0.13532022\n",
      " 0.09308287] KL: 0.5315219615907167\n",
      "abaw_expr_enet0_multiclass 1000 1 [0.01427041 0.56744969 0.10957227 0.03183105 0.05421226 0.12544954\n",
      " 0.09721478] KL: 0.42979912517359137\n",
      "abaw_expr_enet0_multiclass 1000 5 [0.01304614 0.56787053 0.1078889  0.03194583 0.05073074 0.12931364\n",
      " 0.09920422] KL: 0.44772169370400566\n",
      "abaw_expr_enet0_multiclass 1000 10 [0.01124799 0.57024256 0.10976356 0.03221364 0.04881781 0.13088224\n",
      " 0.0968322 ] KL: 0.47276808348625615\n",
      "abaw_expr_enet0_multiclass 1000 50 [0.00803428 0.56943913 0.12273319 0.02777565 0.04472416 0.13352208\n",
      " 0.09377152] KL: 0.5422474984908177\n",
      "abaw_expr_enet0_multiclass 1000 100 [0.00803428 0.56993649 0.12368965 0.02773739 0.0440355  0.13382814\n",
      " 0.09273854] KL: 0.5438852612276072\n",
      "abaw_expr_enet0_multiclass 10000 1 [0.01427041 0.56744969 0.10957227 0.03183105 0.05421226 0.12544954\n",
      " 0.09721478] KL: 0.42979912517359137\n",
      "abaw_expr_enet0_multiclass 10000 5 [0.01296962 0.56790879 0.10796541 0.03190757 0.05069248 0.1293519\n",
      " 0.09920422] KL: 0.4487554788687149\n",
      "abaw_expr_enet0_multiclass 10000 10 [0.01128625 0.56978346 0.11003137 0.03221364 0.04877955 0.13099702\n",
      " 0.09690872] KL: 0.4720718773661646\n",
      "abaw_expr_enet0_multiclass 10000 50 [0.00803428 0.56798531 0.12812763 0.0266279  0.04483893 0.12820415\n",
      " 0.0961818 ] KL: 0.5445458923426607\n",
      "abaw_expr_enet0_multiclass 10000 100 [0.00638917 0.57682302 0.13218303 0.02199862 0.04223736 0.12659729\n",
      " 0.09377152] KL: 0.6065926963598233\n",
      "abaw_expr_enet0_multiclass 100000 1 [0.01427041 0.56744969 0.10957227 0.03183105 0.05421226 0.12544954\n",
      " 0.09721478] KL: 0.42979912517359137\n",
      "abaw_expr_enet0_multiclass 100000 5 [0.01296962 0.56783227 0.10796541 0.03190757 0.05069248 0.1293519\n",
      " 0.09928074] KL: 0.4487168541508295\n",
      "abaw_expr_enet0_multiclass 100000 10 [0.01128625 0.56978346 0.11006963 0.03221364 0.04877955 0.13103527\n",
      " 0.0968322 ] KL: 0.4720753345294973\n",
      "abaw_expr_enet0_multiclass 100000 50 [0.00841686 0.56722014 0.12908409 0.02601576 0.04648405 0.1284337\n",
      " 0.0943454 ] KL: 0.5368192945553718\n",
      "abaw_expr_enet0_multiclass 100000 100 [0.00627439 0.57709083 0.1338664  0.0225725  0.04059224 0.12154717\n",
      " 0.09805647] KL: 0.6096206386044521\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 1 [0.03802892 0.42287092 0.1494376  0.05298799 0.03990359 0.18563012\n",
      " 0.11114087] KL: 0.23578675435363067\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 5 [0.03825847 0.42333002 0.14890198 0.05298799 0.03940623 0.18566838\n",
      " 0.11144694] KL: 0.23612313788898387\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 10 [0.03825847 0.42313873 0.14848114 0.05302625 0.03948275 0.18608922\n",
      " 0.11152345] KL: 0.2359533771903981\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 50 [0.03825847 0.42313873 0.14848114 0.05302625 0.03948275 0.18608922\n",
      " 0.11152345] KL: 0.2359533771903981\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 100 [0.03825847 0.42313873 0.14848114 0.05302625 0.03948275 0.18608922\n",
      " 0.11152345] KL: 0.2359533771903981\n",
      "abaw_expr_enet0_multiclass_train_val 1 1 [0.03699594 0.42489862 0.15008799 0.05203152 0.03741679 0.18582141\n",
      " 0.11274772] KL: 0.2464797114197961\n",
      "abaw_expr_enet0_multiclass_train_val 1 5 [0.03711072 0.42524294 0.14955238 0.05199327 0.03646033 0.18639529\n",
      " 0.11324508] KL: 0.24851709778729553\n",
      "abaw_expr_enet0_multiclass_train_val 1 10 [0.03699594 0.42501339 0.1489785  0.05203152 0.03653684 0.18696916\n",
      " 0.11347463] KL: 0.2487459973518651\n",
      "abaw_expr_enet0_multiclass_train_val 1 50 [0.03653684 0.42424822 0.14848114 0.05203152 0.03653684 0.18773433\n",
      " 0.1144311 ] KL: 0.2503573147838093\n",
      "abaw_expr_enet0_multiclass_train_val 1 100 [0.03653684 0.42424822 0.14848114 0.05203152 0.03653684 0.18773433\n",
      " 0.1144311 ] KL: 0.2503573147838093\n",
      "abaw_expr_enet0_multiclass_train_val 10 1 [0.03699594 0.42631418 0.14878721 0.05187849 0.03688117 0.18670135\n",
      " 0.11244166] KL: 0.24836847417524377\n",
      "abaw_expr_enet0_multiclass_train_val 10 5 [0.03447089 0.42700283 0.15169485 0.0512281  0.03443263 0.18784911\n",
      " 0.1133216 ] KL: 0.2649688886852012\n",
      "abaw_expr_enet0_multiclass_train_val 10 10 [0.03393527 0.4273089  0.15161833 0.05096029 0.03424133 0.18884383\n",
      " 0.11309205] KL: 0.26821179828524916\n",
      "abaw_expr_enet0_multiclass_train_val 10 50 [0.03320836 0.42543423 0.1510062  0.05096029 0.03424133 0.19064198\n",
      " 0.11450761] KL: 0.27108740560573763\n",
      "abaw_expr_enet0_multiclass_train_val 10 100 [0.03313184 0.42551075 0.1510062  0.05096029 0.03424133 0.19064198\n",
      " 0.11450761] KL: 0.2714067905795603\n",
      "abaw_expr_enet0_multiclass_train_val 50 1 [0.03691943 0.42616114 0.14859591 0.05191675 0.03684291 0.18696916\n",
      " 0.11259469] KL: 0.24869232039423717\n",
      "abaw_expr_enet0_multiclass_train_val 50 5 [0.03355268 0.42853317 0.15249828 0.05118984 0.0336292  0.18662484\n",
      " 0.11397199] KL: 0.2706819382337585\n",
      "abaw_expr_enet0_multiclass_train_val 50 10 [0.0316015  0.43063739 0.15379907 0.05019512 0.03095111 0.18888209\n",
      " 0.11393374] KL: 0.28857997586715267\n",
      "abaw_expr_enet0_multiclass_train_val 50 50 [0.02999464 0.42883924 0.15620935 0.05000383 0.03072155 0.19079501\n",
      " 0.11343638] KL: 0.2968458975810703\n",
      "abaw_expr_enet0_multiclass_train_val 50 100 [0.02991813 0.42700283 0.15751014 0.05000383 0.03072155 0.19270793\n",
      " 0.11213559] KL: 0.2974653457374384\n",
      "abaw_expr_enet0_multiclass_train_val 100 1 [0.03691943 0.42616114 0.14863417 0.05187849 0.03684291 0.18693091\n",
      " 0.11263295] KL: 0.24873794075491829\n",
      "abaw_expr_enet0_multiclass_train_val 100 5 [0.03324661 0.42914531 0.15261305 0.05118984 0.03355268 0.18635703\n",
      " 0.11389548] KL: 0.2721567543031351\n",
      "abaw_expr_enet0_multiclass_train_val 100 10 [0.03037723 0.43101997 0.1548703  0.04977428 0.030492   0.18934119\n",
      " 0.11412503] KL: 0.2961251587642481\n",
      "abaw_expr_enet0_multiclass_train_val 100 50 [0.0286556  0.43048435 0.1575484  0.04793787 0.03037723 0.19106282\n",
      " 0.11393374] KL: 0.30777397610666657\n",
      "abaw_expr_enet0_multiclass_train_val 100 100 [0.02857908 0.42864795 0.15884919 0.04793787 0.03037723 0.19297574\n",
      " 0.11263295] KL: 0.3084129674272668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaw_expr_enet0_multiclass_train_val 500 1 [0.03699594 0.42608463 0.14859591 0.05187849 0.03684291 0.18693091\n",
      " 0.11267121] KL: 0.2484536397345221\n",
      "abaw_expr_enet0_multiclass_train_val 500 5 [0.03328487 0.42956615 0.15268957 0.05084551 0.03343791 0.18612748\n",
      " 0.11404851] KL: 0.27284329030041116\n",
      "abaw_expr_enet0_multiclass_train_val 500 10 [0.02991813 0.4318234  0.15410513 0.04927691 0.03045375 0.18922641\n",
      " 0.11519627] KL: 0.2991174422739688\n",
      "abaw_expr_enet0_multiclass_train_val 500 50 [0.02203688 0.43622312 0.16619481 0.0465223  0.02907644 0.18945596\n",
      " 0.11049047] KL: 0.35235276952432526\n",
      "abaw_expr_enet0_multiclass_train_val 500 100 [0.02188385 0.43534318 0.16780167 0.04453286 0.0311424  0.19064198\n",
      " 0.10865407] KL: 0.35096496957426204\n",
      "abaw_expr_enet0_multiclass_train_val 1000 1 [0.03699594 0.42608463 0.14855766 0.05187849 0.03684291 0.18696916\n",
      " 0.11267121] KL: 0.24846146316844564\n",
      "abaw_expr_enet0_multiclass_train_val 1000 5 [0.03332313 0.42968092 0.1528426  0.05080725 0.03336139 0.1860127\n",
      " 0.11397199] KL: 0.27295722889792373\n",
      "abaw_expr_enet0_multiclass_train_val 1000 10 [0.0300329  0.43167036 0.15376081 0.04931517 0.03041549 0.18899686\n",
      " 0.1158084 ] KL: 0.29853988857728647\n",
      "abaw_expr_enet0_multiclass_train_val 1000 50 [0.01977963 0.43794475 0.16956156 0.04640753 0.02880863 0.18853776\n",
      " 0.10896013] KL: 0.36944396719839695\n",
      "abaw_expr_enet0_multiclass_train_val 1000 100 [0.0189762  0.43951335 0.17193358 0.04460938 0.03075981 0.18907338\n",
      " 0.10513429] KL: 0.37363817028125357\n",
      "abaw_expr_enet0_multiclass_train_val 10000 1 [0.03699594 0.42608463 0.14855766 0.05187849 0.03680465 0.18700742\n",
      " 0.11267121] KL: 0.24855976114762846\n",
      "abaw_expr_enet0_multiclass_train_val 10000 5 [0.03339965 0.42964267 0.15288086 0.05080725 0.03339965 0.18593618\n",
      " 0.11393374] KL: 0.2725303987535798\n",
      "abaw_expr_enet0_multiclass_train_val 10000 10 [0.02999464 0.43178514 0.15368429 0.04935343 0.03018594 0.1889586\n",
      " 0.11603795] KL: 0.2993503267896087\n",
      "abaw_expr_enet0_multiclass_train_val 10000 50 [0.01549468 0.44196189 0.16856684 0.04575714 0.02861734 0.18964726\n",
      " 0.10995486] KL: 0.40757229553829266\n",
      "abaw_expr_enet0_multiclass_train_val 10000 100 [0.00547096 0.45340118 0.17442038 0.04594843 0.02601576 0.18237815\n",
      " 0.11236514] KL: 0.5758478760639504\n",
      "abaw_expr_enet0_multiclass_train_val 100000 1 [0.03699594 0.42608463 0.14855766 0.05187849 0.03680465 0.18700742\n",
      " 0.11267121] KL: 0.24855976114762846\n",
      "abaw_expr_enet0_multiclass_train_val 100000 5 [0.03339965 0.42964267 0.15288086 0.05080725 0.03339965 0.18593618\n",
      " 0.11393374] KL: 0.2725303987535798\n",
      "abaw_expr_enet0_multiclass_train_val 100000 10 [0.02999464 0.4318234  0.15372255 0.04931517 0.03018594 0.18888209\n",
      " 0.11607621] KL: 0.2994004596961131\n",
      "abaw_expr_enet0_multiclass_train_val 100000 50 [0.0149208  0.44284184 0.16959982 0.04591017 0.02766088 0.18972377\n",
      " 0.10934272] KL: 0.41640750260576154\n",
      "abaw_expr_enet0_multiclass_train_val 100000 100 [0.00439972 0.45386028 0.17499426 0.0460632  0.02241947 0.18425281\n",
      " 0.11401025] KL: 0.6245229623359565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "    for sigma in [0.1, 1, 10, 50, 100, 500, 1000, 10000, 100000]:\n",
    "        for delta in [1,5,10,50,100]:\n",
    "            compound_classes_counts=np.zeros(len(compound_classes))\n",
    "            for videoname in sorted(videoname2compound_scores):\n",
    "                compound_scores=videoname2compound_scores[videoname]\n",
    "                frame_numbers=sorted(compound_scores.keys())\n",
    "                all_compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "                frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "                for i in range(frames_count):\n",
    "                    start,end=max(0,i-delta),min(frames_count,i+delta+1)\n",
    "                    k_sum=0\n",
    "                    max_faces_scores=np.zeros_like(all_compound_scores[i])\n",
    "                    for j in range(start,end):\n",
    "                        if (j+1) in compound_scores:\n",
    "                            k=math.exp(-(j-i)**2/sigma)\n",
    "                            max_faces_scores+=k*compound_scores[j+1]\n",
    "                            k_sum+=k\n",
    "                    if k_sum>0:\n",
    "                        max_faces_scores/=k_sum\n",
    "                    else:\n",
    "                        max_faces_scores=all_compound_scores[i]\n",
    "            \n",
    "                    compound_index=np.argmax(max_faces_scores)\n",
    "                    compound_classes_counts[compound_index]+=1\n",
    "            compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "            print(model_name,sigma,delta, compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\t0.06065386131302601\t0.05946694102554627\t0.0591066839072463\t0.0591066839072463\t0.0591066839072463\t\n",
      "1\t0.06194768183908228\t0.06210796563918103\t0.062055911790016696\t0.06096514167130687\t0.06096514167130687\t\n",
      "10\t0.06253589103294813\t0.06710028888472563\t0.06760505110793809\t0.06541591619657344\t0.06649319583630928\t\n",
      "50\t0.0627670954124943\t0.06800502172563011\t0.07265215007691063\t0.07465499074828473\t0.07428873589194722\t\n",
      "100\t0.06272530670322751\t0.06799152394800378\t0.07678249294643566\t0.08312409561902645\t0.08310240821560408\t\n",
      "500\t0.06269413080154353\t0.06787909359774408\t0.07790015225965168\t0.10486113601929696\t0.1100606390974769\t\n",
      "1000\t0.06271959847119814\t0.06798899384825319\t0.07819122870592116\t0.11191628597951948\t0.11526985443359479\t\n",
      "10000\t0.0626981465694214\t0.06814155250626405\t0.0777811961536326\t0.12223871641570443\t0.1200757696867555\t\n",
      "100000\t0.0626981465694214\t0.06817995160749693\t0.07794010832036741\t0.12225218132847925\t0.12556566353160942\t\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "for sigma in [0.1, 1, 10, 50, 100, 500, 1000, 10000, 100000]:\n",
    "    print(sigma, end=\"\\t\")\n",
    "    for delta in [1,5,10,50,100]:\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=videoname2compound_scores[videoname]\n",
    "            frame_numbers=sorted(compound_scores.keys())\n",
    "            all_compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "            for i in range(frames_count):\n",
    "                start,end=max(0,i-delta),min(frames_count,i+delta+1)\n",
    "                k_sum=0\n",
    "                max_faces_scores=np.zeros_like(all_compound_scores[i])\n",
    "                for j in range(start,end):\n",
    "                    if (j+1) in compound_scores:\n",
    "                        k=math.exp(-(j-i)**2/sigma)\n",
    "                        max_faces_scores+=k*compound_scores[j+1]\n",
    "                        k_sum+=k\n",
    "                if k_sum>0:\n",
    "                    max_faces_scores/=k_sum\n",
    "                else:\n",
    "                    max_faces_scores=all_compound_scores[i]\n",
    "\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)), end=\"\\t\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454] \n",
      "\n",
      "enet_b0_8_best_vgaf 0 [0.16562094 0.22040707 0.10873058 0.06515418 0.04189303 0.21482133\n",
      " 0.18337287] KL: 0.12255947279994284\n",
      "enet_b0_8_best_vgaf 1 [0.16619481 0.22117224 0.11098783 0.06213176 0.04174    0.21596909\n",
      " 0.18180427] KL: 0.12486703678019509\n",
      "enet_b0_8_best_vgaf 3 [0.16420537 0.22346775 0.11401025 0.0611753  0.04059224 0.21857066\n",
      " 0.17797842] KL: 0.12656768208653865\n",
      "enet_b0_8_best_vgaf 5 [0.16271329 0.22614584 0.11247991 0.06014232 0.03833499 0.22235825\n",
      " 0.17782539] KL: 0.13319570521009422\n",
      "enet_b0_8_best_vgaf 10 [0.16026475 0.2311577  0.11205907 0.06098401 0.03435611 0.22828832\n",
      " 0.17289005] KL: 0.14098801226441693\n",
      "\n",
      "mbf_va 0 [0.11971077 0.30970235 0.06867396 0.12093504 0.07299717 0.16145076\n",
      " 0.14652996] KL: 0.05189005225243018\n",
      "mbf_va 1 [0.11810391 0.31421685 0.06894177 0.11963425 0.07204071 0.16183335\n",
      " 0.14522917] KL: 0.05301847794935083\n",
      "mbf_va 3 [0.11768307 0.31834876 0.06787053 0.11707093 0.06985997 0.16565919\n",
      " 0.14350754] KL: 0.05654783160962703\n",
      "mbf_va 5 [0.11542582 0.32056776 0.06878874 0.11504323 0.06787053 0.16818425\n",
      " 0.14411967] KL: 0.059441342406216104\n",
      "mbf_va 10 [0.11171474 0.32603872 0.06955391 0.10896013 0.06270564 0.17591246\n",
      " 0.14511439] KL: 0.06860542685574944\n",
      "\n",
      "enet_b0_8_mtl_abaw 0 [0.08558421 0.44341572 0.03087459 0.05157242 0.13199174 0.12254189\n",
      " 0.13401944] KL: 0.17292399535289993\n",
      "enet_b0_8_mtl_abaw 1 [0.08409213 0.44903971 0.03053026 0.04992731 0.12973449 0.12192976\n",
      " 0.13474635] KL: 0.1794588970001186\n",
      "enet_b0_8_mtl_abaw 3 [0.0857755  0.45290382 0.02945903 0.04835871 0.12740072 0.11978728\n",
      " 0.13631494] KL: 0.18491335712502185\n",
      "enet_b0_8_mtl_abaw 5 [0.086885   0.45470197 0.02972683 0.04755528 0.12491392 0.11967251\n",
      " 0.13654449] KL: 0.18489904347451083\n",
      "enet_b0_8_mtl_abaw 10 [0.08753539 0.45875736 0.02877037 0.04621624 0.1223506  0.11982554\n",
      " 0.13654449] KL: 0.1908005394564225\n",
      "\n",
      "abaw_expr_enet0_multilabel 0 [0.01886143 0.66669217 0.08684674 0.04759354 0.02310812 0.10746805\n",
      " 0.04942995] KL: 0.5043787955491499\n",
      "abaw_expr_enet0_multilabel 1 [0.01660418 0.67170403 0.0866937  0.04721096 0.02058306 0.10930446\n",
      " 0.04789961] KL: 0.5385577635611205\n",
      "abaw_expr_enet0_multilabel 3 [0.01629811 0.67725151 0.08562247 0.04686663 0.01782845 0.10915143\n",
      " 0.04698141] KL: 0.5604324215611488\n",
      "abaw_expr_enet0_multilabel 5 [0.01526513 0.68191905 0.08501033 0.04613972 0.01622159 0.10968705\n",
      " 0.04575714] KL: 0.5847762638995128\n",
      "abaw_expr_enet0_multilabel 10 [0.01319917 0.68773433 0.08462775 0.04483893 0.01293136 0.11412503\n",
      " 0.04254342] KL: 0.6387660903379659\n",
      "\n",
      "abaw_expr_enet0_multiclass 0 [0.01541817 0.56278216 0.10107889 0.03699594 0.06301171 0.12629122\n",
      " 0.09442191] KL: 0.39619224423093585\n",
      "abaw_expr_enet0_multiclass 1 [0.01515036 0.56450379 0.10111715 0.03554212 0.06044839 0.12728594\n",
      " 0.09595225] KL: 0.40521549943338553\n",
      "abaw_expr_enet0_multiclass 3 [0.014653   0.56668452 0.09889816 0.0351978  0.05857372 0.12961971\n",
      " 0.0963731 ] KL: 0.4144973048708353\n",
      "abaw_expr_enet0_multiclass 5 [0.01476777 0.56802357 0.09824776 0.03427959 0.05792333 0.13042314\n",
      " 0.09633484] KL: 0.41714911532123367\n",
      "abaw_expr_enet0_multiclass 10 [0.01254878 0.57383886 0.09759737 0.03458566 0.05612518 0.13191522\n",
      " 0.09338894] KL: 0.4455890900723122\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0 [0.03309358 0.40932742 0.15640064 0.06947739 0.05195501 0.17002066\n",
      " 0.1097253 ] KL: 0.2099599573714777\n",
      "abaw_expr_enet0_multiclass_train_val 1 [0.03236667 0.41280894 0.15773969 0.06649323 0.04889433 0.1706328\n",
      " 0.11106435] KL: 0.2208180182468055\n",
      "abaw_expr_enet0_multiclass_train_val 3 [0.03060678 0.41231158 0.16321065 0.06595761 0.04648405 0.16921723\n",
      " 0.1122121 ] KL: 0.23279597581098369\n",
      "abaw_expr_enet0_multiclass_train_val 5 [0.02965032 0.41464534 0.16497054 0.06465682 0.04395899 0.16791644\n",
      " 0.11420155] KL: 0.24303553462965136\n",
      "abaw_expr_enet0_multiclass_train_val 10 [0.02712526 0.4162522  0.16967633 0.06262912 0.04158696 0.16829903\n",
      " 0.1144311 ] KL: 0.2626211620149233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probabs_orig=freqs/freqs.sum()\n",
    "print('probabs from paper:',probabs_orig,'\\n')\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores_first(videoname2featuresAll)\n",
    "    for delta in [0,1,3,5,10]:\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            for i in range(len(compound_scores)):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "        compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "        print(model_name,delta, compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf 0.1 1 [0.16565919 0.22067488 0.10865407 0.06519244 0.04170174 0.21470656\n",
      " 0.18341113] KL: 0.1227756414265471\n",
      "enet_b0_8_best_vgaf 0.1 5 [0.17319611 0.21960364 0.10731502 0.06519244 0.0410896  0.211072\n",
      " 0.18253118] KL: 0.12259135758260675\n",
      "enet_b0_8_best_vgaf 0.1 10 [0.18107736 0.21822634 0.10593772 0.06519244 0.04074528 0.20747571\n",
      " 0.18134517] KL: 0.12229796205432589\n",
      "enet_b0_8_best_vgaf 0.1 50 [0.18107736 0.21822634 0.10593772 0.06519244 0.04074528 0.20747571\n",
      " 0.18134517] KL: 0.12229796205432589\n",
      "enet_b0_8_best_vgaf 0.1 100 [0.18107736 0.21822634 0.10593772 0.06519244 0.04074528 0.20747571\n",
      " 0.18134517] KL: 0.12229796205432589\n",
      "enet_b0_8_best_vgaf 1 1 [0.16562094 0.22189915 0.11041396 0.06312648 0.04139567 0.21585431\n",
      " 0.18168949] KL: 0.12435097208609563\n",
      "enet_b0_8_best_vgaf 1 5 [0.16562094 0.22231999 0.11106435 0.06297345 0.04112786 0.21535695\n",
      " 0.18153646] KL: 0.12451134231532626\n",
      "enet_b0_8_best_vgaf 1 10 [0.16585049 0.22254954 0.11167649 0.06297345 0.04105134 0.21459178\n",
      " 0.18130691] KL: 0.12408913049759274\n",
      "enet_b0_8_best_vgaf 1 50 [0.18406152 0.21983319 0.11033744 0.06297345 0.04013314 0.20433851\n",
      " 0.17832275] KL: 0.12200518995540861\n",
      "enet_b0_8_best_vgaf 1 100 [0.18406152 0.21983319 0.11033744 0.06297345 0.04013314 0.20433851\n",
      " 0.17832275] KL: 0.12200518995540861\n",
      "enet_b0_8_best_vgaf 10 1 [0.16608004 0.22140179 0.11087306 0.06232305 0.04151044 0.21616038\n",
      " 0.18165124] KL: 0.12507976255129055\n",
      "enet_b0_8_best_vgaf 10 5 [0.16355498 0.22473028 0.11397199 0.06075446 0.04013314 0.21784375\n",
      " 0.1790114 ] KL: 0.1276323958188236\n",
      "enet_b0_8_best_vgaf 10 10 [0.16317239 0.22488331 0.11462239 0.06067794 0.03986533 0.21738465\n",
      " 0.17939399] KL: 0.12809580329529888\n",
      "enet_b0_8_best_vgaf 10 50 [0.17185707 0.22316168 0.11492846 0.06067794 0.0390619  0.21206672\n",
      " 0.17824623] KL: 0.1273825096610101\n",
      "enet_b0_8_best_vgaf 10 100 [0.17816971 0.22316168 0.11355115 0.06067794 0.0390619  0.20927385\n",
      " 0.17610376] KL: 0.12572476787292636\n",
      "enet_b0_8_best_vgaf 50 1 [0.1661183  0.22163134 0.11102609 0.0622848  0.04147219 0.21570128\n",
      " 0.18176601] KL: 0.1249482374892615\n",
      "enet_b0_8_best_vgaf 50 5 [0.16171857 0.2277527  0.11263295 0.0600658  0.03917668 0.21937409\n",
      " 0.17927921] KL: 0.1303894883440282\n",
      "enet_b0_8_best_vgaf 50 10 [0.15716581 0.23222894 0.11389548 0.06056316 0.03623078 0.22201393\n",
      " 0.17790191] KL: 0.13582403013557234\n",
      "enet_b0_8_best_vgaf 50 50 [0.15739536 0.23176984 0.11446935 0.06014232 0.03538909 0.22105746\n",
      " 0.17977657] KL: 0.13855306589759178\n",
      "enet_b0_8_best_vgaf 50 100 [0.16060907 0.23176984 0.11335986 0.06014232 0.03542735 0.21933583\n",
      " 0.17935573] KL: 0.13746242133182074\n",
      "enet_b0_8_best_vgaf 100 1 [0.16608004 0.2216696  0.11102609 0.06224654 0.04143393 0.21573954\n",
      " 0.18180427] KL: 0.12507695829294696\n",
      "enet_b0_8_best_vgaf 100 5 [0.16148902 0.22802051 0.11244166 0.0600658  0.03864106 0.22013926\n",
      " 0.17920269] KL: 0.13175347327863546\n",
      "enet_b0_8_best_vgaf 100 10 [0.15720407 0.23356799 0.11355115 0.06037187 0.03550386 0.22342949\n",
      " 0.17637157] KL: 0.13743498662481685\n",
      "enet_b0_8_best_vgaf 100 50 [0.15337822 0.23440967 0.11481368 0.06067794 0.03121891 0.22503635\n",
      " 0.18046522] KL: 0.15041474509306124\n",
      "enet_b0_8_best_vgaf 100 100 [0.15330171 0.23440967 0.11481368 0.06067794 0.03121891 0.22358252\n",
      " 0.18199556] KL: 0.15039015796173016\n",
      "enet_b0_8_best_vgaf 500 1 [0.16615655 0.22170786 0.11094958 0.06224654 0.04139567 0.21570128\n",
      " 0.18184253] KL: 0.12514490756276153\n",
      "enet_b0_8_best_vgaf 500 5 [0.16099166 0.22802051 0.11251817 0.06018058 0.03829673 0.22082791\n",
      " 0.17916443] KL: 0.13265629403584517\n",
      "enet_b0_8_best_vgaf 500 10 [0.15647716 0.23395057 0.11370419 0.06106052 0.03412656 0.22407988\n",
      " 0.17660112] KL: 0.1403904932802268\n",
      "enet_b0_8_best_vgaf 500 50 [0.13329252 0.25063126 0.11917515 0.05987451 0.0300329  0.23035427\n",
      " 0.17663938] KL: 0.15553463666392298\n",
      "enet_b0_8_best_vgaf 500 100 [0.12958145 0.25265896 0.11856301 0.05987451 0.0300329  0.23134899\n",
      " 0.17794016] KL: 0.15723912109927163\n",
      "enet_b0_8_best_vgaf 1000 1 [0.16615655 0.2216696  0.11091132 0.0622848  0.04143393 0.21570128\n",
      " 0.18184253] KL: 0.12505354475636193\n",
      "enet_b0_8_best_vgaf 1000 5 [0.16091514 0.22813528 0.11259469 0.06014232 0.03822022 0.22086617\n",
      " 0.17912618] KL: 0.13282217588535672\n",
      "enet_b0_8_best_vgaf 1000 10 [0.15678323 0.2342949  0.11309205 0.06094575 0.03401178 0.22476854\n",
      " 0.17610376] KL: 0.14086485923934072\n",
      "enet_b0_8_best_vgaf 1000 50 [0.12866325 0.26195577 0.11603795 0.05742597 0.02750784 0.23421838\n",
      " 0.17419083] KL: 0.16685403931477794\n",
      "enet_b0_8_best_vgaf 1000 100 [0.12273319 0.26631724 0.11661183 0.05723468 0.02697222 0.23639911\n",
      " 0.17373173] KL: 0.17116589953300743\n",
      "enet_b0_8_best_vgaf 10000 1 [0.16615655 0.2216696  0.11091132 0.0622848  0.04143393 0.21570128\n",
      " 0.18184253] KL: 0.12505354475636193\n",
      "enet_b0_8_best_vgaf 10000 5 [0.16083863 0.22813528 0.11251817 0.06014232 0.03810544 0.22109572\n",
      " 0.17916443] KL: 0.13319296306025724\n",
      "enet_b0_8_best_vgaf 10000 10 [0.15655368 0.23418012 0.11293902 0.06098401 0.03416482 0.2252659\n",
      " 0.17591246] KL: 0.1406577534331578\n",
      "enet_b0_8_best_vgaf 10000 50 [0.12476088 0.26918662 0.11902211 0.0521463  0.02322289 0.24014844\n",
      " 0.17151274] KL: 0.1910757144711514\n",
      "enet_b0_8_best_vgaf 10000 100 [0.1137807  0.28957839 0.11577014 0.05195501 0.01771367 0.2442421\n",
      " 0.16695998] KL: 0.221750452329632\n",
      "enet_b0_8_best_vgaf 100000 1 [0.16615655 0.2216696  0.11091132 0.06224654 0.04143393 0.21570128\n",
      " 0.18188079] KL: 0.12510523923533728\n",
      "enet_b0_8_best_vgaf 100000 5 [0.16083863 0.22813528 0.11251817 0.06014232 0.03810544 0.22105746\n",
      " 0.17920269] KL: 0.1331913500749103\n",
      "enet_b0_8_best_vgaf 100000 10 [0.15655368 0.23414186 0.11282424 0.06098401 0.03420308 0.22534241\n",
      " 0.17595072] KL: 0.14063423302422426\n",
      "enet_b0_8_best_vgaf 100000 50 [0.12453133 0.26853623 0.11909863 0.05206978 0.02329941 0.24102839\n",
      " 0.17143622] KL: 0.19138454034238778\n",
      "enet_b0_8_best_vgaf 100000 100 [0.11087306 0.29305991 0.11603795 0.05130461 0.01744586 0.24466294\n",
      " 0.16661566] KL: 0.2255895791375443\n",
      "\n",
      "mbf_va 0.1 1 [0.11967251 0.30989364 0.06859744 0.12093504 0.07280588 0.16152728\n",
      " 0.14656821] KL: 0.05213130242296632\n",
      "mbf_va 0.1 5 [0.12946668 0.30472875 0.06825312 0.12085852 0.07070166 0.16018823\n",
      " 0.14580305] KL: 0.049728597105608265\n",
      "mbf_va 0.1 10 [0.13998776 0.29914301 0.06767924 0.12074374 0.06886525 0.15861963\n",
      " 0.14496136] KL: 0.04819610661046947\n",
      "mbf_va 0.1 50 [0.13998776 0.29914301 0.06767924 0.12074374 0.06886525 0.15861963\n",
      " 0.14496136] KL: 0.04819610661046947\n",
      "mbf_va 0.1 100 [0.13998776 0.29914301 0.06767924 0.12074374 0.06886525 0.15861963\n",
      " 0.14496136] KL: 0.04819610661046947\n",
      "mbf_va 1 1 [0.11810391 0.31387252 0.06920958 0.11967251 0.07188767 0.1618716\n",
      " 0.1453822 ] KL: 0.05293857128694523\n",
      "mbf_va 1 5 [0.11772133 0.31414033 0.06955391 0.11963425 0.07150509 0.1618716\n",
      " 0.14557349] KL: 0.05316076593420601\n",
      "mbf_va 1 10 [0.11886908 0.31314561 0.06940087 0.11963425 0.07127554 0.16210116\n",
      " 0.14557349] KL: 0.052963144959649315\n",
      "mbf_va 1 50 [0.14174765 0.30335144 0.06767924 0.11963425 0.06691407 0.15796924\n",
      " 0.14270411] KL: 0.04878677033118011\n",
      "mbf_va 1 100 [0.14174765 0.30335144 0.06767924 0.11963425 0.06691407 0.15796924\n",
      " 0.14270411] KL: 0.04878677033118011\n",
      "mbf_va 10 1 [0.11837172 0.31417859 0.068827   0.11963425 0.07158161 0.1620629\n",
      " 0.14534394] KL: 0.05339812819337562\n",
      "mbf_va 10 5 [0.11760655 0.31842528 0.0681766  0.11687964 0.06836789 0.16600352\n",
      " 0.14454052] KL: 0.05782213671011048\n",
      "mbf_va 10 10 [0.11733874 0.31811921 0.06810008 0.11684138 0.06829138 0.16661566\n",
      " 0.14469355] KL: 0.058239204310583874\n",
      "mbf_va 10 50 [0.12954319 0.30935802 0.06741143 0.11684138 0.06672278 0.16680695\n",
      " 0.14331624] KL: 0.05485228090732964\n",
      "mbf_va 10 100 [0.13884    0.30308363 0.06603413 0.11684138 0.06507766 0.16680695\n",
      " 0.14331624] KL: 0.054795865060071315\n",
      "mbf_va 50 1 [0.11833346 0.31433162 0.06905655 0.11951947 0.07139031 0.16190986\n",
      " 0.14545872] KL: 0.05337143024762756\n",
      "mbf_va 50 5 [0.11630576 0.31980259 0.06859744 0.11538756 0.06756447 0.16776341\n",
      " 0.14457877] KL: 0.059361414630351154\n",
      "mbf_va 50 10 [0.11305379 0.32205984 0.06894177 0.11358941 0.06400643 0.17285179\n",
      " 0.14549698] KL: 0.06555261256488912\n",
      "mbf_va 50 50 [0.11182952 0.32427883 0.06940087 0.11236514 0.06251435 0.17453516\n",
      " 0.14507613] KL: 0.0678352942073583\n",
      "mbf_va 50 100 [0.1167266  0.32106512 0.06829138 0.11236514 0.06194047 0.17453516\n",
      " 0.14507613] KL: 0.06672720704780573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va 100 1 [0.1182952  0.31429337 0.06905655 0.11948122 0.07150509 0.16190986\n",
      " 0.14545872] KL: 0.05330704005229459\n",
      "mbf_va 100 5 [0.11611447 0.31949652 0.06886525 0.11515801 0.06733491 0.16822251\n",
      " 0.14480833] KL: 0.05959337826933566\n",
      "mbf_va 100 10 [0.11225036 0.32355192 0.06878874 0.11117913 0.06232305 0.17522381\n",
      " 0.14668299] KL: 0.0689947805008686\n",
      "mbf_va 100 50 [0.10976356 0.32871681 0.07234677 0.10758283 0.05750249 0.17797842\n",
      " 0.14610911] KL: 0.07409239328740878\n",
      "mbf_va 100 100 [0.10980182 0.32867855 0.07234677 0.10758283 0.05750249 0.17797842\n",
      " 0.14610911] KL: 0.0740687612656311\n",
      "mbf_va 500 1 [0.11825694 0.31436988 0.06901829 0.11963425 0.07150509 0.16179509\n",
      " 0.14542046] KL: 0.053312269882119644\n",
      "mbf_va 500 5 [0.11584666 0.31953478 0.06890351 0.1153493  0.06733491 0.16829903\n",
      " 0.14473181] KL: 0.059668940568054295\n",
      "mbf_va 500 10 [0.1119443  0.3234754  0.06982172 0.10984008 0.06232305 0.17671589\n",
      " 0.14587956] KL: 0.06873527546948524\n",
      "mbf_va 500 50 [0.10176754 0.34421149 0.07341801 0.09993113 0.04744051 0.19213406\n",
      " 0.14109725] KL: 0.0977217336018309\n",
      "mbf_va 500 100 [0.10050501 0.34478537 0.07349453 0.09996939 0.04537455 0.19358788\n",
      " 0.14228327] KL: 0.1026170027267154\n",
      "mbf_va 1000 1 [0.11825694 0.31440814 0.06898003 0.11963425 0.07150509 0.16179509\n",
      " 0.14542046] KL: 0.05334488624226546\n",
      "mbf_va 1000 5 [0.1158084  0.31938174 0.06901829 0.11538756 0.0672584  0.1684138\n",
      " 0.14473181] KL: 0.05967250677367716\n",
      "mbf_va 1000 10 [0.11190604 0.32389624 0.06982172 0.10964879 0.06224654 0.17694544\n",
      " 0.14553524] KL: 0.06886684054940245\n",
      "mbf_va 1000 50 [0.09537838 0.34941465 0.07487183 0.09943377 0.04659882 0.19756676\n",
      " 0.13673579] KL: 0.10425415029960594\n",
      "mbf_va 1000 100 [0.09197337 0.34769301 0.0758283  0.10008417 0.04621624 0.20097177\n",
      " 0.13723315] KL: 0.10784007938978446\n",
      "mbf_va 10000 1 [0.11821869 0.31440814 0.06898003 0.11963425 0.07154335 0.16179509\n",
      " 0.14542046] KL: 0.05333424200737041\n",
      "mbf_va 10000 5 [0.11592318 0.31926697 0.06890351 0.11531104 0.0672584  0.16852858\n",
      " 0.14480833] KL: 0.05976179090780836\n",
      "mbf_va 10000 10 [0.11167649 0.32424057 0.06989823 0.10949575 0.06232305 0.17706022\n",
      " 0.14530569] KL: 0.06887517471777305\n",
      "mbf_va 10000 50 [0.09136124 0.35572729 0.0758283  0.10012243 0.04415028 0.20062744\n",
      " 0.13218303] KL: 0.11177378149583178\n",
      "mbf_va 10000 100 [0.08030454 0.35894101 0.07640217 0.09687046 0.04319382 0.21325274\n",
      " 0.13103527] KL: 0.12949485383333606\n",
      "mbf_va 100000 1 [0.11821869 0.31440814 0.06898003 0.11963425 0.07154335 0.16179509\n",
      " 0.14542046] KL: 0.05333424200737041\n",
      "mbf_va 100000 5 [0.11596144 0.31926697 0.06890351 0.11531104 0.06722014 0.16852858\n",
      " 0.14480833] KL: 0.0597753871741497\n",
      "mbf_va 100000 10 [0.11163823 0.32435534 0.06985997 0.10961053 0.06213176 0.17706022\n",
      " 0.14534394] KL: 0.06910703860108458\n",
      "mbf_va 100000 50 [0.0893718  0.35714286 0.07624914 0.09981636 0.04491545 0.20009182\n",
      " 0.13241258] KL: 0.11202391348328719\n",
      "mbf_va 100000 100 [0.07548397 0.36211646 0.0767465  0.09985462 0.04464764 0.21233453\n",
      " 0.12881628] KL: 0.13115690820108056\n",
      "\n",
      "enet_b0_8_mtl_abaw 0.1 1 [0.08535466 0.44368353 0.03091285 0.05153416 0.13191522 0.12269493\n",
      " 0.13390466] KL: 0.17313873901431887\n",
      "enet_b0_8_mtl_abaw 0.1 5 [0.09472798 0.44008723 0.03079807 0.0512281  0.13099702 0.12082026\n",
      " 0.13134134] KL: 0.16430199466339906\n",
      "enet_b0_8_mtl_abaw 0.1 10 [0.10456041 0.43610835 0.03079807 0.0510368  0.12992578 0.11821869\n",
      " 0.1293519 ] KL: 0.1563473565959744\n",
      "enet_b0_8_mtl_abaw 0.1 50 [0.10456041 0.43610835 0.03079807 0.0510368  0.12992578 0.11821869\n",
      " 0.1293519 ] KL: 0.1563473565959744\n",
      "enet_b0_8_mtl_abaw 0.1 100 [0.10456041 0.43610835 0.03079807 0.0510368  0.12992578 0.11821869\n",
      " 0.1293519 ] KL: 0.1563473565959744\n",
      "enet_b0_8_mtl_abaw 1 1 [0.08413038 0.44724156 0.03060678 0.05038641 0.13015533 0.12238886\n",
      " 0.13509067] KL: 0.17806659413623985\n",
      "enet_b0_8_mtl_abaw 1 5 [0.08386258 0.44747111 0.0306833  0.05019512 0.1304614  0.12307751\n",
      " 0.13424899] KL: 0.1782971511962418\n",
      "enet_b0_8_mtl_abaw 1 10 [0.08546943 0.44697375 0.03102762 0.05019512 0.13030836 0.12208279\n",
      " 0.13394292] KL: 0.17550584494785598\n",
      "enet_b0_8_mtl_abaw 1 50 [0.10819497 0.43848037 0.03102762 0.04954472 0.12870151 0.11397199\n",
      " 0.13007881] KL: 0.15664361781971758\n",
      "enet_b0_8_mtl_abaw 1 100 [0.10819497 0.43848037 0.03102762 0.04954472 0.12870151 0.11397199\n",
      " 0.13007881] KL: 0.15664361781971758\n",
      "enet_b0_8_mtl_abaw 10 1 [0.08393909 0.4494223  0.03060678 0.05000383 0.12946668 0.12223583\n",
      " 0.1343255 ] KL: 0.17930396600011794\n",
      "enet_b0_8_mtl_abaw 10 5 [0.08558421 0.45336292 0.02995639 0.04835871 0.12766853 0.12066723\n",
      " 0.13440202] KL: 0.18331718534641478\n",
      "enet_b0_8_mtl_abaw 10 10 [0.08615808 0.45317163 0.03010942 0.04828219 0.12747724 0.12016987\n",
      " 0.13463157] KL: 0.1824124942063033\n",
      "enet_b0_8_mtl_abaw 10 50 [0.09801821 0.44953707 0.03010942 0.04755528 0.12541128 0.11305379\n",
      " 0.13631494] KL: 0.1733108909377917\n",
      "enet_b0_8_mtl_abaw 10 100 [0.10310659 0.44850409 0.03010942 0.04617798 0.12541128 0.1103757\n",
      " 0.13631494] KL: 0.1719963965353491\n",
      "enet_b0_8_mtl_abaw 50 1 [0.08393909 0.44934578 0.03060678 0.04996557 0.12961971 0.12208279\n",
      " 0.13444028] KL: 0.17935959720434305\n",
      "enet_b0_8_mtl_abaw 50 5 [0.08569898 0.45554365 0.03030071 0.04755528 0.1257556  0.11990206\n",
      " 0.13524371] KL: 0.18424780298148064\n",
      "enet_b0_8_mtl_abaw 50 10 [0.08730584 0.45925472 0.02922947 0.04667534 0.12296274 0.11860127\n",
      " 0.13597062] KL: 0.18884917280236968\n",
      "enet_b0_8_mtl_abaw 50 50 [0.09151427 0.45952253 0.02915296 0.04667534 0.12135588 0.1137807\n",
      " 0.13799832] KL: 0.1861963565684145\n",
      "enet_b0_8_mtl_abaw 50 100 [0.09361849 0.46032596 0.02915296 0.04552758 0.12135588 0.1119443\n",
      " 0.13807483] KL: 0.18677830510579868\n",
      "enet_b0_8_mtl_abaw 100 1 [0.08401561 0.44938404 0.03060678 0.04996557 0.12954319 0.12204453\n",
      " 0.13444028] KL: 0.17929434154838006\n",
      "enet_b0_8_mtl_abaw 100 5 [0.08589027 0.45569669 0.02999464 0.04755528 0.12533476 0.12001683\n",
      " 0.13551152] KL: 0.1850998724872518\n",
      "enet_b0_8_mtl_abaw 100 10 [0.08719106 0.45963731 0.02942077 0.0465223  0.12219757 0.11775958\n",
      " 0.13727141] KL: 0.1890276754956579\n",
      "enet_b0_8_mtl_abaw 100 50 [0.09051955 0.46373097 0.02972683 0.04648405 0.12005509 0.11393374\n",
      " 0.13554977] KL: 0.18645272980725736\n",
      "enet_b0_8_mtl_abaw 100 100 [0.09051955 0.46503175 0.02972683 0.04640753 0.12005509 0.11267121\n",
      " 0.13558803] KL: 0.1870939968727024\n",
      "enet_b0_8_mtl_abaw 500 1 [0.08397735 0.44938404 0.03060678 0.04988905 0.12958145 0.12204453\n",
      " 0.1345168 ] KL: 0.17945733805677838\n",
      "enet_b0_8_mtl_abaw 500 5 [0.08604331 0.45581146 0.03007116 0.04751703 0.12499044 0.11994032\n",
      " 0.13562629] KL: 0.18484541530605675\n",
      "enet_b0_8_mtl_abaw 500 10 [0.08722932 0.45986686 0.02991813 0.04656056 0.12246538 0.11795088\n",
      " 0.13600888] KL: 0.18719295662407004\n",
      "enet_b0_8_mtl_abaw 500 50 [0.08275308 0.48041166 0.03095111 0.04503022 0.11270947 0.11492846\n",
      " 0.13321601] KL: 0.1980768298365246\n",
      "enet_b0_8_mtl_abaw 500 100 [0.08003673 0.48377841 0.03091285 0.04503022 0.11247991 0.11500497\n",
      " 0.13275691] KL: 0.20213924808814773\n",
      "enet_b0_8_mtl_abaw 1000 1 [0.08397735 0.44938404 0.03060678 0.04988905 0.12958145 0.12204453\n",
      " 0.1345168 ] KL: 0.17945733805677838\n",
      "enet_b0_8_mtl_abaw 1000 5 [0.08589027 0.45592624 0.0300329  0.04751703 0.12506695 0.12005509\n",
      " 0.13551152] KL: 0.18511741500227083\n",
      "enet_b0_8_mtl_abaw 1000 10 [0.08730584 0.46044074 0.02991813 0.04656056 0.12231234 0.11753003\n",
      " 0.13593236] KL: 0.18731005863928563\n",
      "enet_b0_8_mtl_abaw 1000 50 [0.08451297 0.48527049 0.02766088 0.04591017 0.10762109 0.11531104\n",
      " 0.13371337] KL: 0.2077222430879293\n",
      "enet_b0_8_mtl_abaw 1000 100 [0.08087841 0.490971   0.02762262 0.04675186 0.1058612  0.11454587\n",
      " 0.13336904] KL: 0.21247950399666382\n",
      "enet_b0_8_mtl_abaw 10000 1 [0.08397735 0.44938404 0.03060678 0.04988905 0.12958145 0.12204453\n",
      " 0.1345168 ] KL: 0.17945733805677838\n",
      "enet_b0_8_mtl_abaw 10000 5 [0.08581376 0.45584972 0.03007116 0.04755528 0.12514347 0.12001683\n",
      " 0.13554977] KL: 0.18499609739113265\n",
      "enet_b0_8_mtl_abaw 10000 10 [0.0871528  0.46063203 0.02987987 0.04656056 0.12261841 0.11741526\n",
      " 0.13574107] KL: 0.18758513776691574\n",
      "enet_b0_8_mtl_abaw 10000 50 [0.08455123 0.4848879  0.02502104 0.04820568 0.10984008 0.11768307\n",
      " 0.129811  ] KL: 0.2123448993386464\n",
      "enet_b0_8_mtl_abaw 10000 100 [0.07869768 0.47685362 0.02337593 0.05206978 0.10938098 0.13574107\n",
      " 0.12388094] KL: 0.2165673863687664\n",
      "enet_b0_8_mtl_abaw 100000 1 [0.08397735 0.44938404 0.03060678 0.04988905 0.12958145 0.12204453\n",
      " 0.1345168 ] KL: 0.17945733805677838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_mtl_abaw 100000 5 [0.0857755  0.45592624 0.03007116 0.04751703 0.12514347 0.12001683\n",
      " 0.13554977] KL: 0.1851159249200785\n",
      "enet_b0_8_mtl_abaw 100000 10 [0.08711455 0.46067029 0.02987987 0.04648405 0.12265667 0.11741526\n",
      " 0.13577933] KL: 0.1877620977830951\n",
      "enet_b0_8_mtl_abaw 100000 50 [0.08462775 0.48374015 0.0246002  0.04835871 0.11060525 0.11798913\n",
      " 0.13007881] KL: 0.2132022911467052\n",
      "enet_b0_8_mtl_abaw 100000 100 [0.07659347 0.47478767 0.02245772 0.05329405 0.11347463 0.13738618\n",
      " 0.12200627] KL: 0.22001049239863715\n",
      "\n",
      "abaw_expr_enet0_multilabel 0.1 1 [0.01878491 0.66642436 0.08699977 0.04759354 0.0230316  0.10754457\n",
      " 0.04962124] KL: 0.5048572412904802\n",
      "abaw_expr_enet0_multilabel 0.1 5 [0.01863188 0.66558268 0.08757365 0.0476318  0.02284031 0.10773586\n",
      " 0.05000383] KL: 0.5056538203777332\n",
      "abaw_expr_enet0_multilabel 0.1 10 [0.0185171  0.66508532 0.08772668 0.04774658 0.02284031 0.10785064\n",
      " 0.05023338] KL: 0.5057870618542364\n",
      "abaw_expr_enet0_multilabel 0.1 50 [0.0185171  0.66508532 0.08772668 0.04774658 0.02284031 0.10785064\n",
      " 0.05023338] KL: 0.5057870618542364\n",
      "abaw_expr_enet0_multilabel 0.1 100 [0.0185171  0.66508532 0.08772668 0.04774658 0.02284031 0.10785064\n",
      " 0.05023338] KL: 0.5057870618542364\n",
      "abaw_expr_enet0_multilabel 1 1 [0.01679547 0.67082409 0.08627286 0.04740225 0.02073609 0.10911317\n",
      " 0.04885607] KL: 0.5345798347664037\n",
      "abaw_expr_enet0_multilabel 1 5 [0.01645114 0.67047976 0.08684674 0.04736399 0.02016222 0.10949575\n",
      " 0.0492004 ] KL: 0.5395304715408419\n",
      "abaw_expr_enet0_multilabel 1 10 [0.01625985 0.66986763 0.08707629 0.04747877 0.02016222 0.10964879\n",
      " 0.04950647] KL: 0.5402871025834706\n",
      "abaw_expr_enet0_multilabel 1 50 [0.01560946 0.66929375 0.08803275 0.04747877 0.02016222 0.10980182\n",
      " 0.04962124] KL: 0.5453656348575113\n",
      "abaw_expr_enet0_multilabel 1 100 [0.01560946 0.66929375 0.08803275 0.04747877 0.02016222 0.10980182\n",
      " 0.04962124] KL: 0.5453656348575113\n",
      "abaw_expr_enet0_multilabel 10 1 [0.01645114 0.67135971 0.08684674 0.04732573 0.02039177 0.10949575\n",
      " 0.04812916] KL: 0.5401072961772198\n",
      "abaw_expr_enet0_multilabel 10 5 [0.01591553 0.67575943 0.08661719 0.04682837 0.0171398  0.11026092\n",
      " 0.04747877] KL: 0.5659859210372991\n",
      "abaw_expr_enet0_multilabel 10 10 [0.01530339 0.6756064  0.08696151 0.04686663 0.01725457 0.11045222\n",
      " 0.04755528] KL: 0.570621419002002\n",
      "abaw_expr_enet0_multilabel 10 50 [0.01449996 0.67507078 0.08795623 0.04686663 0.01725457 0.1103757\n",
      " 0.04797613] KL: 0.5773204248473365\n",
      "abaw_expr_enet0_multilabel 10 100 [0.01449996 0.67507078 0.08795623 0.04686663 0.01725457 0.1103757\n",
      " 0.04797613] KL: 0.5773204248473365\n",
      "abaw_expr_enet0_multilabel 50 1 [0.0164894  0.67128319 0.08684674 0.04732573 0.02046828 0.10949575\n",
      " 0.0480909 ] KL: 0.539408406283238\n",
      "abaw_expr_enet0_multilabel 50 5 [0.01534165 0.67862882 0.08661719 0.04644579 0.01625985 0.11056699\n",
      " 0.04613972] KL: 0.5803085200974741\n",
      "abaw_expr_enet0_multilabel 50 10 [0.01388783 0.68272247 0.08562247 0.04548933 0.0149208  0.11408677\n",
      " 0.04327033] KL: 0.611234499087447\n",
      "abaw_expr_enet0_multilabel 50 50 [0.01235749 0.68394674 0.08489555 0.04533629 0.01457648 0.11634402\n",
      " 0.04254342] KL: 0.6330262349761193\n",
      "abaw_expr_enet0_multilabel 50 100 [0.01235749 0.68394674 0.08435994 0.04533629 0.01457648 0.11687964\n",
      " 0.04254342] KL: 0.6332674455802421\n",
      "abaw_expr_enet0_multilabel 100 1 [0.01645114 0.67135971 0.08684674 0.04728747 0.02046828 0.10945749\n",
      " 0.04812916] KL: 0.5398047485432507\n",
      "abaw_expr_enet0_multilabel 100 5 [0.01534165 0.67954702 0.08650241 0.04644579 0.01580075 0.11075828\n",
      " 0.0456041 ] KL: 0.5843895988354744\n",
      "abaw_expr_enet0_multilabel 100 10 [0.0135435  0.68440585 0.08562247 0.04533629 0.01404086 0.11454587\n",
      " 0.04250516] KL: 0.6233638002491975\n",
      "abaw_expr_enet0_multilabel 100 50 [0.01136277 0.68727523 0.08646415 0.04437983 0.01289311 0.11814217\n",
      " 0.03948275] KL: 0.6653764722761788\n",
      "abaw_expr_enet0_multilabel 100 100 [0.01136277 0.68727523 0.08527814 0.04437983 0.01289311 0.11932818\n",
      " 0.03948275] KL: 0.6659067369423893\n",
      "abaw_expr_enet0_multilabel 500 1 [0.01645114 0.67139796 0.08684674 0.04724922 0.02046828 0.10941924\n",
      " 0.04816742] KL: 0.5398453933458035\n",
      "abaw_expr_enet0_multilabel 500 5 [0.01549468 0.68004438 0.08638763 0.0462545  0.01568597 0.11052873\n",
      " 0.0456041 ] KL: 0.5843275026454127\n",
      "abaw_expr_enet0_multilabel 500 10 [0.01350524 0.68532405 0.086885   0.04499197 0.01293136 0.11481368\n",
      " 0.0415487 ] KL: 0.6341764297064675\n",
      "abaw_expr_enet0_multilabel 500 50 [0.00834035 0.69439131 0.08814752 0.04591017 0.01281659 0.11779784\n",
      " 0.03259622] KL: 0.7255707247685332\n",
      "abaw_expr_enet0_multilabel 500 100 [0.00834035 0.69565384 0.08711455 0.04591017 0.01296962 0.11768307\n",
      " 0.03232841] KL: 0.7260122352172569\n",
      "abaw_expr_enet0_multilabel 1000 1 [0.01645114 0.67139796 0.08684674 0.04724922 0.02046828 0.10941924\n",
      " 0.04816742] KL: 0.5398453933458035\n",
      "abaw_expr_enet0_multilabel 1000 5 [0.01549468 0.67996786 0.08642589 0.04621624 0.01568597 0.11060525\n",
      " 0.0456041 ] KL: 0.5843256682506521\n",
      "abaw_expr_enet0_multilabel 1000 10 [0.01335221 0.68513276 0.08722932 0.04506848 0.01289311 0.11477542\n",
      " 0.0415487 ] KL: 0.6357870907848503\n",
      "abaw_expr_enet0_multilabel 1000 50 [0.00879945 0.69530951 0.08933354 0.0462545  0.01293136 0.11607621\n",
      " 0.03129543] KL: 0.7187713251109482\n",
      "abaw_expr_enet0_multilabel 1000 100 [0.00864642 0.69867626 0.08761191 0.04617798 0.01384957 0.11603795\n",
      " 0.02899992] KL: 0.7222865921583963\n",
      "abaw_expr_enet0_multilabel 10000 1 [0.01645114 0.67139796 0.08684674 0.04724922 0.02046828 0.10941924\n",
      " 0.04816742] KL: 0.5398453933458035\n",
      "abaw_expr_enet0_multilabel 10000 5 [0.0155712  0.6799296  0.08646415 0.0462545  0.01564772 0.11052873\n",
      " 0.0456041 ] KL: 0.5837652792248258\n",
      "abaw_expr_enet0_multilabel 10000 10 [0.01327569 0.68532405 0.0871528  0.04506848 0.01274007 0.11473716\n",
      " 0.04170174] KL: 0.6378030634994265\n",
      "abaw_expr_enet0_multilabel 10000 50 [0.00860816 0.6950417  0.08960135 0.0440355  0.01381131 0.11898385\n",
      " 0.02991813] KL: 0.7218013034950871\n",
      "abaw_expr_enet0_multilabel 10000 100 [0.00665697 0.70770526 0.09250899 0.04047747 0.01270181 0.11825694\n",
      " 0.02169255] KL: 0.806112856604629\n",
      "abaw_expr_enet0_multilabel 100000 1 [0.01645114 0.67139796 0.08684674 0.04724922 0.02046828 0.10941924\n",
      " 0.04816742] KL: 0.5398453933458035\n",
      "abaw_expr_enet0_multilabel 100000 5 [0.0155712  0.67989135 0.08650241 0.0462545  0.01564772 0.11049047\n",
      " 0.04564236] KL: 0.5836843178077078\n",
      "abaw_expr_enet0_multilabel 100000 10 [0.01323743 0.68543882 0.08711455 0.04503022 0.01270181 0.11477542\n",
      " 0.04170174] KL: 0.6386845039366321\n",
      "abaw_expr_enet0_multilabel 100000 50 [0.00830209 0.69446782 0.09082562 0.04342337 0.01449996 0.11909863\n",
      " 0.02938251] KL: 0.7238406398106776\n",
      "abaw_expr_enet0_multilabel 100000 100 [0.00570051 0.72124876 0.08611983 0.03883235 0.00799602 0.12269493\n",
      " 0.01740761] KL: 0.9106272423789796\n",
      "\n",
      "abaw_expr_enet0_multiclass 0.1 1 [0.01549468 0.56266738 0.10119366 0.03699594 0.06312648 0.12625297\n",
      " 0.09426888] KL: 0.395302234890641\n",
      "abaw_expr_enet0_multiclass 0.1 5 [0.01564772 0.56186395 0.10172928 0.03707246 0.06297345 0.12632948\n",
      " 0.09438366] KL: 0.3933464673826946\n",
      "abaw_expr_enet0_multiclass 0.1 10 [0.01576249 0.56102227 0.1022649  0.03711072 0.06285867 0.12659729\n",
      " 0.09438366] KL: 0.3918183518592018\n",
      "abaw_expr_enet0_multiclass 0.1 50 [0.01576249 0.56102227 0.1022649  0.03711072 0.06285867 0.12659729\n",
      " 0.09438366] KL: 0.3918183518592018\n",
      "abaw_expr_enet0_multiclass 0.1 100 [0.01576249 0.56102227 0.1022649  0.03711072 0.06285867 0.12659729\n",
      " 0.09438366] KL: 0.3918183518592018\n",
      "abaw_expr_enet0_multiclass 1 1 [0.01515036 0.56377688 0.10169102 0.03630729 0.06132833 0.12663555\n",
      " 0.09511057] KL: 0.4021402402170907\n",
      "abaw_expr_enet0_multiclass 1 5 [0.01507384 0.56308822 0.10215013 0.03634555 0.06079272 0.12717117\n",
      " 0.09537838] KL: 0.4028999162963621\n",
      "abaw_expr_enet0_multiclass 1 10 [0.0151121  0.56178744 0.1029153  0.03638381 0.06079272 0.12759201\n",
      " 0.09541663] KL: 0.4017083485862502\n",
      "abaw_expr_enet0_multiclass 1 50 [0.01407912 0.56106052 0.10406305 0.03638381 0.06090749 0.12839544\n",
      " 0.09511057] KL: 0.41146036659185387\n",
      "abaw_expr_enet0_multiclass 1 100 [0.01407912 0.56106052 0.10406305 0.03638381 0.06090749 0.12839544\n",
      " 0.09511057] KL: 0.41146036659185387\n",
      "abaw_expr_enet0_multiclass 10 1 [0.01515036 0.56427424 0.10146147 0.03558038 0.06067794 0.12717117\n",
      " 0.09568444] KL: 0.40472879100435855\n",
      "abaw_expr_enet0_multiclass 10 5 [0.01472951 0.56607239 0.09954855 0.03554212 0.05780855 0.12954319\n",
      " 0.09675568] KL: 0.41324379820493423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaw_expr_enet0_multiclass 10 10 [0.01453822 0.56480986 0.10016069 0.03546561 0.05773204 0.1304614\n",
      " 0.0968322 ] KL: 0.4147588413152445\n",
      "abaw_expr_enet0_multiclass 10 50 [0.01319917 0.56446553 0.10169102 0.03546561 0.05715816 0.13134134\n",
      " 0.09667916] KL: 0.4291419157686645\n",
      "abaw_expr_enet0_multiclass 10 100 [0.01323743 0.56572806 0.10169102 0.03546561 0.05715816 0.13130308\n",
      " 0.09541663] KL: 0.42938746300043756\n",
      "abaw_expr_enet0_multiclass 50 1 [0.01518861 0.5643125  0.1013467  0.03554212 0.06063968 0.12720943\n",
      " 0.09576096] KL: 0.4045298027921179\n",
      "abaw_expr_enet0_multiclass 50 5 [0.01472951 0.56622542 0.09966333 0.03458566 0.05807636 0.12984926\n",
      " 0.09687046] KL: 0.415324962040657\n",
      "abaw_expr_enet0_multiclass 50 10 [0.01392608 0.56955391 0.09939552 0.03462392 0.05723468 0.13164741\n",
      " 0.09361849] KL: 0.4263912796329307\n",
      "abaw_expr_enet0_multiclass 50 50 [0.01277833 0.57043385 0.1002372  0.03462392 0.05505394 0.13275691\n",
      " 0.09411585] KL: 0.44178887334977734\n",
      "abaw_expr_enet0_multiclass 50 100 [0.01277833 0.57169638 0.1002372  0.03462392 0.05474788 0.13275691\n",
      " 0.09315938] KL: 0.44283352453187724\n",
      "abaw_expr_enet0_multiclass 100 1 [0.01518861 0.56442727 0.10119366 0.03561864 0.06063968 0.12713291\n",
      " 0.09579922] KL: 0.4044288739490287\n",
      "abaw_expr_enet0_multiclass 100 5 [0.01461474 0.56626368 0.09970158 0.03466218 0.05815288 0.12988752\n",
      " 0.09671742] KL: 0.41622037687176705\n",
      "abaw_expr_enet0_multiclass 100 10 [0.01339047 0.57058688 0.09973984 0.03485347 0.05677558 0.1309205\n",
      " 0.09373326] KL: 0.432413144111005\n",
      "abaw_expr_enet0_multiclass 100 50 [0.01155406 0.57387711 0.09996939 0.03370572 0.05432703 0.13313949\n",
      " 0.09342719] KL: 0.4616747480110351\n",
      "abaw_expr_enet0_multiclass 100 100 [0.01155406 0.57510138 0.09996939 0.03370572 0.05402097 0.13313949\n",
      " 0.09250899] KL: 0.4627169088788989\n",
      "abaw_expr_enet0_multiclass 500 1 [0.01518861 0.56446553 0.10119366 0.03558038 0.06063968 0.12713291\n",
      " 0.09579922] KL: 0.4045367645574877\n",
      "abaw_expr_enet0_multiclass 500 5 [0.01457648 0.56649323 0.09970158 0.03466218 0.05803811 0.129811\n",
      " 0.09671742] KL: 0.4168243261891424\n",
      "abaw_expr_enet0_multiclass 500 10 [0.01266355 0.57135205 0.10119366 0.03470044 0.05639299 0.13069095\n",
      " 0.09300635] KL: 0.44151328324391065\n",
      "abaw_expr_enet0_multiclass 500 50 [0.00826383 0.57479532 0.10968705 0.03045375 0.05264366 0.13126483\n",
      " 0.09289158] KL: 0.5215472999458143\n",
      "abaw_expr_enet0_multiclass 500 100 [0.00834035 0.57644043 0.10968705 0.03045375 0.05229933 0.13115005\n",
      " 0.09162905] KL: 0.5214933565955828\n",
      "abaw_expr_enet0_multiclass 1000 1 [0.01518861 0.56446553 0.10119366 0.03558038 0.06063968 0.12713291\n",
      " 0.09579922] KL: 0.4045367645574877\n",
      "abaw_expr_enet0_multiclass 1000 5 [0.01457648 0.5667993  0.09939552 0.03466218 0.05792333 0.1300023\n",
      " 0.09664091] KL: 0.4171861888463314\n",
      "abaw_expr_enet0_multiclass 1000 10 [0.01251052 0.57146683 0.10130844 0.03466218 0.05650777 0.13084398\n",
      " 0.09270028] KL: 0.4433531696757861\n",
      "abaw_expr_enet0_multiclass 1000 50 [0.00661872 0.5758283  0.1119443  0.03060678 0.05161068 0.129811\n",
      " 0.09358023] KL: 0.5563723944481296\n",
      "abaw_expr_enet0_multiclass 1000 100 [0.00673349 0.57793251 0.11347463 0.03056852 0.050769   0.12782156\n",
      " 0.09270028] KL: 0.5557188597150235\n",
      "abaw_expr_enet0_multiclass 10000 1 [0.01518861 0.56446553 0.10119366 0.03558038 0.06063968 0.12713291\n",
      " 0.09579922] KL: 0.4045367645574877\n",
      "abaw_expr_enet0_multiclass 10000 5 [0.01449996 0.56687581 0.09943377 0.03462392 0.05784681 0.1300023\n",
      " 0.09671742] KL: 0.41815140836739173\n",
      "abaw_expr_enet0_multiclass 10000 10 [0.01258704 0.57104599 0.10161451 0.03466218 0.05643125 0.13095876\n",
      " 0.09270028] KL: 0.44228082558902\n",
      "abaw_expr_enet0_multiclass 10000 50 [0.00818731 0.57544571 0.11282424 0.03163976 0.04839697 0.12885454\n",
      " 0.09465147] KL: 0.5248990582258323\n",
      "abaw_expr_enet0_multiclass 10000 100 [0.00638917 0.57973066 0.11290076 0.02643661 0.05053944 0.12973449\n",
      " 0.09426888] KL: 0.5781852151600513\n",
      "abaw_expr_enet0_multiclass 100000 1 [0.01518861 0.56446553 0.10119366 0.03558038 0.06063968 0.12713291\n",
      " 0.09579922] KL: 0.4045367645574877\n",
      "abaw_expr_enet0_multiclass 100000 5 [0.01449996 0.56687581 0.09943377 0.03462392 0.05784681 0.1300023\n",
      " 0.09671742] KL: 0.41815140836739173\n",
      "abaw_expr_enet0_multiclass 100000 10 [0.01258704 0.57108425 0.10165277 0.03466218 0.05643125 0.13095876\n",
      " 0.09262377] KL: 0.4422985880048359\n",
      "abaw_expr_enet0_multiclass 100000 50 [0.00826383 0.57460402 0.11270947 0.03148672 0.04969776 0.12954319\n",
      " 0.093695  ] KL: 0.521814920717077\n",
      "abaw_expr_enet0_multiclass 100000 100 [0.00627439 0.58535466 0.11251817 0.02479149 0.04885607 0.12361313\n",
      " 0.09859209] KL: 0.5913505680071625\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 1 [0.0331701  0.40936567 0.15620935 0.06947739 0.05199327 0.1699824\n",
      " 0.10980182] KL: 0.2095816267267303\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 5 [0.03339965 0.40990129 0.15559721 0.06947739 0.05149591 0.17002066\n",
      " 0.11010789] KL: 0.2094088808912565\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 10 [0.03339965 0.40971    0.15517637 0.06951565 0.05157242 0.1704415\n",
      " 0.11018441] KL: 0.20927778765036192\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 50 [0.03339965 0.40971    0.15517637 0.06951565 0.05157242 0.1704415\n",
      " 0.11018441] KL: 0.20927778765036192\n",
      "abaw_expr_enet0_multiclass_train_val 0.1 100 [0.03339965 0.40971    0.15517637 0.06951565 0.05157242 0.1704415\n",
      " 0.11018441] KL: 0.20927778765036192\n",
      "abaw_expr_enet0_multiclass_train_val 1 1 [0.03229015 0.41108731 0.15896396 0.06737317 0.04946821 0.16994414\n",
      " 0.11087306] KL: 0.21913916267099295\n",
      "abaw_expr_enet0_multiclass_train_val 1 5 [0.03240493 0.41154641 0.15858138 0.06737317 0.04866478 0.17032673\n",
      " 0.11110261] KL: 0.2200064585267308\n",
      "abaw_expr_enet0_multiclass_train_val 1 10 [0.03229015 0.41131686 0.1580075  0.06741143 0.0487413  0.1709006\n",
      " 0.11133216] KL: 0.22033102843763233\n",
      "abaw_expr_enet0_multiclass_train_val 1 50 [0.03183105 0.41055169 0.15751014 0.06741143 0.0487413  0.17166577\n",
      " 0.11228862] KL: 0.2221705485032658\n",
      "abaw_expr_enet0_multiclass_train_val 1 100 [0.03183105 0.41055169 0.15751014 0.06741143 0.0487413  0.17166577\n",
      " 0.11228862] KL: 0.2221705485032658\n",
      "abaw_expr_enet0_multiclass_train_val 10 1 [0.03248144 0.41261764 0.15777795 0.06653149 0.04893259 0.17047976\n",
      " 0.11117913] KL: 0.2201906302246806\n",
      "abaw_expr_enet0_multiclass_train_val 10 5 [0.030492   0.41372714 0.16190986 0.06546025 0.04552758 0.16975285\n",
      " 0.11313031] KL: 0.23556861990227707\n",
      "abaw_expr_enet0_multiclass_train_val 10 10 [0.03010942 0.41391843 0.16183335 0.06534547 0.04522152 0.17047976\n",
      " 0.11309205] KL: 0.23806569533740196\n",
      "abaw_expr_enet0_multiclass_train_val 10 50 [0.02938251 0.41296197 0.16122121 0.06534547 0.04522152 0.17135971\n",
      " 0.11450761] KL: 0.24126618837758043\n",
      "abaw_expr_enet0_multiclass_train_val 10 100 [0.02930599 0.41303849 0.16122121 0.06534547 0.04522152 0.17135971\n",
      " 0.11450761] KL: 0.24163218500516506\n",
      "abaw_expr_enet0_multiclass_train_val 50 1 [0.03229015 0.4128472  0.15751014 0.06653149 0.04900911 0.17055628\n",
      " 0.11125564] KL: 0.22088465556552392\n",
      "abaw_expr_enet0_multiclass_train_val 50 5 [0.02949728 0.4151427  0.16424363 0.06492463 0.04399725 0.16806948\n",
      " 0.11412503] KL: 0.24343521609882465\n",
      "abaw_expr_enet0_multiclass_train_val 50 10 [0.02811998 0.41743821 0.16604178 0.06347081 0.04181651 0.16898768\n",
      " 0.11412503] KL: 0.2562513258398064\n",
      "abaw_expr_enet0_multiclass_train_val 50 50 [0.02697222 0.41682608 0.16891116 0.063203   0.04189303 0.16910246\n",
      " 0.11309205] KL: 0.26237965420126913\n",
      "abaw_expr_enet0_multiclass_train_val 50 100 [0.02689571 0.41690259 0.17021195 0.063203   0.04189303 0.16910246\n",
      " 0.11179126] KL: 0.26300501784379793\n",
      "abaw_expr_enet0_multiclass_train_val 100 1 [0.03229015 0.4128472  0.1575484  0.06649323 0.04900911 0.17055628\n",
      " 0.11125564] KL: 0.2209234188222202\n",
      "abaw_expr_enet0_multiclass_train_val 100 5 [0.02942077 0.41541051 0.16416711 0.06500115 0.0440355  0.16768689\n",
      " 0.11427806] KL: 0.2436117058880443\n",
      "abaw_expr_enet0_multiclass_train_val 100 10 [0.02735481 0.41743821 0.16826077 0.06308822 0.04166348 0.16864335\n",
      " 0.11355115] KL: 0.26094351904271856\n",
      "abaw_expr_enet0_multiclass_train_val 100 50 [0.02582447 0.41896855 0.17166577 0.06090749 0.04181651 0.16837555\n",
      " 0.11244166] KL: 0.271610607654075\n",
      "abaw_expr_enet0_multiclass_train_val 100 100 [0.02574795 0.41904507 0.17296656 0.06090749 0.04181651 0.16837555\n",
      " 0.11114087] KL: 0.27227771492685066\n",
      "abaw_expr_enet0_multiclass_train_val 500 1 [0.03236667 0.41280894 0.15747188 0.06649323 0.04900911 0.17055628\n",
      " 0.1112939 ] KL: 0.2205945667579573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abaw_expr_enet0_multiclass_train_val 500 5 [0.02945903 0.41556355 0.16412885 0.06465682 0.04399725 0.16768689\n",
      " 0.11450761] KL: 0.2438597817029847\n",
      "abaw_expr_enet0_multiclass_train_val 500 10 [0.0266279  0.41850945 0.16810774 0.06243783 0.04166348 0.16852858\n",
      " 0.11412503] KL: 0.26545456790419164\n",
      "abaw_expr_enet0_multiclass_train_val 500 50 [0.01981789 0.4232535  0.18987681 0.05631647 0.03848803 0.16780167\n",
      " 0.10444563] KL: 0.32565779276704293\n",
      "abaw_expr_enet0_multiclass_train_val 500 100 [0.01970311 0.4232535  0.19156018 0.05428877 0.04055398 0.16814599\n",
      " 0.10249445] KL: 0.3253771507903532\n",
      "abaw_expr_enet0_multiclass_train_val 1000 1 [0.03236667 0.41280894 0.15743362 0.06649323 0.04900911 0.17059454\n",
      " 0.1112939 ] KL: 0.22059845746305903\n",
      "abaw_expr_enet0_multiclass_train_val 1000 5 [0.02945903 0.41567832 0.16416711 0.06469508 0.04392073 0.16753386\n",
      " 0.11454587] KL: 0.2439585546862671\n",
      "abaw_expr_enet0_multiclass_train_val 1000 10 [0.02674267 0.41850945 0.16764863 0.06243783 0.04151044 0.16856684\n",
      " 0.11458413] KL: 0.2651022006704966\n",
      "abaw_expr_enet0_multiclass_train_val 1000 50 [0.01736935 0.42589334 0.19374091 0.05478614 0.03791415 0.16558268\n",
      " 0.10471344] KL: 0.34886968425809173\n",
      "abaw_expr_enet0_multiclass_train_val 1000 100 [0.01702502 0.4282271  0.19584513 0.05283495 0.03994185 0.16447318\n",
      " 0.10165277] KL: 0.3511380834997421\n",
      "abaw_expr_enet0_multiclass_train_val 10000 1 [0.03236667 0.41280894 0.15743362 0.06649323 0.04900911 0.1706328\n",
      " 0.11125564] KL: 0.2206071495603082\n",
      "abaw_expr_enet0_multiclass_train_val 10000 5 [0.02949728 0.41571658 0.16412885 0.06465682 0.04399725 0.16757212\n",
      " 0.1144311 ] KL: 0.2436929765681294\n",
      "abaw_expr_enet0_multiclass_train_val 10000 10 [0.02666616 0.41847119 0.16764863 0.06247609 0.04147219 0.16864335\n",
      " 0.11462239] KL: 0.2655375507944856\n",
      "abaw_expr_enet0_multiclass_train_val 10000 50 [0.01289311 0.43381284 0.19274619 0.05218456 0.03718724 0.16627133\n",
      " 0.10490474] KL: 0.39941710683105813\n",
      "abaw_expr_enet0_multiclass_train_val 10000 100 [0.00918203 0.44601729 0.19787283 0.04663708 0.03580993 0.15659194\n",
      " 0.1078889 ] KL: 0.4645275434836833\n",
      "abaw_expr_enet0_multiclass_train_val 100000 1 [0.03236667 0.41280894 0.15743362 0.06649323 0.04900911 0.1706328\n",
      " 0.11125564] KL: 0.2206071495603082\n",
      "abaw_expr_enet0_multiclass_train_val 100000 5 [0.02949728 0.41571658 0.16412885 0.06469508 0.04395899 0.16757212\n",
      " 0.1144311 ] KL: 0.2437247879725575\n",
      "abaw_expr_enet0_multiclass_train_val 100000 10 [0.02666616 0.41850945 0.16764863 0.06243783 0.04147219 0.16856684\n",
      " 0.11469891] KL: 0.26556969305494826\n",
      "abaw_expr_enet0_multiclass_train_val 100000 50 [0.01304614 0.43450149 0.19198102 0.05199327 0.03726375 0.16692172\n",
      " 0.1042926 ] KL: 0.39789779943336134\n",
      "abaw_expr_enet0_multiclass_train_val 100000 100 [0.01048282 0.44303313 0.19760502 0.04659882 0.03584819 0.15873441\n",
      " 0.10769761] KL: 0.4439728961616596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores_first(videoname2featuresAll)\n",
    "    for sigma in [0.1, 1, 10, 50, 100, 500, 1000, 10000, 100000]:\n",
    "        for delta in [1,5,10,50,100]:\n",
    "            compound_classes_counts=np.zeros(len(compound_classes))\n",
    "            for videoname in sorted(videoname2compound_scores):\n",
    "                compound_scores=videoname2compound_scores[videoname]\n",
    "                frame_numbers=sorted(compound_scores.keys())\n",
    "                all_compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "                frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "                for i in range(frames_count):\n",
    "                    start,end=max(0,i-delta),min(frames_count,i+delta+1)\n",
    "                    k_sum=0\n",
    "                    max_faces_scores=np.zeros_like(all_compound_scores[i])\n",
    "                    for j in range(start,end):\n",
    "                        if (j+1) in compound_scores:\n",
    "                            k=math.exp(-(j-i)**2/sigma)\n",
    "                            max_faces_scores+=k*compound_scores[j+1]\n",
    "                            k_sum+=k\n",
    "                    if k_sum>0:\n",
    "                        max_faces_scores/=k_sum\n",
    "                    else:\n",
    "                        max_faces_scores=all_compound_scores[i]\n",
    "            \n",
    "                    compound_index=np.argmax(max_faces_scores)\n",
    "                    compound_classes_counts[compound_index]+=1\n",
    "            compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "            print(model_name,sigma,delta, compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models agreements  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454] \n",
      "\n",
      "ddamfnet_8 [0.06890351 0.3697299  0.08856837 0.07150509 0.03083633 0.19121585\n",
      " 0.17924095] KL: 0.18467258532309613\n",
      "\n",
      "enet_b0_8_best_vgaf [0.17706022 0.23942153 0.0988599  0.06098401 0.04131915 0.2137501\n",
      " 0.1686051 ] KL: 0.11862078496424168\n",
      "\n",
      "enet_b0_8_va_mtl [0.21665774 0.31961129 0.05566608 0.05933889 0.07031908 0.15494682\n",
      " 0.1234601 ] KL: 0.08304831480955421\n",
      "\n",
      "mbf_va [0.13019359 0.32860204 0.05872676 0.12273319 0.06645497 0.15268957\n",
      " 0.14059989] KL: 0.060323047351097385\n",
      "\n",
      "enet_b0_8_mtl_abaw [0.08194965 0.46197108 0.02727829 0.0512281  0.12223583 0.12690336\n",
      " 0.1284337 ] KL: 0.1933555393166923\n",
      "\n",
      "abaw_expr_enet0_multilabel [0.01729283 0.67002066 0.09296809 0.04066876 0.01932053 0.11010789\n",
      " 0.04962124] KL: 0.5450719728228879\n",
      "\n",
      "abaw_expr_enet0_multiclass [0.0144617  0.56683755 0.11114087 0.03286403 0.05700513 0.1239192\n",
      " 0.09377152] KL: 0.4215674095706967\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val [0.03795241 0.42283266 0.14962889 0.05298799 0.03986533 0.18566838\n",
      " 0.11106435] KL: 0.23613772570912675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probabs_orig=freqs/freqs.sum()\n",
    "print('probabs from paper:',probabs_orig,'\\n')\n",
    "\n",
    "model2compound_labels={}\n",
    "for model_name in ['ddamfnet_8','enet_b0_8_best_vgaf', 'enet_b0_8_va_mtl','mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "\n",
    "\n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "    videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "    compound_labels=[]\n",
    "    for videoname in sorted(videoname2compound_scores):\n",
    "        compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "        for i in range(len(compound_scores)):\n",
    "            compound_index=np.argmax(compound_scores[i])\n",
    "            compound_labels.append(compound_index)\n",
    "\n",
    "    compound_labels=np.array(compound_labels)\n",
    "    model2compound_labels[model_name]=compound_labels\n",
    "    \n",
    "    unique_labels,compound_classes_probabs=np.unique(compound_labels, return_counts=True)\n",
    "    compound_classes_probabs=compound_classes_probabs.astype('float64')/compound_classes_probabs.sum()\n",
    "    print(model_name,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddamfnet_8 ddamfnet_8 1.0 1.0\n",
      "ddamfnet_8 enet_b0_8_best_vgaf 0.4196313810361144 0.5276991353584819\n",
      "ddamfnet_8 enet_b0_8_va_mtl 0.404468180123724 0.5213099701583901\n",
      "ddamfnet_8 mbf_va 0.4231861592984494 0.5390619022113398\n",
      "ddamfnet_8 enet_b0_8_mtl_abaw 0.23329699237067048 0.4123880939628128\n",
      "ddamfnet_8 abaw_expr_enet0_multilabel 0.18132594008373504 0.4192363608539291\n",
      "ddamfnet_8 abaw_expr_enet0_multiclass 0.1479752039025296 0.3737852934424975\n",
      "ddamfnet_8 abaw_expr_enet0_multiclass_train_val 0.20608366065128214 0.3907720560104063\n",
      "\n",
      "enet_b0_8_best_vgaf ddamfnet_8 0.4196313810361145 0.5276991353584819\n",
      "enet_b0_8_best_vgaf enet_b0_8_best_vgaf 1.0 1.0\n",
      "enet_b0_8_best_vgaf enet_b0_8_va_mtl 0.6368227373680284 0.7025021042160838\n",
      "enet_b0_8_best_vgaf mbf_va 0.48131334078884414 0.5716198637998317\n",
      "enet_b0_8_best_vgaf enet_b0_8_mtl_abaw 0.2606252997350189 0.3972377381590022\n",
      "enet_b0_8_best_vgaf abaw_expr_enet0_multilabel 0.16542721118778303 0.3388935649246308\n",
      "enet_b0_8_best_vgaf abaw_expr_enet0_multiclass 0.17015095137527547 0.3327339505700513\n",
      "enet_b0_8_best_vgaf abaw_expr_enet0_multiclass_train_val 0.23747332255739217 0.3793327722090443\n",
      "\n",
      "enet_b0_8_va_mtl ddamfnet_8 0.404468180123724 0.5213099701583901\n",
      "enet_b0_8_va_mtl enet_b0_8_best_vgaf 0.6368227373680284 0.7025021042160838\n",
      "enet_b0_8_va_mtl enet_b0_8_va_mtl 1.0 1.0\n",
      "enet_b0_8_va_mtl mbf_va 0.4615188181583344 0.5635473257326498\n",
      "enet_b0_8_va_mtl enet_b0_8_mtl_abaw 0.3272932834400665 0.4713061443109649\n",
      "enet_b0_8_va_mtl abaw_expr_enet0_multilabel 0.19077872239351534 0.39310582293978114\n",
      "enet_b0_8_va_mtl abaw_expr_enet0_multiclass 0.17673374002274644 0.3637998316627133\n",
      "enet_b0_8_va_mtl abaw_expr_enet0_multiclass_train_val 0.23452218973891492 0.3877113780702426\n",
      "\n",
      "mbf_va ddamfnet_8 0.4231861592984494 0.5390619022113398\n",
      "mbf_va enet_b0_8_best_vgaf 0.48131334078884414 0.5716198637998317\n",
      "mbf_va enet_b0_8_va_mtl 0.4615188181583343 0.5635473257326498\n",
      "mbf_va mbf_va 1.0 1.0\n",
      "mbf_va enet_b0_8_mtl_abaw 0.20128836375408887 0.37374703496824546\n",
      "mbf_va abaw_expr_enet0_multilabel 0.15409588157705134 0.3722932129466677\n",
      "mbf_va abaw_expr_enet0_multiclass 0.1226132277802836 0.328449001453822\n",
      "mbf_va abaw_expr_enet0_multiclass_train_val 0.1897032883167591 0.3564542046063203\n",
      "\n",
      "enet_b0_8_mtl_abaw ddamfnet_8 0.23329699237067048 0.4123880939628128\n",
      "enet_b0_8_mtl_abaw enet_b0_8_best_vgaf 0.2606252997350189 0.3972377381590022\n",
      "enet_b0_8_mtl_abaw enet_b0_8_va_mtl 0.3272932834400665 0.4713061443109649\n",
      "enet_b0_8_mtl_abaw mbf_va 0.20128836375408887 0.37374703496824546\n",
      "enet_b0_8_mtl_abaw enet_b0_8_mtl_abaw 1.0 1.0\n",
      "enet_b0_8_mtl_abaw abaw_expr_enet0_multilabel 0.2660808079481798 0.5143469278445175\n",
      "enet_b0_8_mtl_abaw abaw_expr_enet0_multiclass 0.24980454574476962 0.47673884765475555\n",
      "enet_b0_8_mtl_abaw abaw_expr_enet0_multiclass_train_val 0.34818076899856376 0.509794169408524\n",
      "\n",
      "abaw_expr_enet0_multilabel ddamfnet_8 0.18132594008373504 0.4192363608539291\n",
      "abaw_expr_enet0_multilabel enet_b0_8_best_vgaf 0.16542721118778292 0.3388935649246308\n",
      "abaw_expr_enet0_multilabel enet_b0_8_va_mtl 0.19077872239351534 0.39310582293978114\n",
      "abaw_expr_enet0_multilabel mbf_va 0.15409588157705134 0.3722932129466677\n",
      "abaw_expr_enet0_multilabel enet_b0_8_mtl_abaw 0.2660808079481798 0.5143469278445175\n",
      "abaw_expr_enet0_multilabel abaw_expr_enet0_multilabel 1.0 1.0\n",
      "abaw_expr_enet0_multilabel abaw_expr_enet0_multiclass 0.6118859251463776 0.7714438748182723\n",
      "abaw_expr_enet0_multilabel abaw_expr_enet0_multiclass_train_val 0.43542528856462626 0.6199020583059147\n",
      "\n",
      "abaw_expr_enet0_multiclass ddamfnet_8 0.14797520390252938 0.3737852934424975\n",
      "abaw_expr_enet0_multiclass enet_b0_8_best_vgaf 0.17015095137527558 0.3327339505700513\n",
      "abaw_expr_enet0_multiclass enet_b0_8_va_mtl 0.17673374002274633 0.3637998316627133\n",
      "abaw_expr_enet0_multiclass mbf_va 0.12261322778028372 0.328449001453822\n",
      "abaw_expr_enet0_multiclass enet_b0_8_mtl_abaw 0.24980454574476962 0.47673884765475555\n",
      "abaw_expr_enet0_multiclass abaw_expr_enet0_multilabel 0.6118859251463776 0.7714438748182723\n",
      "abaw_expr_enet0_multiclass abaw_expr_enet0_multiclass 1.0 1.0\n",
      "abaw_expr_enet0_multiclass abaw_expr_enet0_multiclass_train_val 0.4831879906623646 0.6352819649552376\n",
      "\n",
      "abaw_expr_enet0_multiclass_train_val ddamfnet_8 0.20608366065128214 0.3907720560104063\n",
      "abaw_expr_enet0_multiclass_train_val enet_b0_8_best_vgaf 0.23747332255739195 0.3793327722090443\n",
      "abaw_expr_enet0_multiclass_train_val enet_b0_8_va_mtl 0.23452218973891492 0.3877113780702426\n",
      "abaw_expr_enet0_multiclass_train_val mbf_va 0.18970328831675898 0.3564542046063203\n",
      "abaw_expr_enet0_multiclass_train_val enet_b0_8_mtl_abaw 0.34818076899856376 0.509794169408524\n",
      "abaw_expr_enet0_multiclass_train_val abaw_expr_enet0_multilabel 0.43542528856462626 0.6199020583059147\n",
      "abaw_expr_enet0_multiclass_train_val abaw_expr_enet0_multiclass 0.4831879906623646 0.6352819649552376\n",
      "abaw_expr_enet0_multiclass_train_val abaw_expr_enet0_multiclass_train_val 1.0 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappas=np.zeros((len(model2compound_labels),len(model2compound_labels)))\n",
    "\n",
    "for i1,model_name1 in enumerate(model2compound_labels):\n",
    "    compound_labels1=model2compound_labels[model_name1]\n",
    "    for i2,model_name2 in enumerate(model2compound_labels):\n",
    "        compound_labels2=model2compound_labels[model_name2]\n",
    "        kappas[i1,i2]=cohen_kappa_score(compound_labels1,compound_labels2)\n",
    "        print(model_name1,model_name2,kappas[i1,i2],(compound_labels1==compound_labels2).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass display_labels=dict_keys(['ddamfnet_8', 'enet_b0_8_best_vgaf', 'enet_b0_8_va_mtl', 'mbf_va', 'enet_b0_8_mtl_abaw', 'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']) as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp=ConfusionMatrixDisplay(kappas,model2compound_labels.keys())\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(\n",
    "        include_values=True,\n",
    "        cmap=plt.cm.Blues,\n",
    "        ax=ax,\n",
    "        xticks_rotation=\"vertical\",\n",
    "        values_format=None,\n",
    "        colorbar=False,\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_7/CE/outputs/\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR=DATA_DIR+'outputs/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26146 ['image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry', '01/00001.jpg,', '01/00002.jpg,', '01/00003.jpg,', '01/00004.jpg,']\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_DIR+'../test_set_examples/CER.txt', 'r') as f:\n",
    "    test_set_sample=f.read().splitlines()\n",
    "print(len(test_set_sample),test_set_sample[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'24/00627.jpg', '29/00092.jpg', '28/00330.jpg', '51/00483.jpg', '05/00189.jpg', '56/00267.jpg', '16/00266.jpg', '40/00769.jpg', '43/00076.jpg', '44/00387.jpg', '33/00193.jpg'} {'10/00035.jpg', '09/00087.jpg', '22/00068.jpg', '45/00061.jpg'}\n",
      "['24', '29', '28', '51', '05', '56', '16', '40', '43', '44', '33'] ['10', '09', '22', '45']\n"
     ]
    }
   ],
   "source": [
    "correct_filepaths=set()\n",
    "for line in test_set_sample[1:]:\n",
    "    correct_filepaths.add(line.split(',')[0])\n",
    "\n",
    "filepaths=set()\n",
    "for videoname in sorted(videoname2compound_scores):\n",
    "    compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "    for i in range(len(compound_scores)):\n",
    "        filepaths.add(videoname+'/'+get_names(i+1)+'.jpg')\n",
    "\n",
    "print(correct_filepaths-filepaths,filepaths-correct_filepaths)\n",
    "\n",
    "videos_with_new_frame,videos_with_extra_frame=[],[]\n",
    "for filepath in (correct_filepaths-filepaths):\n",
    "    videos_with_new_frame.append(filepath.split('/')[0])\n",
    "for filepath in (filepaths-correct_filepaths):\n",
    "    videos_with_extra_frame.append(filepath.split('/')[0])\n",
    "    \n",
    "print(videos_with_new_frame,videos_with_extra_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs from paper: [0.15996323 0.27590751 0.1193772  0.11779363 0.11666408 0.1119798\n",
      " 0.09831454]\n",
      "mbf_va set() [0.09783897 0.37464142 0.06567221 0.10066934 0.05136737 0.17467967\n",
      " 0.135131  ] KL: 0.09872366077611314\n"
     ]
    }
   ],
   "source": [
    "delta=50\n",
    "print('freqs from paper:',freqs/freqs.sum())\n",
    "\n",
    "for model_name in ['enet_b0_8_best_vgaf', 'mbf_va', 'enet_b0_8_mtl_abaw',\n",
    "                  'abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass', 'abaw_expr_enet0_multiclass_train_val']: \n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "    compound_classes_counts=np.zeros(len(compound_classes))\n",
    "    filepaths=set()\n",
    "    with open(os.path.join(OUTPUT_DIR,model_name+'.txt'), 'w') as f:\n",
    "        f.write('image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry\\n')\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            max_i=len(compound_scores)\n",
    "            if videoname in videos_with_extra_frame:\n",
    "                max_i-=1\n",
    "            for i in range(max_i):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "            if videoname in videos_with_new_frame:\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+2)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "\n",
    "    compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "    print(model_name,correct_filepaths-filepaths,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='mbf_va'\n",
    "with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "    videoname2featuresAll=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va set() [0.12009945 0.34779116 0.05894052 0.11336776 0.05729585 0.16389367\n",
      " 0.13861159] KL: 0.07726130787213445\n",
      "mbf_va set() [0.09783897 0.37464142 0.06567221 0.10066934 0.05136737 0.17467967\n",
      " 0.135131  ] KL: 0.09872366077611314\n",
      "mbf_va set() [0.0831899  0.39556321 0.06834959 0.10724804 0.05450373 0.17479442\n",
      " 0.11635112] KL: 0.10517239972573313\n"
     ]
    }
   ],
   "source": [
    "videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "\n",
    "for delta in [10,50,100]:\n",
    "    filepaths=set()\n",
    "    compound_classes_counts=np.zeros(len(compound_classes))\n",
    "    with open(os.path.join(OUTPUT_DIR,'1_'+model_name+'_'+str(delta)+'.txt'), 'w') as f:\n",
    "        f.write('image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry\\n')\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            max_i=len(compound_scores)\n",
    "            if videoname in videos_with_extra_frame:\n",
    "                max_i-=1\n",
    "            for i in range(max_i):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "            if videoname in videos_with_new_frame:\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+2)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "\n",
    "    compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "    print(model_name,correct_filepaths-filepaths,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va set() [0.11160834 0.32598967 0.06953528 0.10908395 0.06276535 0.17590361\n",
      " 0.14511379] KL: 0.06859256204898498\n",
      "mbf_va set() [0.0897686  0.35291643 0.0789826  0.09680627 0.0551922  0.18898451\n",
      " 0.1373494 ] KL: 0.0927610995658489\n",
      "mbf_va set() [0.07588449 0.37452668 0.07638172 0.09711226 0.05316504 0.19365079\n",
      " 0.12927902] KL: 0.11445415020637041\n"
     ]
    }
   ],
   "source": [
    "videoname2compound_scores=get_videoname2compound_scores_first(videoname2featuresAll)\n",
    "\n",
    "for delta in [10,50,100]:\n",
    "    filepaths=set()\n",
    "    compound_classes_counts=np.zeros(len(compound_classes))\n",
    "    with open(os.path.join(OUTPUT_DIR,'2_'+model_name+'_first_'+str(delta)+'.txt'), 'w') as f:\n",
    "        f.write('image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry\\n')\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            max_i=len(compound_scores)\n",
    "            if videoname in videos_with_extra_frame:\n",
    "                max_i-=1\n",
    "            for i in range(max_i):\n",
    "                i1=max(i-delta,0)\n",
    "                max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "            if videoname in videos_with_new_frame:\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+2)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "\n",
    "    compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "    print(model_name,correct_filepaths-filepaths,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va set() [0.11805423 0.35037669 0.06183793 0.11193545 0.05178018 0.16581896\n",
      " 0.14019657] KL: 0.08311755050945863\n",
      "mbf_va set() [0.10271903 0.37179242 0.06428544 0.10233661 0.04237256 0.18149834\n",
      " 0.1349956 ] KL: 0.11192533065650276\n",
      "mbf_va set() [0.09965964 0.37821714 0.06390302 0.10271903 0.03908371 0.18509312\n",
      " 0.13132433] KL: 0.1222483392875363\n"
     ]
    }
   ],
   "source": [
    "videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll)\n",
    "\n",
    "delta=50\n",
    "for sigma in [100,1000,10000]:\n",
    "    with open(os.path.join(OUTPUT_DIR,'3_'+model_name+'_'+str(delta)+'_'+str(sigma)+'.txt'), 'w') as f:\n",
    "        f.write('image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry\\n')\n",
    "        compound_classes_counts=np.zeros(len(compound_classes))\n",
    "        for videoname in sorted(videoname2compound_scores):\n",
    "            compound_scores=videoname2compound_scores[videoname]\n",
    "            all_compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "            frames_count=len(os.listdir(os.path.join(FRAMES_DIR, videoname)))\n",
    "            for i in range(frames_count):\n",
    "                start,end=max(0,i-delta),min(frames_count,i+delta+1)\n",
    "                k_sum=0\n",
    "                max_faces_scores=np.zeros_like(all_compound_scores[i])\n",
    "                for j in range(start,end):\n",
    "                    if (j+1) in compound_scores:\n",
    "                        k=math.exp(-(j-i)**2/sigma)\n",
    "                        max_faces_scores+=k*compound_scores[j+1]\n",
    "                        k_sum+=k\n",
    "                if k_sum>0:\n",
    "                    max_faces_scores/=k_sum\n",
    "                else:\n",
    "                    max_faces_scores=all_compound_scores[i]\n",
    "\n",
    "                compound_index=np.argmax(max_faces_scores)\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')\n",
    "            if videoname in videos_with_new_frame:\n",
    "                compound_classes_counts[compound_index]+=1\n",
    "                filepath=videoname+'/'+get_names(i+2)+'.jpg'\n",
    "                filepaths.add(filepath)\n",
    "                f.write(filepath +','+str(compound_index)+'\\n')    \n",
    "    compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "    print(model_name,correct_filepaths-filepaths,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbf_va 0 0 set() [0.13008223 0.32859055 0.05871103 0.12285332 0.06647543 0.15268694\n",
      " 0.1406005 ] KL: 0.06035189095157949\n",
      "mbf_va 0 1 set() [0.13918531 0.30070759 0.07515777 0.04631861 0.07473704 0.17364697\n",
      " 0.1902467 ] KL: 0.10161662955222363\n",
      "mbf_va 0 2 set() [0.14320138 0.28406961 0.07584624 0.037751   0.07649646 0.17647734\n",
      " 0.20615797] KL: 0.12335288978533654\n",
      "mbf_va 10 0 set() [0.12009945 0.34779116 0.05894052 0.11336776 0.05729585 0.16389367\n",
      " 0.13861159] KL: 0.07726130787213445\n",
      "mbf_va 10 1 set() [0.13964429 0.31642762 0.07393383 0.037904   0.06353031 0.18799006\n",
      " 0.1805699 ] KL: 0.12780521850158844\n",
      "mbf_va 10 2 set() [0.14587875 0.29898642 0.07408682 0.03193727 0.06965003 0.19020845\n",
      " 0.18925225] KL: 0.13973069007677058\n",
      "abaw_expr_enet0_multilabel 0 0 set() [0.01724995 0.67003251 0.0930197  0.04065787 0.0193536  0.11007841\n",
      " 0.04960796] KL: 0.5452862763673841\n",
      "abaw_expr_enet0_multilabel 0 1 set() [0.01740295 0.66253586 0.09393766 0.0399694  0.0195066  0.11841652\n",
      " 0.04823102] KL: 0.5414901691895261\n",
      "abaw_expr_enet0_multilabel 0 2 set() [0.01809141 0.65159686 0.09133678 0.04352649 0.02180149 0.12308281\n",
      " 0.05056416] KL: 0.5112383007123962\n",
      "abaw_expr_enet0_multilabel 10 0 set() [0.0119717  0.68751195 0.08934787 0.03993115 0.0118952  0.11902849\n",
      " 0.04031364] KL: 0.6719704673694626\n",
      "abaw_expr_enet0_multilabel 10 1 set() [0.01174221 0.68005355 0.0961943  0.03981641 0.01028877 0.12312106\n",
      " 0.03878371] KL: 0.68654522008552\n",
      "abaw_expr_enet0_multilabel 10 2 set() [0.01239243 0.6755785  0.09393766 0.04134634 0.01128323 0.12533945\n",
      " 0.04012239] KL: 0.6620381275163506\n",
      "abaw_expr_enet0_multiclass 0 0 set() [0.01441958 0.56672404 0.11111111 0.03285523 0.05718111 0.12392427\n",
      " 0.09378466] KL: 0.4217747996644956\n",
      "abaw_expr_enet0_multiclass 0 1 set() [0.01319564 0.56595907 0.11099637 0.03247275 0.0541595  0.12709887\n",
      " 0.0961178 ] KL: 0.4389243304475532\n",
      "abaw_expr_enet0_multiclass 0 2 set() [0.01369287 0.54243641 0.11183783 0.03312297 0.0595525  0.13704341\n",
      " 0.10231402] KL: 0.41583115857597547\n",
      "abaw_expr_enet0_multiclass 10 0 set() [0.01120673 0.57299675 0.10548862 0.03212851 0.04869    0.13199465\n",
      " 0.09749474] KL: 0.47576827479697714\n",
      "abaw_expr_enet0_multiclass 10 1 set() [0.00921782 0.58099063 0.10422643 0.03144005 0.04547715 0.13115318\n",
      " 0.09749474] KL: 0.5158672617599033\n",
      "abaw_expr_enet0_multiclass 10 2 set() [0.00906483 0.56863645 0.10284949 0.0303691  0.04716007 0.14014152\n",
      " 0.10177854] KL: 0.5142549885036101\n",
      "abaw_expr_enet0_multiclass_train_val 0 0 set() [0.03794225 0.42279595 0.14958883 0.0529738  0.03993115 0.18569516\n",
      " 0.11107286] KL: 0.23605186607083636\n",
      "abaw_expr_enet0_multiclass_train_val 0 1 set() [0.03694779 0.43117231 0.14920635 0.05209409 0.04069612 0.18393574\n",
      " 0.1059476 ] KL: 0.2406625611117284\n",
      "abaw_expr_enet0_multiclass_train_val 0 2 set() [0.03855422 0.40252438 0.15486709 0.06257411 0.04547715 0.18558042\n",
      " 0.11042264] KL: 0.20876411220341884\n",
      "abaw_expr_enet0_multiclass_train_val 10 0 set() [0.03059858 0.42960413 0.15532607 0.04949321 0.0303691  0.18871677\n",
      " 0.11589214] KL: 0.29551827069700903\n",
      "abaw_expr_enet0_multiclass_train_val 10 1 set() [0.02968063 0.43878371 0.15517307 0.04853701 0.03193727 0.18569516\n",
      " 0.11019315] KL: 0.297864095298418\n",
      "abaw_expr_enet0_multiclass_train_val 10 2 set() [0.03319946 0.42474661 0.15723848 0.05721935 0.03476764 0.18099063\n",
      " 0.11183783] KL: 0.2594601473559049\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['mbf_va','abaw_expr_enet0_multilabel', 'abaw_expr_enet0_multiclass','abaw_expr_enet0_multiclass_train_val']:\n",
    "    with open('cexpr_'+model_name+'.pickle' , 'rb') as handle:\n",
    "        videoname2featuresAll=pickle.load(handle)\n",
    "\n",
    "    for delta in [0,10]:\n",
    "        for mean_function in [ARITHMETIC_MEAN,GEOMETRIC_MEAN,HARMONIC_MEAN]:\n",
    "            filepaths=set()\n",
    "            compound_classes_counts=np.zeros(len(compound_classes))\n",
    "            videoname2compound_scores=get_videoname2compound_scores(videoname2featuresAll,mean_function)\n",
    "            with open(os.path.join(OUTPUT_DIR,'4_'+model_name+'_'+str(delta)+'_agg_'+str(mean_function)+'.txt'), 'w') as f:\n",
    "                f.write('image_location,Fearfully_Surprised,Happily_Surprised,Sadly_Surprised,Disgustedly_Surprised,Angrily_Surprised,Sadly_Fearful,Sadly_Angry\\n')\n",
    "                for videoname in sorted(videoname2compound_scores):\n",
    "                    compound_scores=get_compound_scores(videoname,videoname2compound_scores)\n",
    "                    max_i=len(compound_scores)\n",
    "                    if videoname in videos_with_extra_frame:\n",
    "                        max_i-=1\n",
    "                    for i in range(max_i):\n",
    "                        i1=max(i-delta,0)\n",
    "                        max_faces_scores=np.mean(compound_scores[i1:i+delta+1],axis=0)\n",
    "                        compound_index=np.argmax(max_faces_scores)\n",
    "                        compound_classes_counts[compound_index]+=1\n",
    "                        filepath=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "                        filepaths.add(filepath)\n",
    "                        f.write(filepath +','+str(compound_index)+'\\n')\n",
    "                    if videoname in videos_with_new_frame:\n",
    "                        compound_classes_counts[compound_index]+=1\n",
    "                        filepath=videoname+'/'+get_names(i+2)+'.jpg'\n",
    "                        filepaths.add(filepath)\n",
    "                        f.write(filepath +','+str(compound_index)+'\\n')\n",
    "\n",
    "            compound_classes_probabs=compound_classes_counts/compound_classes_counts.sum()\n",
    "            print(model_name,delta,mean_function,correct_filepaths-filepaths,compound_classes_probabs, 'KL:',np.sum(probabs_orig * np.log(probabs_orig / compound_classes_probabs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
