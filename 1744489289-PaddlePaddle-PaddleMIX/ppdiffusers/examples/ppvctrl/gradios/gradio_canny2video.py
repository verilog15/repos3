# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import cv2
import numpy as np
import subprocess
from decord import VideoReader, cpu
import moviepy.editor as mpy
import gradio as gr
from utils import FeedbackManager, add_watermark, process_input_video

env = os.environ
env["CUDA_VISIBLE_DEVICES"] = "3"

def extract_canny(video_path, low_threshold=100, high_threshold=255):
    output_video_path = video_path.replace('.mp4', '_canny.mp4')
    first_rgb_image_path = video_path.replace('.mp4', '_first_frame_rgb.jpg')
    first_canny_image_path = video_path.replace('.mp4', '_first_frame_canny.jpg')
    vr = VideoReader(video_path, ctx=cpu(0))
    target_fps = vr.get_avg_fps()
    first_frame = vr[0].asnumpy()
    first_frame_bgr = cv2.cvtColor(first_frame, cv2.COLOR_RGB2BGR)
    cv2.imwrite(first_rgb_image_path, first_frame_bgr)
    print(f"Á¨¨‰∏ÄÂ∏ßrgbÂ∑≤‰øùÂ≠òÂà∞ {first_rgb_image_path}")
    frames = []
    for i in range(len(vr)):
        frame = vr[i].asnumpy()
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        frame = cv2.Canny(frame, low_threshold, high_threshold)
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
        frames.append(frame)
    cv2.imwrite(first_canny_image_path, frames[0])
    print(f"Á¨¨‰∏ÄÂ∏ßcannyÂ∑≤‰øùÂ≠òÂà∞ {first_canny_image_path}")

    def downsample_fps(frames, target_fps=8):
        length = len(frames)
        avg_fps = float(vr.get_avg_fps())
        interval_frame = max(1, int(round(avg_fps / target_fps)))
        bg_frame_id = 0
        frame_ids = list(range(bg_frame_id, length, interval_frame))
        len_frame_ids = len(frame_ids)
        len_frame_ids = len_frame_ids - (len_frame_ids - 1) % 8
        frame_ids = frame_ids[:len_frame_ids]
        frames = [frames[frame_id] for frame_id in frame_ids]
        return frames
    frames = downsample_fps(frames, target_fps)


    if len(frames) < 49:
        height, width, channels = frames[0].shape if frames else (480, 640, 3)
        blank_frame = np.zeros((height, width, channels), dtype=np.uint8)
        frames_to_add = 49 - len(frames)
        for _ in range(frames_to_add):
            frames.append(blank_frame.copy())

    def write_video(frames, output_video_path):
        output_fps = target_fps
        def make_frame(t):
            return frames[int(t * output_fps)]

        clip = mpy.VideoClip(make_frame, duration=len(frames) / output_fps)

        clip.write_videofile(output_video_path, fps=output_fps)

    write_video(frames, output_video_path)

    print(f"ËßÜÈ¢ëÂ§ÑÁêÜÂÆåÊàêÔºåÂ∑≤‰øùÂ≠òÂà∞ {output_video_path}")

    return output_video_path, first_rgb_image_path, first_canny_image_path

def cogvideox_5b_i2v_vctrl_process(
    input_video,
    prompt,
    controlnet_seed,
    controlnet_num_inference_steps,
    controlnet_guidance_scale,
    controlnet_conditioning_scale,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame,
    use_controlnet
):
    use_controlnet = True if use_controlnet == "yes" else False
    input_video = process_input_video(input_video, task="canny", height=480, width=720)

    canny_video_path, first_rgb_image_path, first_canny_image_path = extract_canny(input_video, low_threshold, high_threshold)
    controlnet_command = [
        "python", "tools/controlnet_gradio.py",
        "--image_path", first_canny_image_path, 
        "--prompt", prompt,
        "--task", "canny",
        "--controlnet_seed", str(controlnet_seed),
        "--controlnet_num_inference_steps", str(controlnet_num_inference_steps),
        "--controlnet_guidance_scale", str(controlnet_guidance_scale),
        "--controlnet_conditioning_scale", str(controlnet_conditioning_scale)
    ]
    vctrl_command = [
        "python", "infer_cogvideox_i2v_vctrl_cli.py",
        "--pretrained_model_name_or_path", "paddlemix/cogvideox-5b-i2v-vctrl",
        "--vctrl_path", "weights/canny/vctrl_canny_5b_i2v_vctrl-tiny.pdparams",
        "--vctrl_config", "vctrl_configs/cogvideox_5b_i2v_vctrl_tiny_config.json",
        "--control_video_path", canny_video_path,
        "--output_dir", "infer_outputs/canny2video/i2v",
        "--task", "canny",
        "--ref_image_path", first_canny_image_path.replace('.jpg', '_controlnet.jpg') if use_controlnet else first_rgb_image_path,
        "--prompt_path", prompt,
        "--width", "720",
        "--height", "480",
        "--max_frame", str(max_frame),
        "--guidance_scale", str(guidance_scale),
        "--num_inference_steps", str(num_inference_steps),
        "--conditioning_scale", str(conditioning_scale),
    ]
    if use_controlnet:
        subprocess.run(controlnet_command, check=True, env=env)
    subprocess.run(vctrl_command, check=True, env=env)
    return add_watermark("infer_outputs/canny2video/i2v/output.mp4"), "infer_outputs/canny2video/i2v/origin_predict.mp4", "infer_outputs/canny2video/i2v/test_1.mp4", first_canny_image_path.replace('.jpg', '_controlnet.jpg') if use_controlnet else first_rgb_image_path

def cogvideox_5b_vctrl_process(
    input_video,
    prompt,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame
):
    input_video = process_input_video(input_video, task="canny", height=480, width=720)
    canny_video_path, _, _ = extract_canny(input_video)
    vctrl_command = [
        "python", "infer_cogvideox_t2v_vctrl_cli.py",
        "--pretrained_model_name_or_path", "paddlemix/cogvideox-5b-vctrl",
        "--vctrl_path", "weights/canny/vctrl_canny_5b_t2v.pdparams",
        "--vctrl_config", "vctrl_configs/cogvideox_5b_vctrl_config.json",
        "--control_video_path", canny_video_path,
        "--output_dir", "infer_outputs/canny2video/t2v",
        "--task", "canny",
        "--prompt_path", prompt,
        "--width", "720",
        "--height", "480",
        "--max_frame", str(max_frame),
        "--guidance_scale", str(guidance_scale),
        "--num_inference_steps", str(num_inference_steps),
        "--conditioning_scale", str(conditioning_scale)
    ]

    subprocess.run(vctrl_command, check=True, env=env)
    return add_watermark("infer_outputs/canny2video/t2v/output.mp4"),"infer_outputs/canny2video/t2v/origin_predict.mp4", "infer_outputs/canny2video/t2v/test_1.mp4", None

def process(
    model,
    input_video,
    prompt,
    controlnet_seed,
    controlnet_num_inference_steps,
    controlnet_guidance_scale,
    controlnet_conditioning_scale,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame,
    use_controlnet
):
    if model == "cogvideox_5b_i2v_vctrl":
        output = cogvideox_5b_i2v_vctrl_process(
            input_video,
            prompt,
            controlnet_seed,
            controlnet_num_inference_steps,
            controlnet_guidance_scale,
            controlnet_conditioning_scale,
            num_inference_steps,
            conditioning_scale,
            guidance_scale,
            low_threshold,
            high_threshold,
            max_frame,
            use_controlnet
        )
    elif model == "cogvideox_5b_vctrl":
        output = cogvideox_5b_vctrl_process(
            input_video,
            prompt,
            num_inference_steps,
            conditioning_scale,
            guidance_scale,
            low_threshold,
            high_threshold,
            max_frame
        )
    else:
        raise ValueError(f"Invalid model name: {model}")
    
    current_output_dir = os.path.dirname(output[0])
    feedback_mgr.store_conversation(prompt, input_video, current_output_dir)
    feedback_mgr.mark_chat_complete()
    
    return output

def get_feedback_stats():
    """‰ªé FeedbackManager Ëé∑ÂèñÂΩìÂâçÂèçÈ¶àÊï∞ÊçÆ"""
    return f"{feedback_mgr.feedback_data['likes']} üëç | {feedback_mgr.feedback_data['dislikes']} üëé"

feedback_mgr = FeedbackManager(os.path.join(os.path.dirname(os.path.abspath(__file__)), "feedback"))

block = gr.Blocks().queue()
with block:
    with gr.Row():
        gr.Markdown("## ü§ñ PP-VCtrl: Multimodal Scene Transitions (Canny) Demo")
    with gr.Row():
        gr.Markdown('üìö ÂéüÂßãÊ®°ÂûãÊù•Ëá™ [PaddleMIX](https://github.com/PaddlePaddle/PaddleMIX) Ôºàüåü ‰∏Ä‰∏™Âü∫‰∫éÈ£ûÊ°®PaddlePaddleÊ°ÜÊû∂ÊûÑÂª∫ÁöÑÂ§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÂ•ó‰ª∂Ôºâ')
    with gr.Row():
        gr.Markdown('PP-VCtrlÊòØ‰∏Ä‰∏™Áªü‰∏ÄÁöÑËßÜÈ¢ëÁîüÊàêÊéßÂà∂Ê®°ÂûãÔºö')
    with gr.Row():
        gr.Markdown('- ÂÆÉÈÄöËøáÂºïÂÖ•ËæÖÂä©Êù°‰ª∂ÁºñÁ†ÅÂô®ÔºåÂÆûÁé∞‰∫ÜÂØπÂêÑÁ±ªÊéßÂà∂‰ø°Âè∑ÁöÑÁÅµÊ¥ªÊé•ÂÖ•ÂíåÁ≤æÁ°ÆÊéßÂà∂ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÊïàÁöÑËÆ°ÁÆóÊÄßËÉΩ')
    with gr.Row():
        gr.Markdown('- ÂÆÉÂèØ‰ª•È´òÊïàÂú∞Â∫îÁî®Âú®ÂêÑÁ±ªËßÜÈ¢ëÁîüÊàêÂú∫ÊôØÔºåÂ∞§ÂÖ∂ÊòØ‰∫∫Áâ©Âä®Áîª„ÄÅÂú∫ÊôØËΩ¨Êç¢„ÄÅËßÜÈ¢ëÁºñËæëÁ≠âÈúÄË¶ÅÁ≤æÁ°ÆÊéßÂà∂ÁöÑ‰ªªÂä°„ÄÇ')
    with gr.Row():
        gr.Markdown('**ÔºàÂü∫‰∫éCannyÔºâÂú∫ÊôØËΩ¨Êç¢ÁöÑ‰ΩøÁî®ÊñπÊ≥ïÔºö**')
    with gr.Row():
        gr.Markdown('- ‰∏ä‰º†ËßÜÈ¢ëÔºàÁî®‰∫éÊèêÂèñËæπÁºòÔºâ')
    with gr.Row():
        gr.Markdown('- ËæìÂÖ•promptÊèèËø∞Êñ∞ÁîüÊàêÁöÑËßÜÈ¢ëÔºå‰æãÂ¶ÇÊ†∑‰æã‰∏≠Â∞ÜÂú∫ÊôØËΩ¨Êç¢‰∏∫snow mountain')
    with gr.Row():
        gr.Markdown('- ÁÇπ‰∫ëRunËøõË°åÁîüÊàê')
    with gr.Row():
        gr.Markdown('- ÁÇπÂáª"üëç Like"Êàñ"üëé Dislike"ÂØπÊ®°ÂûãÂõûÁ≠îËøõË°åÂèçÈ¶à')
    with gr.Row():
        gr.Markdown('**Ê≥®ÊÑè‰∫ãÈ°πÔºö**')
    with gr.Row():
        gr.Markdown('- ËßÜÈ¢ëË¶ÅÊ±ÇÔºö‰∏∫Ëé∑ÂæóÊúÄÂ•ΩÁöÑÁîüÊàêÊïàÊûúÔºåÂª∫ËÆÆÊèê‰æõ720ÔºàÂÆΩÔºâ*480ÔºàÈ´òÔºâËßÜÈ¢ëÔºåËßÜÈ¢ëÈïøÂ∫¶Âú®2s-5sÔºõËßÜÈ¢ëÂêçÁß∞‰∏çËÉΩÂ≠òÂú®‰∏≠ÊñáÔºåÁ©∫Ê†ºÂíåÁâπÊÆäÁ¨¶Âè∑')
    with gr.Row():
        gr.Markdown('- promptË¶ÅÊ±ÇÔºöÂíåÂéüÂßãËßÜÈ¢ëÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÁõ∏ÂÖ≥ÊÄßÔºõÊèèËø∞Â∞ΩÂèØËÉΩËØ¶ÁªÜÔºåÂçïËØçÊï∞ÈáèÂ∫î<80‰∏™ÂçïËØç')
    with gr.Row():
        gr.Markdown('- ËøêË°åÊó∂ÈïøÔºöÂ§ßÁ∫¶Âú®10minÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ')

    with gr.Row():
        with gr.Column():
            input_video = gr.Video(label="Upload Video")
            prompt = gr.Textbox(label="Prompt")
            model = gr.Dropdown(
                label="Select Model",
                choices=["cogvideox_5b_vctrl", "cogvideox_5b_i2v_vctrl"],
                value="cogvideox_5b_i2v_vctrl",
                interactive=True
            )
            use_controlnet = gr.Dropdown(
                label="Use ControlNet with ‚Äòcogvideox_5b_i2v_vctrl‚Äô",
                choices=["yes", "no"],
                value="yes",
                interactive=True
            )
            run_button = gr.Button(value="Run")
            with gr.Accordion("Advanced options", open=False):
                controlnet_seed = gr.Slider(
                    label="Controlnet Seed",
                    minimum=0,
                    maximum=100,
                    value=0,
                    step=1,
                )
                controlnet_num_inference_steps = gr.Slider(
                    label="Controlnet Steps",
                    minimum=1,
                    maximum=100,
                    value=28,
                    step=1,
                )
                controlnet_guidance_scale = gr.Slider(
                    label="Controlnet Guidance Scale",
                    minimum=0.1,
                    maximum=30.0,
                    value=7.0,
                    step=0.1,
                )
                controlnet_conditioning_scale = gr.Slider(
                    label="Controlnet Conditioning Scale",
                    minimum=0.0,
                    maximum=1.0,
                    value=1.0,
                    step=0.1,
                )
                conditioning_scale = gr.Slider(
                    label="Control Strength",
                    minimum=0.0,
                    maximum=5.0,
                    value=1.0,
                    step=0.05,
                )
                low_threshold = gr.Slider(
                    label="Canny low threshold",
                    minimum=1,
                    maximum=255,
                    value=100,
                    step=1,
                )
                high_threshold = gr.Slider(
                    label="Canny high threshold",
                    minimum=1,
                    maximum=255,
                    value=200,
                    step=1,
                )
                num_inference_steps = gr.Slider(label="Steps", minimum=1, maximum=100, value=20, step=1)
                guidance_scale = gr.Slider(
                    label="Guidance Scale",
                    minimum=0.1,
                    maximum=30.0,
                    value=9.0,
                    step=0.1,
                )
                max_frame = gr.Slider(
                    label="Max frames",
                    minimum=1,
                    maximum=100,
                    value=49,
                    step=1,
                )
        with gr.Column():
            display_video = gr.Video(label="Presentation video")
            generated_video = gr.Video(label="Generated Video")
            compared_video = gr.Video(label="Compared Video")
            ref_image = gr.Image(label="Reference Image")
    
    with gr.Row():
        feedback_display = gr.Textbox(
            value=get_feedback_stats(),
            label="üìä Feedback Stats",
            interactive=False
        )

    with gr.Row():
        like_button = gr.Button("üëç Like")
        dislike_button = gr.Button("üëé Dislike")
    
    like_button.click(
        fn=lambda: feedback_mgr.update_feedback("like"),
        outputs=feedback_display
    )
    dislike_button.click(
        fn=lambda: feedback_mgr.update_feedback("dislike"),
        outputs=feedback_display
    )

    ips = [
        model,
        input_video,
        prompt,
        controlnet_seed,
        controlnet_num_inference_steps,
        controlnet_guidance_scale,
        controlnet_conditioning_scale,
        num_inference_steps,
        conditioning_scale,
        guidance_scale,
        low_threshold,
        high_threshold,
        max_frame,
        use_controlnet
    ]

    run_button.click(fn=process, inputs=ips, outputs=[display_video, generated_video, compared_video, ref_image])

block.launch(server_name="0.0.0.0", server_port=8513, share=True)